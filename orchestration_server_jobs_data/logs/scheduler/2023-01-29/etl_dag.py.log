[2023-01-29T14:35:20.459+0000] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:35:20.463+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:35:20.464+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:35:20.464+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:36.492+0000] {processor.py:153} INFO - Started process (PID=164) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:36.506+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:45:36.508+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:45:36.508+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:37.478+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:45:37.461+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 7, in <module>
    import plotly.express as px
ModuleNotFoundError: No module named 'plotly'
[2023-01-29T14:45:37.479+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:37.517+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.033 seconds
[2023-01-29T14:45:47.678+0000] {processor.py:153} INFO - Started process (PID=171) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:47.681+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:45:47.683+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:45:47.683+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:47.967+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:45:47.955+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 7, in <module>
    import plotly.express as px
ModuleNotFoundError: No module named 'plotly'
[2023-01-29T14:45:47.969+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:47.990+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.318 seconds
[2023-01-29T14:45:58.161+0000] {processor.py:153} INFO - Started process (PID=177) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:58.164+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:45:58.165+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:45:58.165+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:58.418+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:45:58.412+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 7, in <module>
    import plotly.express as px
ModuleNotFoundError: No module named 'plotly'
[2023-01-29T14:45:58.421+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:45:58.446+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.295 seconds
[2023-01-29T14:46:08.621+0000] {processor.py:153} INFO - Started process (PID=183) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:08.623+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:46:08.625+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:46:08.624+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:08.917+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:46:08.912+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 7, in <module>
    import plotly.express as px
ModuleNotFoundError: No module named 'plotly'
[2023-01-29T14:46:08.919+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:08.956+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.340 seconds
[2023-01-29T14:46:19.179+0000] {processor.py:153} INFO - Started process (PID=189) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:19.181+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:46:19.182+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:46:19.182+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:19.457+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:46:19.451+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 7, in <module>
    import plotly.express as px
ModuleNotFoundError: No module named 'plotly'
[2023-01-29T14:46:19.458+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:19.493+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.321 seconds
[2023-01-29T14:46:29.726+0000] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:29.733+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:46:29.735+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:46:29.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:30.088+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:46:30.058+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 7, in <module>
    import plotly.express as px
ModuleNotFoundError: No module named 'plotly'
[2023-01-29T14:46:30.098+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:30.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.450 seconds
[2023-01-29T14:46:40.455+0000] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:40.459+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:46:40.461+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:46:40.461+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:40.788+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:46:40.782+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 7, in <module>
    import plotly.express as px
ModuleNotFoundError: No module named 'plotly'
[2023-01-29T14:46:40.792+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:46:40.842+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.406 seconds
[2023-01-29T14:51:28.082+0000] {processor.py:153} INFO - Started process (PID=167) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:28.093+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:51:28.095+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:51:28.095+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:29.671+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:51:29.656+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:51:29.674+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:29.694+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.626 seconds
[2023-01-29T14:51:39.943+0000] {processor.py:153} INFO - Started process (PID=173) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:39.952+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:51:39.954+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:51:39.954+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:40.501+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:51:40.496+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:51:40.504+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:40.525+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.587 seconds
[2023-01-29T14:51:50.726+0000] {processor.py:153} INFO - Started process (PID=179) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:50.730+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:51:50.732+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:51:50.732+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:51.329+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:51:51.324+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:51:51.330+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:51:51.350+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.627 seconds
[2023-01-29T14:52:01.490+0000] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:01.491+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:52:01.493+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:01.493+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:02.075+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:02.070+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:52:02.076+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:02.094+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.609 seconds
[2023-01-29T14:52:12.301+0000] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:12.305+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:52:12.307+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:12.307+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:12.944+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:12.939+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:52:12.949+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:12.981+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.684 seconds
[2023-01-29T14:52:23.219+0000] {processor.py:153} INFO - Started process (PID=197) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:23.222+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:52:23.224+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:23.223+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:23.814+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:23.805+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:52:23.818+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:23.850+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.639 seconds
[2023-01-29T14:52:34.108+0000] {processor.py:153} INFO - Started process (PID=203) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:34.111+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:52:34.113+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:34.112+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:34.687+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:34.683+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:52:34.688+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:34.712+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.617 seconds
[2023-01-29T14:52:44.946+0000] {processor.py:153} INFO - Started process (PID=209) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:44.949+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:52:44.951+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:44.951+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:45.614+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:45.610+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:52:45.616+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:45.629+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.692 seconds
[2023-01-29T14:52:55.861+0000] {processor.py:153} INFO - Started process (PID=215) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:55.864+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:52:55.867+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:55.867+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:56.503+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:52:56.498+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:52:56.504+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:52:56.531+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.675 seconds
[2023-01-29T14:53:06.679+0000] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:06.682+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:53:06.683+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:06.683+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:07.267+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:07.262+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:53:07.268+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:07.287+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.612 seconds
[2023-01-29T14:53:17.492+0000] {processor.py:153} INFO - Started process (PID=227) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:17.495+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:53:17.500+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:17.500+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:18.082+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:18.078+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:53:18.085+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:18.121+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.633 seconds
[2023-01-29T14:53:28.316+0000] {processor.py:153} INFO - Started process (PID=233) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:28.318+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:53:28.320+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:28.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:28.870+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:28.865+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:53:28.871+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:28.900+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.588 seconds
[2023-01-29T14:53:39.130+0000] {processor.py:153} INFO - Started process (PID=239) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:39.138+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:53:39.139+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:39.139+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:39.735+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:39.731+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:53:39.737+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:39.761+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.636 seconds
[2023-01-29T14:53:49.969+0000] {processor.py:153} INFO - Started process (PID=245) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:49.973+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:53:49.975+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:49.975+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:50.887+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:53:50.861+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:53:50.892+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:53:50.968+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.003 seconds
[2023-01-29T14:54:01.197+0000] {processor.py:153} INFO - Started process (PID=251) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:01.203+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:54:01.204+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:01.204+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:01.757+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:01.750+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:54:01.758+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:01.782+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.588 seconds
[2023-01-29T14:54:11.960+0000] {processor.py:153} INFO - Started process (PID=257) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:11.967+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:54:11.969+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:11.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:12.814+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:12.807+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:54:12.815+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:12.847+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.891 seconds
[2023-01-29T14:54:23.056+0000] {processor.py:153} INFO - Started process (PID=263) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:23.059+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:54:23.060+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:23.060+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:24.175+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:24.156+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:54:24.180+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:24.217+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.165 seconds
[2023-01-29T14:54:34.446+0000] {processor.py:153} INFO - Started process (PID=269) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:34.449+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:54:34.451+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:34.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:35.077+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:35.071+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:54:35.079+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:35.103+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.667 seconds
[2023-01-29T14:54:45.313+0000] {processor.py:153} INFO - Started process (PID=275) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:45.315+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:54:45.316+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:45.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:45.921+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:45.910+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:54:45.924+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:45.964+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.657 seconds
[2023-01-29T14:54:56.164+0000] {processor.py:153} INFO - Started process (PID=281) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:56.167+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:54:56.168+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:56.168+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:56.860+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:54:56.856+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:54:56.862+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:54:56.882+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.722 seconds
[2023-01-29T14:55:07.106+0000] {processor.py:153} INFO - Started process (PID=287) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:07.108+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:55:07.110+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:07.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:07.752+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:07.746+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:55:07.754+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:07.780+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.679 seconds
[2023-01-29T14:55:17.910+0000] {processor.py:153} INFO - Started process (PID=293) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:17.912+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:55:17.913+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:17.913+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:18.532+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:18.528+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:55:18.534+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:18.552+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.648 seconds
[2023-01-29T14:55:28.779+0000] {processor.py:153} INFO - Started process (PID=299) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:28.783+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:55:28.784+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:28.784+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:29.411+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:29.407+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:55:29.413+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:29.431+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.663 seconds
[2023-01-29T14:55:39.649+0000] {processor.py:153} INFO - Started process (PID=305) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:39.652+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:55:39.654+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:39.654+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:40.276+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:40.271+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:55:40.278+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:40.300+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.656 seconds
[2023-01-29T14:55:50.542+0000] {processor.py:153} INFO - Started process (PID=311) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:50.545+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:55:50.546+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:50.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:51.178+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:55:51.174+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:55:51.180+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:55:51.209+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.674 seconds
[2023-01-29T14:56:01.431+0000] {processor.py:153} INFO - Started process (PID=317) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:01.433+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:56:01.435+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:01.435+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:02.044+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:02.038+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:56:02.045+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:02.070+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.645 seconds
[2023-01-29T14:56:12.372+0000] {processor.py:153} INFO - Started process (PID=323) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:12.376+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:56:12.380+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:12.380+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:13.257+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:13.251+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:56:13.260+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:13.289+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.923 seconds
[2023-01-29T14:56:23.683+0000] {processor.py:153} INFO - Started process (PID=329) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:23.697+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:56:23.699+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:23.699+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:24.377+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:24.373+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:56:24.380+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:24.401+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.724 seconds
[2023-01-29T14:56:34.628+0000] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:34.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:56:34.640+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:34.640+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:35.720+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:35.710+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:56:35.725+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:35.780+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.133 seconds
[2023-01-29T14:56:46.098+0000] {processor.py:153} INFO - Started process (PID=341) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:46.105+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:56:46.108+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:46.108+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:48.302+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:48.288+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:56:48.305+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:48.372+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 2.281 seconds
[2023-01-29T14:56:58.804+0000] {processor.py:153} INFO - Started process (PID=347) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:58.808+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:56:58.810+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:58.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:59.508+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:56:59.500+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:56:59.509+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:56:59.548+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.756 seconds
[2023-01-29T14:57:09.785+0000] {processor.py:153} INFO - Started process (PID=353) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:09.788+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:57:09.790+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:09.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:10.757+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:10.744+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:57:10.763+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:10.800+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.026 seconds
[2023-01-29T14:57:20.976+0000] {processor.py:153} INFO - Started process (PID=359) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:20.979+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:57:20.982+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:20.982+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:21.634+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:21.624+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:57:21.636+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:21.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.695 seconds
[2023-01-29T14:57:31.924+0000] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:31.926+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:57:31.927+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:31.927+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:32.688+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:32.682+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:57:32.690+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:32.734+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.816 seconds
[2023-01-29T14:57:43.009+0000] {processor.py:153} INFO - Started process (PID=371) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:43.012+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:57:43.014+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:43.014+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:43.747+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:43.734+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:57:43.749+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:43.797+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.795 seconds
[2023-01-29T14:57:54.133+0000] {processor.py:153} INFO - Started process (PID=377) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:54.137+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:57:54.140+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:54.140+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:54.900+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:57:54.894+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:57:54.906+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:57:54.931+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.813 seconds
[2023-01-29T14:58:05.135+0000] {processor.py:153} INFO - Started process (PID=383) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:05.137+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:58:05.139+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:58:05.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:05.810+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:58:05.803+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:58:05.813+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:05.830+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.700 seconds
[2023-01-29T14:58:16.067+0000] {processor.py:153} INFO - Started process (PID=389) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:16.071+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:58:16.075+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:58:16.075+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:16.690+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:58:16.683+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:58:16.693+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:16.720+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.660 seconds
[2023-01-29T14:58:26.937+0000] {processor.py:153} INFO - Started process (PID=395) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:26.940+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:58:26.942+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:58:26.941+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:27.576+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:58:27.569+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:58:27.577+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:27.594+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.662 seconds
[2023-01-29T14:58:37.896+0000] {processor.py:153} INFO - Started process (PID=401) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:37.902+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T14:58:37.903+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:58:37.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:38.824+0000] {logging_mixin.py:137} INFO - [2023-01-29T14:58:38.815+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 9, in <module>
    import spacy
ModuleNotFoundError: No module named 'spacy'
[2023-01-29T14:58:38.825+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T14:58:38.883+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.002 seconds
[2023-01-29T15:03:40.697+0000] {processor.py:153} INFO - Started process (PID=167) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:03:40.703+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:03:40.705+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:03:40.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:03:51.913+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:03:51.973+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:03:51.972+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:03:52.030+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:03:52.029+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:03:51.844321+00:00, run_after=2023-01-30T15:03:51.844321+00:00
[2023-01-29T15:03:52.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 11.371 seconds
[2023-01-29T15:04:02.418+0000] {processor.py:153} INFO - Started process (PID=174) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:02.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:04:02.423+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:02.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:06.340+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:06.376+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:06.375+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:04:06.393+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:06.393+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:04:06.324141+00:00, run_after=2023-01-30T15:04:06.324141+00:00
[2023-01-29T15:04:06.414+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.007 seconds
[2023-01-29T15:04:16.741+0000] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:16.744+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:04:16.746+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:16.746+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:20.449+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:20.512+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:20.511+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:04:20.527+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:20.526+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:04:20.440356+00:00, run_after=2023-01-30T15:04:20.440356+00:00
[2023-01-29T15:04:20.539+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.806 seconds
[2023-01-29T15:04:30.813+0000] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:30.817+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:04:30.819+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:30.819+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:34.480+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:34.508+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:34.508+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:04:34.529+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:34.529+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:04:34.456705+00:00, run_after=2023-01-30T15:04:34.456705+00:00
[2023-01-29T15:04:34.547+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.743 seconds
[2023-01-29T15:04:44.898+0000] {processor.py:153} INFO - Started process (PID=192) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:44.901+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:04:44.903+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:44.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:48.392+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:48.463+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:48.462+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:04:48.495+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:48.495+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:04:48.362794+00:00, run_after=2023-01-30T15:04:48.362794+00:00
[2023-01-29T15:04:48.511+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.618 seconds
[2023-01-29T15:04:58.847+0000] {processor.py:153} INFO - Started process (PID=198) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:04:58.850+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:04:58.852+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:04:58.851+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:02.233+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:02.297+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:02.297+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:05:02.311+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:02.311+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:05:02.218912+00:00, run_after=2023-01-30T15:05:02.218912+00:00
[2023-01-29T15:05:02.324+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.486 seconds
[2023-01-29T15:05:12.537+0000] {processor.py:153} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:12.539+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:05:12.541+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:12.541+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:16.403+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:16.425+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:16.425+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:05:16.450+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:16.450+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:05:16.379779+00:00, run_after=2023-01-30T15:05:16.379779+00:00
[2023-01-29T15:05:16.465+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.931 seconds
[2023-01-29T15:05:26.669+0000] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:26.671+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:05:26.672+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:26.672+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:30.127+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:30.154+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:30.154+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:05:30.175+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:30.175+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:05:30.109332+00:00, run_after=2023-01-30T15:05:30.109332+00:00
[2023-01-29T15:05:30.193+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.529 seconds
[2023-01-29T15:05:40.500+0000] {processor.py:153} INFO - Started process (PID=216) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:40.506+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:05:40.507+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:40.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:43.981+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:44.127+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:44.125+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:05:44.192+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:44.192+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:05:43.949256+00:00, run_after=2023-01-30T15:05:43.949256+00:00
[2023-01-29T15:05:44.212+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.717 seconds
[2023-01-29T15:05:54.520+0000] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:54.523+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:05:54.525+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:54.524+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:58.135+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:05:58.153+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:58.153+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:05:58.172+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:05:58.172+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:05:58.124253+00:00, run_after=2023-01-30T15:05:58.124253+00:00
[2023-01-29T15:05:58.183+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.667 seconds
[2023-01-29T15:06:08.465+0000] {processor.py:153} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:08.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:06:08.470+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:08.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:11.918+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:11.953+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:11.952+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:06:11.972+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:11.972+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:06:11.890895+00:00, run_after=2023-01-30T15:06:11.890895+00:00
[2023-01-29T15:06:11.987+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.527 seconds
[2023-01-29T15:06:22.306+0000] {processor.py:153} INFO - Started process (PID=234) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:22.308+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:06:22.309+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:22.309+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:25.825+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:25.899+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:25.898+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:06:25.917+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:25.917+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:06:25.804046+00:00, run_after=2023-01-30T15:06:25.804046+00:00
[2023-01-29T15:06:25.932+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.631 seconds
[2023-01-29T15:06:36.244+0000] {processor.py:153} INFO - Started process (PID=240) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:36.247+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:06:36.249+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:36.248+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:39.703+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:39.726+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:39.726+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:06:39.752+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:39.752+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:06:39.680936+00:00, run_after=2023-01-30T15:06:39.680936+00:00
[2023-01-29T15:06:39.764+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.526 seconds
[2023-01-29T15:06:50.033+0000] {processor.py:153} INFO - Started process (PID=246) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:50.036+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:06:50.038+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:50.038+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:53.563+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:06:53.586+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:53.586+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:06:53.611+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:06:53.611+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:06:53.543998+00:00, run_after=2023-01-30T15:06:53.543998+00:00
[2023-01-29T15:06:53.624+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.602 seconds
[2023-01-29T15:07:03.788+0000] {processor.py:153} INFO - Started process (PID=252) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:03.791+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:07:03.793+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:03.793+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:07.320+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:07.387+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:07.387+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:07:07.409+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:07.409+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:07:07.295537+00:00, run_after=2023-01-30T15:07:07.295537+00:00
[2023-01-29T15:07:07.422+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.641 seconds
[2023-01-29T15:07:17.714+0000] {processor.py:153} INFO - Started process (PID=258) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:17.717+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:07:17.718+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:17.718+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:21.238+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:21.259+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:21.259+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:07:21.280+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:21.280+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:07:21.224612+00:00, run_after=2023-01-30T15:07:21.224612+00:00
[2023-01-29T15:07:21.292+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.584 seconds
[2023-01-29T15:07:31.565+0000] {processor.py:153} INFO - Started process (PID=264) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:31.568+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:07:31.569+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:31.569+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:35.080+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:35.109+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:35.109+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:07:35.129+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:35.129+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:07:35.046047+00:00, run_after=2023-01-30T15:07:35.046047+00:00
[2023-01-29T15:07:35.144+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.589 seconds
[2023-01-29T15:07:45.439+0000] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:45.442+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:07:45.443+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:45.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:49.201+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:49.269+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:49.269+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:07:49.288+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:49.288+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:07:49.189508+00:00, run_after=2023-01-30T15:07:49.189508+00:00
[2023-01-29T15:07:49.300+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.867 seconds
[2023-01-29T15:07:59.471+0000] {processor.py:153} INFO - Started process (PID=276) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:07:59.473+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:07:59.475+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:07:59.475+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:02.976+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:02.995+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:02.995+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:08:03.019+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:03.019+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:08:02.960080+00:00, run_after=2023-01-30T15:08:02.960080+00:00
[2023-01-29T15:08:03.030+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.564 seconds
[2023-01-29T15:08:13.312+0000] {processor.py:153} INFO - Started process (PID=282) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:13.316+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:08:13.318+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:13.318+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:16.849+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:16.877+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:16.876+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:08:16.914+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:16.914+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:08:16.825546+00:00, run_after=2023-01-30T15:08:16.825546+00:00
[2023-01-29T15:08:16.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.627 seconds
[2023-01-29T15:08:27.254+0000] {processor.py:153} INFO - Started process (PID=288) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:27.261+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:08:27.262+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:27.262+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:30.650+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:30.718+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:30.718+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:08:30.735+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:30.735+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:08:30.634647+00:00, run_after=2023-01-30T15:08:30.634647+00:00
[2023-01-29T15:08:30.749+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.500 seconds
[2023-01-29T15:08:41.150+0000] {processor.py:153} INFO - Started process (PID=294) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:41.153+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:08:41.154+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:41.154+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:44.534+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:44.552+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:44.552+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:08:44.570+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:44.570+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:08:44.514787+00:00, run_after=2023-01-30T15:08:44.514787+00:00
[2023-01-29T15:08:44.581+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.440 seconds
[2023-01-29T15:08:54.790+0000] {processor.py:153} INFO - Started process (PID=300) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:54.792+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:08:54.793+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:54.793+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:58.302+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:08:58.327+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:58.326+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:08:58.353+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:08:58.352+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:08:58.276380+00:00, run_after=2023-01-30T15:08:58.276380+00:00
[2023-01-29T15:08:58.366+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.580 seconds
[2023-01-29T15:09:08.642+0000] {processor.py:153} INFO - Started process (PID=306) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:08.646+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:09:08.647+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:08.647+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:11.959+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:12.013+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:12.013+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:09:12.027+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:12.027+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:09:11.952662+00:00, run_after=2023-01-30T15:09:11.952662+00:00
[2023-01-29T15:09:12.040+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.403 seconds
[2023-01-29T15:09:22.313+0000] {processor.py:153} INFO - Started process (PID=312) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:22.316+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:09:22.317+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:22.317+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:25.734+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:25.751+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:25.750+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:09:25.766+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:25.766+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:09:25.726168+00:00, run_after=2023-01-30T15:09:25.726168+00:00
[2023-01-29T15:09:25.778+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.470 seconds
[2023-01-29T15:09:35.908+0000] {processor.py:153} INFO - Started process (PID=318) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:35.911+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:09:35.912+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:35.912+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:39.327+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:39.350+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:39.350+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:09:39.369+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:39.368+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:09:39.308027+00:00, run_after=2023-01-30T15:09:39.308027+00:00
[2023-01-29T15:09:39.386+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.484 seconds
[2023-01-29T15:09:49.709+0000] {processor.py:153} INFO - Started process (PID=324) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:49.712+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:09:49.713+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:49.713+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:53.153+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:09:53.217+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:53.217+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:09:53.232+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:09:53.232+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:09:53.140699+00:00, run_after=2023-01-30T15:09:53.140699+00:00
[2023-01-29T15:09:53.245+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.540 seconds
[2023-01-29T15:10:03.511+0000] {processor.py:153} INFO - Started process (PID=330) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:03.516+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:10:03.518+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:03.517+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:06.956+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:06.974+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:06.974+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:10:06.994+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:06.994+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:10:06.938136+00:00, run_after=2023-01-30T15:10:06.938136+00:00
[2023-01-29T15:10:07.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.510 seconds
[2023-01-29T15:10:17.275+0000] {processor.py:153} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:17.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:10:17.280+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:17.280+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:20.741+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:20.764+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:20.764+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:10:20.784+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:20.784+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:10:20.715985+00:00, run_after=2023-01-30T15:10:20.715985+00:00
[2023-01-29T15:10:20.803+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.534 seconds
[2023-01-29T15:10:31.089+0000] {processor.py:153} INFO - Started process (PID=342) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:31.092+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:10:31.093+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:31.093+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:34.361+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:34.415+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:34.415+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:10:34.429+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:34.429+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:10:34.354388+00:00, run_after=2023-01-30T15:10:34.354388+00:00
[2023-01-29T15:10:34.446+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.363 seconds
[2023-01-29T15:10:44.702+0000] {processor.py:153} INFO - Started process (PID=348) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:44.706+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:10:44.708+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:44.708+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:48.336+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:48.377+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:48.376+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:10:48.396+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:48.396+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:10:48.317791+00:00, run_after=2023-01-30T15:10:48.317791+00:00
[2023-01-29T15:10:48.408+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.716 seconds
[2023-01-29T15:10:58.743+0000] {processor.py:153} INFO - Started process (PID=354) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:10:58.746+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:10:58.748+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:10:58.747+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:02.909+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:02.939+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:02.939+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:11:02.959+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:02.959+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:11:02.885067+00:00, run_after=2023-01-30T15:11:02.885067+00:00
[2023-01-29T15:11:02.984+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.247 seconds
[2023-01-29T15:11:13.247+0000] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:13.251+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:11:13.252+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:13.252+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:16.874+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:16.932+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:16.931+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:11:16.948+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:16.948+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:11:16.853571+00:00, run_after=2023-01-30T15:11:16.853571+00:00
[2023-01-29T15:11:16.965+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.724 seconds
[2023-01-29T15:11:27.157+0000] {processor.py:153} INFO - Started process (PID=366) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:27.159+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:11:27.160+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:27.160+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:30.828+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:30.877+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:30.876+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:11:30.947+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:30.946+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:11:30.743838+00:00, run_after=2023-01-30T15:11:30.743838+00:00
[2023-01-29T15:11:30.969+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.816 seconds
[2023-01-29T15:11:41.312+0000] {processor.py:153} INFO - Started process (PID=372) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:41.315+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:11:41.317+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:41.317+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:45.225+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:45.260+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:45.260+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:11:45.290+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:45.290+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:11:45.206778+00:00, run_after=2023-01-30T15:11:45.206778+00:00
[2023-01-29T15:11:45.305+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.998 seconds
[2023-01-29T15:11:55.524+0000] {processor.py:153} INFO - Started process (PID=378) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:55.527+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:11:55.528+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:55.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:59.440+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:11:59.517+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:59.517+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:11:59.541+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:11:59.541+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:11:59.404956+00:00, run_after=2023-01-30T15:11:59.404956+00:00
[2023-01-29T15:11:59.555+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.036 seconds
[2023-01-29T15:12:07.871+0000] {processor.py:153} INFO - Started process (PID=384) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:07.881+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:12:07.885+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:07.885+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:12.588+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:12.665+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:12.665+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:12:12.695+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:12.695+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:12:12.551861+00:00, run_after=2023-01-30T15:12:12.551861+00:00
[2023-01-29T15:12:12.717+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.868 seconds
[2023-01-29T15:12:23.086+0000] {processor.py:153} INFO - Started process (PID=390) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:23.089+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:12:23.090+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:23.090+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:26.502+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:26.515+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:26.514+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:12:26.528+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:26.528+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:12:26.492598+00:00, run_after=2023-01-30T15:12:26.492598+00:00
[2023-01-29T15:12:26.539+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.460 seconds
[2023-01-29T15:12:36.769+0000] {processor.py:153} INFO - Started process (PID=396) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:36.772+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:12:36.774+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:36.773+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:40.493+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:40.590+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:40.589+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:12:40.618+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:40.618+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:12:40.440974+00:00, run_after=2023-01-30T15:12:40.440974+00:00
[2023-01-29T15:12:40.638+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.874 seconds
[2023-01-29T15:12:50.906+0000] {processor.py:153} INFO - Started process (PID=402) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:50.909+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:12:50.910+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:50.910+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:54.439+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:12:54.480+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:54.479+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:12:54.506+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:12:54.506+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:12:54.414240+00:00, run_after=2023-01-30T15:12:54.414240+00:00
[2023-01-29T15:12:54.524+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.623 seconds
[2023-01-29T15:13:04.709+0000] {processor.py:153} INFO - Started process (PID=408) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:04.712+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:13:04.713+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:04.713+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:08.034+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:08.050+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:08.050+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:13:08.071+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:08.071+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:13:08.025631+00:00, run_after=2023-01-30T15:13:08.025631+00:00
[2023-01-29T15:13:08.088+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.380 seconds
[2023-01-29T15:13:18.272+0000] {processor.py:153} INFO - Started process (PID=414) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:18.275+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:13:18.276+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:18.276+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:21.615+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:21.670+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:21.669+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:13:21.685+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:21.684+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:13:21.594569+00:00, run_after=2023-01-30T15:13:21.594569+00:00
[2023-01-29T15:13:21.698+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.431 seconds
[2023-01-29T15:13:31.902+0000] {processor.py:153} INFO - Started process (PID=420) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:31.905+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:13:31.906+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:31.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:35.355+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:35.379+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:35.379+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:13:35.395+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:35.395+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:13:35.343814+00:00, run_after=2023-01-30T15:13:35.343814+00:00
[2023-01-29T15:13:35.411+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.522 seconds
[2023-01-29T15:13:45.652+0000] {processor.py:153} INFO - Started process (PID=426) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:45.655+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:13:45.656+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:45.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:49.877+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:13:49.895+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:49.895+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:13:49.912+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:13:49.912+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:13:49.863017+00:00, run_after=2023-01-30T15:13:49.863017+00:00
[2023-01-29T15:13:49.924+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.282 seconds
[2023-01-29T15:14:00.153+0000] {processor.py:153} INFO - Started process (PID=432) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:00.156+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:14:00.157+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:00.157+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:03.845+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:03.955+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:03.954+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:14:04.005+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:04.005+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:14:03.805656+00:00, run_after=2023-01-30T15:14:03.805656+00:00
[2023-01-29T15:14:04.022+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.873 seconds
[2023-01-29T15:14:14.318+0000] {processor.py:153} INFO - Started process (PID=438) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:14.320+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:14:14.322+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:14.322+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:17.762+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:17.808+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:17.808+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:14:17.827+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:17.827+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:14:17.738492+00:00, run_after=2023-01-30T15:14:17.738492+00:00
[2023-01-29T15:14:17.842+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.528 seconds
[2023-01-29T15:14:22.451+0000] {processor.py:153} INFO - Started process (PID=444) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:22.453+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:14:22.455+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:22.455+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:26.551+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:26.587+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:26.587+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:14:26.606+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:26.606+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:14:26.538986+00:00, run_after=2023-01-30T15:14:26.538986+00:00
[2023-01-29T15:14:26.628+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.188 seconds
[2023-01-29T15:14:34.883+0000] {processor.py:153} INFO - Started process (PID=450) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:34.885+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:14:34.890+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:34.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:38.424+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:38.486+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:38.485+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:14:38.501+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:38.501+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:14:38.414885+00:00, run_after=2023-01-30T15:14:38.414885+00:00
[2023-01-29T15:14:38.519+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.643 seconds
[2023-01-29T15:14:48.854+0000] {processor.py:153} INFO - Started process (PID=456) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:48.856+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:14:48.857+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:48.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:52.461+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:14:52.500+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:52.499+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:14:52.520+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:14:52.520+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:14:52.448283+00:00, run_after=2023-01-30T15:14:52.448283+00:00
[2023-01-29T15:14:52.532+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.683 seconds
[2023-01-29T15:15:02.804+0000] {processor.py:153} INFO - Started process (PID=462) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:02.807+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:15:02.810+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:02.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:06.589+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:06.621+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:06.621+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:15:06.648+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:06.648+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:15:06.564159+00:00, run_after=2023-01-30T15:15:06.564159+00:00
[2023-01-29T15:15:06.662+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.859 seconds
[2023-01-29T15:15:12.995+0000] {processor.py:153} INFO - Started process (PID=468) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:13.010+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:15:13.014+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:13.014+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:16.823+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:16.882+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:16.881+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:15:16.903+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:16.903+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:15:16.797589+00:00, run_after=2023-01-30T15:15:16.797589+00:00
[2023-01-29T15:15:16.920+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.931 seconds
[2023-01-29T15:15:27.210+0000] {processor.py:153} INFO - Started process (PID=474) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:27.213+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:15:27.215+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:27.214+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:30.580+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:30.609+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:30.608+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:15:30.625+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:30.625+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:15:30.564513+00:00, run_after=2023-01-30T15:15:30.564513+00:00
[2023-01-29T15:15:30.638+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.438 seconds
[2023-01-29T15:15:40.892+0000] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:40.895+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:15:40.897+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:40.896+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:44.462+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:44.493+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:44.493+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:15:44.511+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:44.511+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:15:44.446212+00:00, run_after=2023-01-30T15:15:44.446212+00:00
[2023-01-29T15:15:44.523+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.636 seconds
[2023-01-29T15:15:54.687+0000] {processor.py:153} INFO - Started process (PID=486) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:54.690+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:15:54.691+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:54.691+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:58.254+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:15:58.317+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:58.317+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:15:58.334+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:15:58.334+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:15:58.223097+00:00, run_after=2023-01-30T15:15:58.223097+00:00
[2023-01-29T15:15:58.348+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.667 seconds
[2023-01-29T15:16:08.656+0000] {processor.py:153} INFO - Started process (PID=492) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:08.661+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:16:08.664+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:08.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:12.019+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:12.059+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:12.058+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:16:12.086+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:12.086+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:16:12.009890+00:00, run_after=2023-01-30T15:16:12.009890+00:00
[2023-01-29T15:16:12.099+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.449 seconds
[2023-01-29T15:16:22.330+0000] {processor.py:153} INFO - Started process (PID=498) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:22.333+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:16:22.335+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:22.335+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:25.848+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:25.869+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:25.869+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:16:25.892+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:25.892+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:16:25.833477+00:00, run_after=2023-01-30T15:16:25.833477+00:00
[2023-01-29T15:16:25.905+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.582 seconds
[2023-01-29T15:16:36.173+0000] {processor.py:153} INFO - Started process (PID=504) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:36.176+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:16:36.178+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:36.178+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:39.632+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:39.700+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:39.699+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:16:39.716+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:39.715+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:16:39.609969+00:00, run_after=2023-01-30T15:16:39.609969+00:00
[2023-01-29T15:16:39.734+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.568 seconds
[2023-01-29T15:16:49.965+0000] {processor.py:153} INFO - Started process (PID=510) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:49.967+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:16:49.969+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:49.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:53.544+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:16:53.575+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:53.574+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:16:53.595+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:16:53.595+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:16:53.532270+00:00, run_after=2023-01-30T15:16:53.532270+00:00
[2023-01-29T15:16:53.608+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.648 seconds
[2023-01-29T15:17:03.857+0000] {processor.py:153} INFO - Started process (PID=516) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:03.861+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:17:03.863+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:03.862+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:07.305+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:07.335+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:07.335+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:17:07.367+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:07.366+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:17:07.295145+00:00, run_after=2023-01-30T15:17:07.295145+00:00
[2023-01-29T15:17:07.388+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.541 seconds
[2023-01-29T15:17:17.685+0000] {processor.py:153} INFO - Started process (PID=522) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:17.691+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:17:17.693+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:17.692+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:21.211+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:21.270+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:21.270+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:17:21.286+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:21.286+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:17:21.191371+00:00, run_after=2023-01-30T15:17:21.191371+00:00
[2023-01-29T15:17:21.302+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.623 seconds
[2023-01-29T15:17:31.564+0000] {processor.py:153} INFO - Started process (PID=528) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:31.567+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:17:31.568+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:31.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:35.036+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:35.059+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:35.059+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:17:35.084+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:35.084+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:17:35.010340+00:00, run_after=2023-01-30T15:17:35.010340+00:00
[2023-01-29T15:17:35.098+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.540 seconds
[2023-01-29T15:17:45.243+0000] {processor.py:153} INFO - Started process (PID=534) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:45.245+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:17:45.246+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:45.246+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:48.710+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:48.747+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:48.746+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:17:48.767+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:48.767+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:17:48.690291+00:00, run_after=2023-01-30T15:17:48.690291+00:00
[2023-01-29T15:17:48.784+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.546 seconds
[2023-01-29T15:17:59.128+0000] {processor.py:153} INFO - Started process (PID=540) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:17:59.130+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:17:59.132+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:17:59.132+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:02.829+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:02.888+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:02.887+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:18:02.903+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:02.903+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:18:02.814596+00:00, run_after=2023-01-30T15:18:02.814596+00:00
[2023-01-29T15:18:02.916+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.792 seconds
[2023-01-29T15:18:13.152+0000] {processor.py:153} INFO - Started process (PID=546) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:13.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:18:13.155+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:13.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:16.574+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:16.623+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:16.622+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:18:16.643+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:16.643+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:18:16.545837+00:00, run_after=2023-01-30T15:18:16.545837+00:00
[2023-01-29T15:18:16.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.521 seconds
[2023-01-29T15:18:26.952+0000] {processor.py:153} INFO - Started process (PID=552) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:26.954+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:18:26.956+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:26.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:30.461+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:30.493+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:30.493+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:18:30.511+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:30.511+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:18:30.444883+00:00, run_after=2023-01-30T15:18:30.444883+00:00
[2023-01-29T15:18:30.523+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.576 seconds
[2023-01-29T15:18:40.758+0000] {processor.py:153} INFO - Started process (PID=558) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:40.760+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:18:40.762+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:40.761+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:44.759+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:44.836+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:44.836+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:18:44.859+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:44.859+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:18:44.731953+00:00, run_after=2023-01-30T15:18:44.731953+00:00
[2023-01-29T15:18:44.874+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.120 seconds
[2023-01-29T15:18:55.069+0000] {processor.py:153} INFO - Started process (PID=564) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:55.072+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:18:55.075+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:55.075+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:58.447+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:18:58.471+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:58.471+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:18:58.491+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:18:58.490+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:18:58.433823+00:00, run_after=2023-01-30T15:18:58.433823+00:00
[2023-01-29T15:18:58.503+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.447 seconds
[2023-01-29T15:19:08.788+0000] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:08.791+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:19:08.792+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:08.792+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:12.360+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:12.381+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:12.380+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:19:12.403+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:12.403+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:19:12.349373+00:00, run_after=2023-01-30T15:19:12.349373+00:00
[2023-01-29T15:19:12.416+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.635 seconds
[2023-01-29T15:19:22.658+0000] {processor.py:153} INFO - Started process (PID=576) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:22.661+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:19:22.663+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:22.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:26.301+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:26.373+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:26.373+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:19:26.390+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:26.390+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:19:26.281399+00:00, run_after=2023-01-30T15:19:26.281399+00:00
[2023-01-29T15:19:26.403+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.750 seconds
[2023-01-29T15:19:36.723+0000] {processor.py:153} INFO - Started process (PID=582) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:36.725+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:19:36.726+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:36.726+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:40.157+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:40.186+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:40.185+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:19:40.207+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:40.207+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:19:40.141596+00:00, run_after=2023-01-30T15:19:40.141596+00:00
[2023-01-29T15:19:40.219+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.502 seconds
[2023-01-29T15:19:50.501+0000] {processor.py:153} INFO - Started process (PID=588) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:50.504+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:19:50.506+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:50.506+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:53.922+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:19:53.946+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:53.945+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:19:53.965+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:19:53.965+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:19:53.898029+00:00, run_after=2023-01-30T15:19:53.898029+00:00
[2023-01-29T15:19:53.984+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.493 seconds
[2023-01-29T15:20:04.253+0000] {processor.py:153} INFO - Started process (PID=594) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:04.257+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:20:04.259+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:04.259+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:07.833+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:07.892+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:07.892+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:20:07.911+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:07.911+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:20:07.824086+00:00, run_after=2023-01-30T15:20:07.824086+00:00
[2023-01-29T15:20:07.925+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.687 seconds
[2023-01-29T15:20:18.205+0000] {processor.py:153} INFO - Started process (PID=600) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:18.208+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:20:18.210+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:18.209+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:21.648+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:21.672+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:21.671+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:20:21.689+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:21.689+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:20:21.638518+00:00, run_after=2023-01-30T15:20:21.638518+00:00
[2023-01-29T15:20:21.701+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.501 seconds
[2023-01-29T15:20:31.971+0000] {processor.py:153} INFO - Started process (PID=606) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:31.975+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:20:31.977+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:31.976+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:35.398+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:35.430+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:35.430+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:20:35.478+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:35.478+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:20:35.378946+00:00, run_after=2023-01-30T15:20:35.378946+00:00
[2023-01-29T15:20:35.492+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.532 seconds
[2023-01-29T15:20:45.736+0000] {processor.py:153} INFO - Started process (PID=612) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:45.739+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:20:45.741+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:45.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:49.758+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:20:49.840+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:49.840+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:20:49.863+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:20:49.863+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:20:49.737375+00:00, run_after=2023-01-30T15:20:49.737375+00:00
[2023-01-29T15:20:49.878+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.147 seconds
[2023-01-29T15:21:00.123+0000] {processor.py:153} INFO - Started process (PID=618) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:00.134+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:21:00.136+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:00.136+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:04.017+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:04.056+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:04.056+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:21:04.079+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:04.079+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:21:03.987373+00:00, run_after=2023-01-30T15:21:03.987373+00:00
[2023-01-29T15:21:04.092+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.974 seconds
[2023-01-29T15:21:14.362+0000] {processor.py:153} INFO - Started process (PID=624) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:14.365+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:21:14.367+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:14.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:17.841+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:17.894+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:17.894+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:21:17.930+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:17.930+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:21:17.817484+00:00, run_after=2023-01-30T15:21:17.817484+00:00
[2023-01-29T15:21:17.952+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.600 seconds
[2023-01-29T15:21:28.338+0000] {processor.py:153} INFO - Started process (PID=630) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:28.340+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:21:28.342+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:28.342+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:31.999+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:32.072+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:32.072+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:21:32.087+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:32.087+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:21:31.985092+00:00, run_after=2023-01-30T15:21:31.985092+00:00
[2023-01-29T15:21:32.100+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.778 seconds
[2023-01-29T15:21:42.382+0000] {processor.py:153} INFO - Started process (PID=636) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:42.384+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:21:42.385+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:42.385+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:46.053+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:46.105+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:46.104+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:21:46.127+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:46.127+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:21:45.949601+00:00, run_after=2023-01-30T15:21:45.949601+00:00
[2023-01-29T15:21:46.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.774 seconds
[2023-01-29T15:21:56.482+0000] {processor.py:153} INFO - Started process (PID=642) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:21:56.484+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:21:56.486+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:21:56.486+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:00.011+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:00.049+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:00.049+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:22:00.076+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:00.075+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:21:59.980151+00:00, run_after=2023-01-30T15:21:59.980151+00:00
[2023-01-29T15:22:00.092+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.614 seconds
[2023-01-29T15:22:10.381+0000] {processor.py:153} INFO - Started process (PID=648) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:10.383+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:22:10.385+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:10.385+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:13.910+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:13.974+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:13.974+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:22:13.995+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:13.995+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:22:13.887166+00:00, run_after=2023-01-30T15:22:13.887166+00:00
[2023-01-29T15:22:14.011+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.634 seconds
[2023-01-29T15:22:24.416+0000] {processor.py:153} INFO - Started process (PID=654) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:24.418+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:22:24.420+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:24.420+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:28.214+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:28.265+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:28.265+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:22:28.302+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:28.302+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:22:28.179898+00:00, run_after=2023-01-30T15:22:28.179898+00:00
[2023-01-29T15:22:28.398+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.989 seconds
[2023-01-29T15:22:38.662+0000] {processor.py:153} INFO - Started process (PID=660) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:38.664+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:22:38.666+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:38.666+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:42.215+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:42.245+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:42.244+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:22:42.264+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:42.264+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:22:42.188345+00:00, run_after=2023-01-30T15:22:42.188345+00:00
[2023-01-29T15:22:42.276+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.618 seconds
[2023-01-29T15:22:52.568+0000] {processor.py:153} INFO - Started process (PID=666) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:52.571+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:22:52.573+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:52.573+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:56.347+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:22:56.414+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:56.414+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:22:56.431+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:22:56.431+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:22:56.319951+00:00, run_after=2023-01-30T15:22:56.319951+00:00
[2023-01-29T15:22:56.444+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.882 seconds
[2023-01-29T15:23:06.694+0000] {processor.py:153} INFO - Started process (PID=672) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:06.697+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:23:06.699+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:06.699+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:10.022+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:10.062+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:10.061+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:23:10.085+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:10.085+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:23:10.009187+00:00, run_after=2023-01-30T15:23:10.009187+00:00
[2023-01-29T15:23:10.097+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.410 seconds
[2023-01-29T15:23:20.367+0000] {processor.py:153} INFO - Started process (PID=678) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:20.371+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:23:20.373+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:20.373+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:23.946+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:23.978+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:23.978+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:23:23.998+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:23.998+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:23:23.915283+00:00, run_after=2023-01-30T15:23:23.915283+00:00
[2023-01-29T15:23:24.017+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.657 seconds
[2023-01-29T15:23:34.199+0000] {processor.py:153} INFO - Started process (PID=684) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:34.203+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:23:34.205+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:34.205+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:37.594+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:37.650+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:37.649+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:23:37.669+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:37.669+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:23:37.578067+00:00, run_after=2023-01-30T15:23:37.578067+00:00
[2023-01-29T15:23:37.682+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.490 seconds
[2023-01-29T15:23:47.979+0000] {processor.py:153} INFO - Started process (PID=690) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:47.985+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:23:47.988+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:47.987+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:51.439+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:23:51.465+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:51.465+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:23:51.481+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:23:51.481+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:23:51.430388+00:00, run_after=2023-01-30T15:23:51.430388+00:00
[2023-01-29T15:23:51.492+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.521 seconds
[2023-01-29T15:24:01.675+0000] {processor.py:153} INFO - Started process (PID=696) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:01.677+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:24:01.678+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:01.678+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:05.234+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:05.262+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:05.262+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:24:05.287+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:05.287+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:24:05.198791+00:00, run_after=2023-01-30T15:24:05.198791+00:00
[2023-01-29T15:24:05.300+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.631 seconds
[2023-01-29T15:24:15.603+0000] {processor.py:153} INFO - Started process (PID=702) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:15.606+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:24:15.607+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:15.607+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:18.987+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:19.074+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:19.073+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:24:19.095+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:19.094+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:24:18.970404+00:00, run_after=2023-01-30T15:24:18.970404+00:00
[2023-01-29T15:24:19.113+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.514 seconds
[2023-01-29T15:24:29.483+0000] {processor.py:153} INFO - Started process (PID=708) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:29.486+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:24:29.487+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:29.487+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:32.870+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:32.890+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:32.890+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:24:32.907+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:32.907+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:24:32.853232+00:00, run_after=2023-01-30T15:24:32.853232+00:00
[2023-01-29T15:24:32.920+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.442 seconds
[2023-01-29T15:24:43.080+0000] {processor.py:153} INFO - Started process (PID=714) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:43.082+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:24:43.083+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:43.083+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:47.295+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:47.338+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:47.338+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:24:47.358+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:47.358+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:24:47.261042+00:00, run_after=2023-01-30T15:24:47.261042+00:00
[2023-01-29T15:24:47.378+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.302 seconds
[2023-01-29T15:24:57.664+0000] {processor.py:153} INFO - Started process (PID=720) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:24:57.666+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:24:57.668+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:24:57.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:01.251+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:01.313+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:01.312+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:25:01.329+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:01.329+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:25:01.240506+00:00, run_after=2023-01-30T15:25:01.240506+00:00
[2023-01-29T15:25:01.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.683 seconds
[2023-01-29T15:25:11.606+0000] {processor.py:153} INFO - Started process (PID=726) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:11.609+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:25:11.610+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:11.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:15.542+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:15.581+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:15.580+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:25:15.610+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:15.610+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:25:15.499349+00:00, run_after=2023-01-30T15:25:15.499349+00:00
[2023-01-29T15:25:15.638+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.037 seconds
[2023-01-29T15:25:25.821+0000] {processor.py:153} INFO - Started process (PID=732) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:25.828+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:25:25.830+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:25.830+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:30.058+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:30.131+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:30.130+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:25:30.154+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:30.154+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:25:30.029495+00:00, run_after=2023-01-30T15:25:30.029495+00:00
[2023-01-29T15:25:30.179+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.365 seconds
[2023-01-29T15:25:40.502+0000] {processor.py:153} INFO - Started process (PID=738) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:40.505+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:25:40.507+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:40.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:44.087+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:44.181+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:44.180+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:25:44.208+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:44.208+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:25:44.071273+00:00, run_after=2023-01-30T15:25:44.071273+00:00
[2023-01-29T15:25:44.225+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.728 seconds
[2023-01-29T15:25:54.505+0000] {processor.py:153} INFO - Started process (PID=744) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:54.509+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:25:54.511+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:54.511+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:58.630+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:25:58.697+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:58.697+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:25:58.735+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:25:58.735+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:25:58.592940+00:00, run_after=2023-01-30T15:25:58.592940+00:00
[2023-01-29T15:25:58.759+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.260 seconds
[2023-01-29T15:26:09.028+0000] {processor.py:153} INFO - Started process (PID=750) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:09.031+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:26:09.032+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:09.032+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:12.624+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:12.687+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:12.687+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:26:12.720+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:12.719+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:26:12.582367+00:00, run_after=2023-01-30T15:26:12.582367+00:00
[2023-01-29T15:26:12.738+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.714 seconds
[2023-01-29T15:26:23.041+0000] {processor.py:153} INFO - Started process (PID=756) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:23.051+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:26:23.052+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:23.052+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:26.536+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:26.590+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:26.590+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:26:26.606+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:26.606+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:26:26.521034+00:00, run_after=2023-01-30T15:26:26.521034+00:00
[2023-01-29T15:26:26.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.585 seconds
[2023-01-29T15:26:36.886+0000] {processor.py:153} INFO - Started process (PID=762) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:36.889+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:26:36.890+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:36.890+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:40.376+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:40.396+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:40.396+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:26:40.430+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:40.430+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:26:40.344901+00:00, run_after=2023-01-30T15:26:40.344901+00:00
[2023-01-29T15:26:40.446+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.565 seconds
[2023-01-29T15:26:50.709+0000] {processor.py:153} INFO - Started process (PID=768) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:50.712+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:26:50.719+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:50.719+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:54.279+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:26:54.317+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:54.316+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:26:54.338+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:26:54.338+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:26:54.246057+00:00, run_after=2023-01-30T15:26:54.246057+00:00
[2023-01-29T15:26:54.357+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.651 seconds
[2023-01-29T15:27:04.712+0000] {processor.py:153} INFO - Started process (PID=774) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:04.715+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:27:04.717+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:04.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:08.646+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:08.746+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:08.745+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:27:08.775+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:08.775+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:27:08.613003+00:00, run_after=2023-01-30T15:27:08.613003+00:00
[2023-01-29T15:27:08.807+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.101 seconds
[2023-01-29T15:27:19.137+0000] {processor.py:153} INFO - Started process (PID=780) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:19.140+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:27:19.141+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:19.141+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:19.151+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:19.147+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:27:19.152+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:19.193+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.061 seconds
[2023-01-29T15:27:29.343+0000] {processor.py:153} INFO - Started process (PID=785) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:29.346+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:27:29.348+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:29.348+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:29.356+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:29.355+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:27:29.357+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:29.377+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.039 seconds
[2023-01-29T15:27:39.549+0000] {processor.py:153} INFO - Started process (PID=790) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:39.552+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:27:39.554+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:39.554+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:39.564+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:39.562+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:27:39.566+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:39.597+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.062 seconds
[2023-01-29T15:27:49.713+0000] {processor.py:153} INFO - Started process (PID=795) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:49.715+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:27:49.716+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:49.716+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:49.723+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:49.722+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:27:49.724+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:49.746+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.037 seconds
[2023-01-29T15:27:59.887+0000] {processor.py:153} INFO - Started process (PID=800) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:59.889+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:27:59.890+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:59.890+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:59.909+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:27:59.902+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:27:59.913+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:27:59.936+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.053 seconds
[2023-01-29T15:28:10.071+0000] {processor.py:153} INFO - Started process (PID=805) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:10.074+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:28:10.075+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:10.075+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:10.088+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:10.082+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:28:10.090+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:10.121+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.055 seconds
[2023-01-29T15:28:20.278+0000] {processor.py:153} INFO - Started process (PID=810) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:20.282+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:28:20.284+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:20.283+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:20.292+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:20.290+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:28:20.293+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:20.324+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.056 seconds
[2023-01-29T15:28:30.436+0000] {processor.py:153} INFO - Started process (PID=815) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:30.439+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:28:30.440+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:30.440+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:30.449+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:30.447+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:28:30.450+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:30.478+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.051 seconds
[2023-01-29T15:28:40.727+0000] {processor.py:153} INFO - Started process (PID=820) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:40.734+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:28:40.742+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:40.742+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:40.763+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:40.761+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 69
    data_extractor.store_data_in_mongo(raw_data, collection_name=*kwargs["job"])
                                                                 ^
SyntaxError: invalid syntax
[2023-01-29T15:28:40.775+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:40.854+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.137 seconds
[2023-01-29T15:28:44.850+0000] {processor.py:153} INFO - Started process (PID=825) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:44.853+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:28:44.855+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:44.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:49.053+0000] {processor.py:753} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:49.143+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:49.142+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:28:49.161+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:49.161+0000] {dag.py:3441} INFO - Setting next_dagrun for etl_pipeline to 2023-01-29T15:28:49.022841+00:00, run_after=2023-01-30T15:28:49.022841+00:00
[2023-01-29T15:28:49.195+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.352 seconds
[2023-01-29T15:28:52.112+0000] {processor.py:153} INFO - Started process (PID=831) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:52.116+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:28:52.125+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:52.125+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:56.996+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:28:57.402+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:57.402+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:data_pipeline
[2023-01-29T15:28:57.429+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:57.428+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:data_pipeline
[2023-01-29T15:28:57.438+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:57.438+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:data_pipeline
[2023-01-29T15:28:57.439+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:57.439+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:28:57.450+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:57.449+0000] {dag.py:2711} INFO - Creating ORM DAG for data_pipeline
[2023-01-29T15:28:57.465+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:28:57.465+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:28:56.960443+00:00, run_after=2023-01-30T15:28:56.960443+00:00
[2023-01-29T15:28:57.490+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.386 seconds
[2023-01-29T15:29:07.884+0000] {processor.py:153} INFO - Started process (PID=837) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:07.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:29:07.889+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:07.888+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:14.483+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:14.526+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:14.525+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:29:14.562+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:14.562+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:29:14.444782+00:00, run_after=2023-01-30T15:29:14.444782+00:00
[2023-01-29T15:29:14.588+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.713 seconds
[2023-01-29T15:29:24.991+0000] {processor.py:153} INFO - Started process (PID=843) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:24.995+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:29:24.997+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:24.997+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:29.817+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:29.895+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:29.894+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:29:29.917+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:29.917+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:29:29.801015+00:00, run_after=2023-01-30T15:29:29.801015+00:00
[2023-01-29T15:29:29.934+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.955 seconds
[2023-01-29T15:29:40.279+0000] {processor.py:153} INFO - Started process (PID=849) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:40.283+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:29:40.285+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:40.285+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:45.075+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:45.128+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:45.128+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:29:45.158+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:45.158+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:29:45.035658+00:00, run_after=2023-01-30T15:29:45.035658+00:00
[2023-01-29T15:29:45.173+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.900 seconds
[2023-01-29T15:29:55.660+0000] {processor.py:153} INFO - Started process (PID=855) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:29:55.666+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:29:55.669+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:29:55.669+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:00.833+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:00.944+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:00.943+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:30:00.963+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:00.963+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:30:00.797661+00:00, run_after=2023-01-30T15:30:00.797661+00:00
[2023-01-29T15:30:00.985+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.337 seconds
[2023-01-29T15:30:11.394+0000] {processor.py:153} INFO - Started process (PID=861) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:11.398+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:30:11.402+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:11.401+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:15.160+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:15.187+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:15.187+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:30:15.207+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:15.206+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:30:15.124791+00:00, run_after=2023-01-30T15:30:15.124791+00:00
[2023-01-29T15:30:15.220+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.831 seconds
[2023-01-29T15:30:25.545+0000] {processor.py:153} INFO - Started process (PID=867) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:25.551+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:30:25.569+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:25.569+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:29.975+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:30.016+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:30.016+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:30:30.045+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:30.045+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:30:29.941610+00:00, run_after=2023-01-30T15:30:29.941610+00:00
[2023-01-29T15:30:30.066+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.525 seconds
[2023-01-29T15:30:40.414+0000] {processor.py:153} INFO - Started process (PID=873) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:40.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:30:40.417+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:40.417+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:44.653+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:44.736+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:44.735+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:30:44.754+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:44.754+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:30:44.629071+00:00, run_after=2023-01-30T15:30:44.629071+00:00
[2023-01-29T15:30:44.775+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.366 seconds
[2023-01-29T15:30:55.129+0000] {processor.py:153} INFO - Started process (PID=879) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:55.132+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:30:55.134+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:55.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:59.597+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:30:59.627+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:59.627+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:30:59.646+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:30:59.646+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:30:59.583863+00:00, run_after=2023-01-30T15:30:59.583863+00:00
[2023-01-29T15:30:59.662+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.546 seconds
[2023-01-29T15:31:09.961+0000] {processor.py:153} INFO - Started process (PID=885) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:09.965+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:31:09.967+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:09.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:14.723+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:14.800+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:14.799+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:31:14.823+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:14.823+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:31:14.690168+00:00, run_after=2023-01-30T15:31:14.690168+00:00
[2023-01-29T15:31:14.845+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.891 seconds
[2023-01-29T15:31:25.205+0000] {processor.py:153} INFO - Started process (PID=891) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:25.207+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:31:25.209+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:25.209+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:29.199+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:29.240+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:29.240+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:31:29.271+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:29.271+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:31:29.172415+00:00, run_after=2023-01-30T15:31:29.172415+00:00
[2023-01-29T15:31:29.293+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.093 seconds
[2023-01-29T15:31:39.599+0000] {processor.py:153} INFO - Started process (PID=902) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:39.602+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:31:39.604+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:39.604+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:45.130+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:45.187+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:45.187+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:31:45.203+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:45.203+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:31:45.109544+00:00, run_after=2023-01-30T15:31:45.109544+00:00
[2023-01-29T15:31:45.216+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.622 seconds
[2023-01-29T15:31:55.504+0000] {processor.py:153} INFO - Started process (PID=908) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:55.507+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:31:55.508+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:55.508+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:59.219+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:31:59.241+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:59.241+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:31:59.268+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:31:59.268+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:31:59.198810+00:00, run_after=2023-01-30T15:31:59.198810+00:00
[2023-01-29T15:31:59.282+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.788 seconds
[2023-01-29T15:32:09.662+0000] {processor.py:153} INFO - Started process (PID=914) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:09.664+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:32:09.666+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:09.665+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:13.253+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:13.319+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:13.318+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:32:13.352+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:13.352+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:32:13.219426+00:00, run_after=2023-01-30T15:32:13.219426+00:00
[2023-01-29T15:32:13.373+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.716 seconds
[2023-01-29T15:32:23.754+0000] {processor.py:153} INFO - Started process (PID=920) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:23.756+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:32:23.758+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:23.757+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:27.441+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:27.489+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:27.489+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:32:27.503+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:27.503+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:32:27.433519+00:00, run_after=2023-01-30T15:32:27.433519+00:00
[2023-01-29T15:32:27.515+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.767 seconds
[2023-01-29T15:32:37.812+0000] {processor.py:153} INFO - Started process (PID=926) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:37.816+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:32:37.818+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:37.818+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:41.370+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:41.388+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:41.388+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:32:41.414+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:41.414+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:32:41.351962+00:00, run_after=2023-01-30T15:32:41.351962+00:00
[2023-01-29T15:32:41.428+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.622 seconds
[2023-01-29T15:32:51.705+0000] {processor.py:153} INFO - Started process (PID=932) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:51.707+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:32:51.708+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:51.708+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:55.843+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:32:55.879+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:55.878+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:32:55.907+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:32:55.906+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:32:55.814684+00:00, run_after=2023-01-30T15:32:55.814684+00:00
[2023-01-29T15:32:55.921+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.220 seconds
[2023-01-29T15:33:06.239+0000] {processor.py:153} INFO - Started process (PID=938) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:06.241+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:33:06.242+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:06.242+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:09.897+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:09.972+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:09.971+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:33:09.987+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:09.987+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:33:09.884344+00:00, run_after=2023-01-30T15:33:09.884344+00:00
[2023-01-29T15:33:10.000+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.766 seconds
[2023-01-29T15:33:20.219+0000] {processor.py:153} INFO - Started process (PID=944) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:20.221+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:33:20.222+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:20.222+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:23.808+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:23.832+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:23.832+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:33:23.851+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:23.851+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:33:23.786512+00:00, run_after=2023-01-30T15:33:23.786512+00:00
[2023-01-29T15:33:23.864+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.649 seconds
[2023-01-29T15:33:34.210+0000] {processor.py:153} INFO - Started process (PID=950) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:34.212+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:33:34.214+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:34.214+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:37.854+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:37.875+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:37.874+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:33:37.899+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:37.899+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:33:37.835147+00:00, run_after=2023-01-30T15:33:37.835147+00:00
[2023-01-29T15:33:37.912+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.709 seconds
[2023-01-29T15:33:48.309+0000] {processor.py:153} INFO - Started process (PID=956) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:48.317+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:33:48.318+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:48.318+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:51.996+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:33:52.055+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:52.054+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:33:52.084+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:33:52.084+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:33:51.985696+00:00, run_after=2023-01-30T15:33:51.985696+00:00
[2023-01-29T15:33:52.098+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.795 seconds
[2023-01-29T15:34:02.419+0000] {processor.py:153} INFO - Started process (PID=962) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:02.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:34:02.422+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:02.422+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:06.068+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:06.089+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:06.089+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:34:06.122+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:06.121+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:34:06.039147+00:00, run_after=2023-01-30T15:34:06.039147+00:00
[2023-01-29T15:34:06.139+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.726 seconds
[2023-01-29T15:34:16.448+0000] {processor.py:153} INFO - Started process (PID=968) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:16.450+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:34:16.451+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:16.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:20.191+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:20.220+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:20.220+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:34:20.236+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:20.236+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:34:20.175740+00:00, run_after=2023-01-30T15:34:20.175740+00:00
[2023-01-29T15:34:20.250+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.807 seconds
[2023-01-29T15:34:30.509+0000] {processor.py:153} INFO - Started process (PID=974) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:30.511+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:34:30.512+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:30.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:34.198+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:34.263+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:34.263+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:34:34.280+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:34.280+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:34:34.180135+00:00, run_after=2023-01-30T15:34:34.180135+00:00
[2023-01-29T15:34:34.293+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.789 seconds
[2023-01-29T15:34:44.619+0000] {processor.py:153} INFO - Started process (PID=980) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:44.622+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:34:44.624+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:44.623+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:48.407+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:48.440+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:48.439+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:34:48.461+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:48.461+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:34:48.374132+00:00, run_after=2023-01-30T15:34:48.374132+00:00
[2023-01-29T15:34:48.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.865 seconds
[2023-01-29T15:34:58.787+0000] {processor.py:153} INFO - Started process (PID=986) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:34:58.790+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:34:58.797+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:34:58.796+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:02.413+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:02.434+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:02.433+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:35:02.452+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:02.452+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:35:02.385308+00:00, run_after=2023-01-30T15:35:02.385308+00:00
[2023-01-29T15:35:02.465+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.681 seconds
[2023-01-29T15:35:12.823+0000] {processor.py:153} INFO - Started process (PID=992) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:12.826+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:35:12.831+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:12.831+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:16.584+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:16.638+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:16.637+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:35:16.654+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:16.654+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:35:16.562570+00:00, run_after=2023-01-30T15:35:16.562570+00:00
[2023-01-29T15:35:16.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.850 seconds
[2023-01-29T15:35:26.954+0000] {processor.py:153} INFO - Started process (PID=998) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:26.963+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:35:26.965+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:26.965+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:30.581+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:30.613+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:30.612+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:35:30.646+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:30.645+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:35:30.546475+00:00, run_after=2023-01-30T15:35:30.546475+00:00
[2023-01-29T15:35:30.669+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.720 seconds
[2023-01-29T15:35:41.014+0000] {processor.py:153} INFO - Started process (PID=1004) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:41.016+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:35:41.017+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:41.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:44.623+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:44.648+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:44.647+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:35:44.671+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:44.670+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:35:44.605159+00:00, run_after=2023-01-30T15:35:44.605159+00:00
[2023-01-29T15:35:44.685+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.675 seconds
[2023-01-29T15:35:54.976+0000] {processor.py:153} INFO - Started process (PID=1010) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:54.980+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:35:54.981+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:54.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:58.803+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:35:58.863+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:58.862+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:35:58.878+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:35:58.878+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:35:58.771744+00:00, run_after=2023-01-30T15:35:58.771744+00:00
[2023-01-29T15:35:58.899+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.929 seconds
[2023-01-29T15:36:09.200+0000] {processor.py:153} INFO - Started process (PID=1016) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:09.203+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:36:09.204+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:09.204+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:12.784+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:12.832+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:12.830+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:36:12.867+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:12.867+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:36:12.758448+00:00, run_after=2023-01-30T15:36:12.758448+00:00
[2023-01-29T15:36:12.882+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.687 seconds
[2023-01-29T15:36:23.331+0000] {processor.py:153} INFO - Started process (PID=1022) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:23.333+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:36:23.338+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:23.337+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:26.968+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:26.989+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:26.989+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:36:27.006+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:27.006+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:36:26.960057+00:00, run_after=2023-01-30T15:36:26.960057+00:00
[2023-01-29T15:36:27.021+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.695 seconds
[2023-01-29T15:36:37.268+0000] {processor.py:153} INFO - Started process (PID=1033) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:37.272+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:36:37.274+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:37.273+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:40.776+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:40.836+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:40.836+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:36:40.852+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:40.852+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:36:40.750370+00:00, run_after=2023-01-30T15:36:40.750370+00:00
[2023-01-29T15:36:40.873+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.612 seconds
[2023-01-29T15:36:51.108+0000] {processor.py:153} INFO - Started process (PID=1039) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:51.111+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:36:51.112+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:51.112+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:54.822+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:36:54.849+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:54.848+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:36:54.866+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:36:54.866+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:36:54.811005+00:00, run_after=2023-01-30T15:36:54.811005+00:00
[2023-01-29T15:36:54.879+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.779 seconds
[2023-01-29T15:37:05.164+0000] {processor.py:153} INFO - Started process (PID=1045) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:05.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:37:05.176+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:05.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:10.967+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:11.066+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:11.066+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:37:11.094+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:11.094+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:37:10.934690+00:00, run_after=2023-01-30T15:37:10.934690+00:00
[2023-01-29T15:37:11.113+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.952 seconds
[2023-01-29T15:37:21.429+0000] {processor.py:153} INFO - Started process (PID=1051) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:21.439+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:37:21.441+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:21.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:26.290+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:26.368+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:26.367+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:37:26.414+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:26.414+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:37:26.246437+00:00, run_after=2023-01-30T15:37:26.246437+00:00
[2023-01-29T15:37:26.445+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.026 seconds
[2023-01-29T15:37:36.890+0000] {processor.py:153} INFO - Started process (PID=1057) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:36.892+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:37:36.894+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:36.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:41.064+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:41.142+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:41.141+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:37:41.165+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:41.165+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:37:41.032645+00:00, run_after=2023-01-30T15:37:41.032645+00:00
[2023-01-29T15:37:41.180+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.295 seconds
[2023-01-29T15:37:51.564+0000] {processor.py:153} INFO - Started process (PID=1063) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:51.567+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:37:51.568+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:51.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:56.119+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:37:56.156+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:56.156+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:37:56.187+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:37:56.187+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:37:56.079052+00:00, run_after=2023-01-30T15:37:56.079052+00:00
[2023-01-29T15:37:56.202+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.642 seconds
[2023-01-29T15:38:06.553+0000] {processor.py:153} INFO - Started process (PID=1069) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:06.555+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:38:06.556+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:06.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:10.176+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:10.203+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:10.203+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:38:10.224+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:10.224+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:38:10.167745+00:00, run_after=2023-01-30T15:38:10.167745+00:00
[2023-01-29T15:38:10.236+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.688 seconds
[2023-01-29T15:38:20.435+0000] {processor.py:153} INFO - Started process (PID=1075) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:20.438+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:38:20.439+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:20.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:24.699+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:24.783+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:24.782+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:38:24.800+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:24.800+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:38:24.675437+00:00, run_after=2023-01-30T15:38:24.675437+00:00
[2023-01-29T15:38:24.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.386 seconds
[2023-01-29T15:38:35.229+0000] {processor.py:153} INFO - Started process (PID=1081) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:35.231+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:38:35.232+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:35.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:39.390+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:39.453+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:39.453+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:38:39.497+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:39.497+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:38:39.357966+00:00, run_after=2023-01-30T15:38:39.357966+00:00
[2023-01-29T15:38:39.515+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.291 seconds
[2023-01-29T15:38:49.970+0000] {processor.py:153} INFO - Started process (PID=1087) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:49.973+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:38:49.980+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:49.980+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:54.237+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:38:54.313+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:54.312+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:38:54.348+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:38:54.347+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:38:54.193591+00:00, run_after=2023-01-30T15:38:54.193591+00:00
[2023-01-29T15:38:54.400+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.435 seconds
[2023-01-29T15:39:05.017+0000] {processor.py:153} INFO - Started process (PID=1095) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:05.022+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:39:05.024+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:05.024+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:09.307+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:09.404+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:09.403+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:39:09.425+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:09.425+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:39:09.281649+00:00, run_after=2023-01-30T15:39:09.281649+00:00
[2023-01-29T15:39:09.442+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.439 seconds
[2023-01-29T15:39:19.799+0000] {processor.py:153} INFO - Started process (PID=1104) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:19.803+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:39:19.805+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:19.805+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:23.540+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:23.558+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:23.557+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:39:23.582+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:23.581+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:39:23.522107+00:00, run_after=2023-01-30T15:39:23.522107+00:00
[2023-01-29T15:39:23.595+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.804 seconds
[2023-01-29T15:39:33.818+0000] {processor.py:153} INFO - Started process (PID=1110) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:33.821+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:39:33.822+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:33.822+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:37.353+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:37.376+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:37.376+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:39:37.395+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:37.395+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:39:37.344057+00:00, run_after=2023-01-30T15:39:37.344057+00:00
[2023-01-29T15:39:37.407+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.594 seconds
[2023-01-29T15:39:47.648+0000] {processor.py:153} INFO - Started process (PID=1116) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:47.653+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:39:47.655+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:47.654+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:51.262+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:39:51.304+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:51.304+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:39:51.319+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:39:51.319+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:39:51.246355+00:00, run_after=2023-01-30T15:39:51.246355+00:00
[2023-01-29T15:39:51.332+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.690 seconds
[2023-01-29T15:40:01.583+0000] {processor.py:153} INFO - Started process (PID=1122) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:01.586+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:40:01.588+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:01.588+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:05.229+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:05.261+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:05.261+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:40:05.282+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:05.281+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:40:05.205216+00:00, run_after=2023-01-30T15:40:05.205216+00:00
[2023-01-29T15:40:05.301+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.725 seconds
[2023-01-29T15:40:15.559+0000] {processor.py:153} INFO - Started process (PID=1128) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:15.562+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:40:15.563+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:15.563+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:19.023+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:19.061+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:19.061+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:40:19.077+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:19.077+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:40:19.016955+00:00, run_after=2023-01-30T15:40:19.016955+00:00
[2023-01-29T15:40:19.094+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.550 seconds
[2023-01-29T15:40:29.323+0000] {processor.py:153} INFO - Started process (PID=1134) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:29.326+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:40:29.327+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:29.327+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:33.084+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:33.172+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:33.172+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:40:33.188+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:33.188+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:40:33.069104+00:00, run_after=2023-01-30T15:40:33.069104+00:00
[2023-01-29T15:40:33.201+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.884 seconds
[2023-01-29T15:40:43.483+0000] {processor.py:153} INFO - Started process (PID=1140) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:43.487+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:40:43.489+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:43.489+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:47.151+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:47.183+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:47.182+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:40:47.220+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:47.220+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:40:47.114119+00:00, run_after=2023-01-30T15:40:47.114119+00:00
[2023-01-29T15:40:47.235+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.761 seconds
[2023-01-29T15:40:57.592+0000] {processor.py:153} INFO - Started process (PID=1146) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:40:57.595+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:40:57.596+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:40:57.596+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:01.293+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:01.345+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:01.345+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:41:01.376+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:01.376+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:41:01.259701+00:00, run_after=2023-01-30T15:41:01.259701+00:00
[2023-01-29T15:41:01.396+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.815 seconds
[2023-01-29T15:41:11.854+0000] {processor.py:153} INFO - Started process (PID=1152) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:11.858+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:41:11.860+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:11.860+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:15.994+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:16.093+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:16.093+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:41:16.118+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:16.118+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:41:15.975496+00:00, run_after=2023-01-30T15:41:15.975496+00:00
[2023-01-29T15:41:16.132+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.289 seconds
[2023-01-29T15:41:26.501+0000] {processor.py:153} INFO - Started process (PID=1158) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:26.504+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:41:26.506+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:26.506+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:30.843+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:30.875+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:30.875+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:41:30.903+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:30.903+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:41:30.817120+00:00, run_after=2023-01-30T15:41:30.817120+00:00
[2023-01-29T15:41:30.917+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.429 seconds
[2023-01-29T15:41:41.228+0000] {processor.py:153} INFO - Started process (PID=1164) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:41.231+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:41:41.232+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:41.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:44.989+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:45.032+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:45.031+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:41:45.054+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:45.054+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:41:44.962304+00:00, run_after=2023-01-30T15:41:44.962304+00:00
[2023-01-29T15:41:45.069+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.849 seconds
[2023-01-29T15:41:55.454+0000] {processor.py:153} INFO - Started process (PID=1170) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:55.461+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:41:55.464+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:55.464+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:59.710+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:41:59.775+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:59.775+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:41:59.795+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:41:59.795+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:41:59.691186+00:00, run_after=2023-01-30T15:41:59.691186+00:00
[2023-01-29T15:41:59.810+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.362 seconds
[2023-01-29T15:42:10.029+0000] {processor.py:153} INFO - Started process (PID=1176) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:10.032+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:42:10.034+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:10.034+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:13.570+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:13.595+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:13.594+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:42:13.621+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:13.621+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:42:13.535404+00:00, run_after=2023-01-30T15:42:13.535404+00:00
[2023-01-29T15:42:13.640+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.624 seconds
[2023-01-29T15:42:23.936+0000] {processor.py:153} INFO - Started process (PID=1182) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:23.938+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:42:23.940+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:23.940+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:28.077+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:28.128+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:28.127+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:42:28.157+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:28.157+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:42:28.048284+00:00, run_after=2023-01-30T15:42:28.048284+00:00
[2023-01-29T15:42:28.193+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.264 seconds
[2023-01-29T15:42:38.518+0000] {processor.py:153} INFO - Started process (PID=1188) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:38.521+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:42:38.524+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:38.523+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:42.437+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:42.532+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:42.532+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:42:42.552+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:42.552+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:42:42.409667+00:00, run_after=2023-01-30T15:42:42.409667+00:00
[2023-01-29T15:42:42.568+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.063 seconds
[2023-01-29T15:42:52.835+0000] {processor.py:153} INFO - Started process (PID=1194) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:52.840+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:42:52.844+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:52.844+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:57.151+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:42:57.202+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:57.201+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:42:57.227+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:42:57.227+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:42:57.118322+00:00, run_after=2023-01-30T15:42:57.118322+00:00
[2023-01-29T15:42:57.250+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.421 seconds
[2023-01-29T15:43:07.566+0000] {processor.py:153} INFO - Started process (PID=1200) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:07.568+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:43:07.569+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:07.569+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:11.049+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:11.066+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:11.065+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:43:11.082+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:11.082+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:43:11.040138+00:00, run_after=2023-01-30T15:43:11.040138+00:00
[2023-01-29T15:43:11.093+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.535 seconds
[2023-01-29T15:43:21.341+0000] {processor.py:153} INFO - Started process (PID=1206) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:21.345+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:43:21.347+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:21.346+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:25.458+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:25.533+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:25.532+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:43:25.559+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:25.559+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:43:25.421751+00:00, run_after=2023-01-30T15:43:25.421751+00:00
[2023-01-29T15:43:25.577+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.243 seconds
[2023-01-29T15:43:35.878+0000] {processor.py:153} INFO - Started process (PID=1212) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:35.881+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:43:35.883+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:35.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:39.775+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:39.801+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:39.800+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:43:39.833+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:39.833+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:43:39.735937+00:00, run_after=2023-01-30T15:43:39.735937+00:00
[2023-01-29T15:43:39.847+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.976 seconds
[2023-01-29T15:43:50.112+0000] {processor.py:153} INFO - Started process (PID=1218) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:50.115+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:43:50.116+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:50.116+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:53.783+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:43:53.818+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:53.817+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:43:53.837+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:43:53.837+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:43:53.764536+00:00, run_after=2023-01-30T15:43:53.764536+00:00
[2023-01-29T15:43:53.852+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.745 seconds
[2023-01-29T15:44:04.189+0000] {processor.py:153} INFO - Started process (PID=1224) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:04.198+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:44:04.201+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:04.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:08.005+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:08.072+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:08.072+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:44:08.089+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:08.089+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:44:07.984718+00:00, run_after=2023-01-30T15:44:07.984718+00:00
[2023-01-29T15:44:08.103+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.923 seconds
[2023-01-29T15:44:18.385+0000] {processor.py:153} INFO - Started process (PID=1230) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:18.388+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:44:18.390+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:18.390+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:22.475+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:22.506+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:22.505+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:44:22.529+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:22.529+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T15:44:22.447008+00:00, run_after=2023-01-30T15:44:22.447008+00:00
[2023-01-29T15:44:22.542+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.161 seconds
[2023-01-29T15:44:30.021+0000] {processor.py:153} INFO - Started process (PID=1236) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:30.026+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:44:30.033+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:30.030+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:35.804+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:35.934+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:35.934+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:data_pipeline_1
[2023-01-29T15:44:35.943+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:35.943+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:data_pipeline_1
[2023-01-29T15:44:35.948+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:35.948+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:data_pipeline_1
[2023-01-29T15:44:35.950+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:35.950+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:44:35.976+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:35.975+0000] {dag.py:2711} INFO - Creating ORM DAG for data_pipeline_1
[2023-01-29T15:44:35.983+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:35.983+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:44:35.790819+00:00, run_after=2023-01-30T15:44:35.790819+00:00
[2023-01-29T15:44:35.998+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.993 seconds
[2023-01-29T15:44:46.264+0000] {processor.py:153} INFO - Started process (PID=1242) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:46.267+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:44:46.269+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:46.269+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:53.480+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:44:53.682+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:53.682+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:44:53.793+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:44:53.793+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:44:53.409595+00:00, run_after=2023-01-30T15:44:53.409595+00:00
[2023-01-29T15:44:53.850+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.591 seconds
[2023-01-29T15:45:04.673+0000] {processor.py:153} INFO - Started process (PID=1253) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:04.682+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:45:04.685+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:04.685+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:08.974+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:09.064+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:09.063+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:45:09.083+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:09.083+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:45:08.948110+00:00, run_after=2023-01-30T15:45:08.948110+00:00
[2023-01-29T15:45:09.099+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.433 seconds
[2023-01-29T15:45:19.447+0000] {processor.py:153} INFO - Started process (PID=1259) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:19.453+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:45:19.456+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:19.456+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:23.527+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:23.569+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:23.569+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:45:23.593+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:23.593+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:45:23.500110+00:00, run_after=2023-01-30T15:45:23.500110+00:00
[2023-01-29T15:45:23.612+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.177 seconds
[2023-01-29T15:45:34.038+0000] {processor.py:153} INFO - Started process (PID=1265) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:34.041+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:45:34.045+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:34.045+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:42.935+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:43.026+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:43.025+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:45:43.045+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:43.045+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:45:42.895418+00:00, run_after=2023-01-30T15:45:42.895418+00:00
[2023-01-29T15:45:43.061+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.041 seconds
[2023-01-29T15:45:53.589+0000] {processor.py:153} INFO - Started process (PID=1271) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:53.592+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:45:53.593+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:53.593+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:59.651+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:45:59.709+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:59.707+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:45:59.773+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:45:59.773+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:45:59.616646+00:00, run_after=2023-01-30T15:45:59.616646+00:00
[2023-01-29T15:45:59.802+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.219 seconds
[2023-01-29T15:46:10.276+0000] {processor.py:153} INFO - Started process (PID=1277) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:10.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:46:10.279+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:10.279+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:20.667+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:20.785+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:20.785+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:46:20.809+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:20.809+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:46:20.613483+00:00, run_after=2023-01-30T15:46:20.613483+00:00
[2023-01-29T15:46:20.830+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.561 seconds
[2023-01-29T15:46:31.253+0000] {processor.py:153} INFO - Started process (PID=1283) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:31.257+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:46:31.262+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:31.262+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:36.152+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:36.219+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:36.219+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:46:36.274+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:36.274+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:46:36.111108+00:00, run_after=2023-01-30T15:46:36.111108+00:00
[2023-01-29T15:46:36.296+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.050 seconds
[2023-01-29T15:46:46.754+0000] {processor.py:153} INFO - Started process (PID=1289) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:46.759+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:46:46.760+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:46.760+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:51.990+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:46:52.102+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:52.102+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:46:52.127+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:46:52.127+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:46:51.960300+00:00, run_after=2023-01-30T15:46:51.960300+00:00
[2023-01-29T15:46:52.143+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.404 seconds
[2023-01-29T15:47:02.596+0000] {processor.py:153} INFO - Started process (PID=1295) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:02.600+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:47:02.602+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:02.602+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:09.933+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:09.994+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:09.993+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:47:10.036+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:10.035+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:47:09.881736+00:00, run_after=2023-01-30T15:47:09.881736+00:00
[2023-01-29T15:47:10.062+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.482 seconds
[2023-01-29T15:47:20.560+0000] {processor.py:153} INFO - Started process (PID=1301) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:20.563+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:47:20.565+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:20.565+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:26.586+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:26.684+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:26.683+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:47:26.711+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:26.711+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:47:26.542591+00:00, run_after=2023-01-30T15:47:26.542591+00:00
[2023-01-29T15:47:26.731+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.184 seconds
[2023-01-29T15:47:37.376+0000] {processor.py:153} INFO - Started process (PID=1307) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:37.383+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:47:37.385+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:37.385+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:42.082+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:42.134+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:42.134+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:47:42.172+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:42.172+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:47:42.042298+00:00, run_after=2023-01-30T15:47:42.042298+00:00
[2023-01-29T15:47:42.187+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.819 seconds
[2023-01-29T15:47:52.676+0000] {processor.py:153} INFO - Started process (PID=1313) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:52.679+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:47:52.680+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:52.680+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:58.087+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:47:58.193+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:58.192+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:47:58.219+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:47:58.219+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:47:58.052195+00:00, run_after=2023-01-30T15:47:58.052195+00:00
[2023-01-29T15:47:58.239+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.568 seconds
[2023-01-29T15:48:08.700+0000] {processor.py:153} INFO - Started process (PID=1319) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:08.703+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:48:08.704+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:08.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:13.171+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:13.217+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:13.216+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:48:13.247+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:13.247+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:48:13.133832+00:00, run_after=2023-01-30T15:48:13.133832+00:00
[2023-01-29T15:48:13.265+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.572 seconds
[2023-01-29T15:48:23.700+0000] {processor.py:153} INFO - Started process (PID=1325) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:23.702+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:48:23.704+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:23.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:28.337+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:28.424+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:28.423+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:48:28.447+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:28.447+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:48:28.302673+00:00, run_after=2023-01-30T15:48:28.302673+00:00
[2023-01-29T15:48:28.464+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.778 seconds
[2023-01-29T15:48:38.876+0000] {processor.py:153} INFO - Started process (PID=1331) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:38.879+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:48:38.880+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:38.880+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:43.480+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:43.533+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:43.532+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:48:43.579+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:43.579+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:48:43.407370+00:00, run_after=2023-01-30T15:48:43.407370+00:00
[2023-01-29T15:48:43.602+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.732 seconds
[2023-01-29T15:48:54.068+0000] {processor.py:153} INFO - Started process (PID=1337) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:54.070+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:48:54.072+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:54.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:58.593+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:48:58.718+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:58.717+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:48:58.738+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:48:58.738+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:48:58.516202+00:00, run_after=2023-01-30T15:48:58.516202+00:00
[2023-01-29T15:48:58.765+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.708 seconds
[2023-01-29T15:49:09.274+0000] {processor.py:153} INFO - Started process (PID=1343) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:09.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:49:09.281+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:09.280+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:14.554+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:14.603+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:14.603+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:49:14.649+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:14.649+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:49:14.477565+00:00, run_after=2023-01-30T15:49:14.477565+00:00
[2023-01-29T15:49:14.670+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.410 seconds
[2023-01-29T15:49:25.235+0000] {processor.py:153} INFO - Started process (PID=1349) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:25.237+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:49:25.238+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:25.238+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:29.761+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:29.880+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:29.879+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:49:29.907+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:29.907+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:49:29.715163+00:00, run_after=2023-01-30T15:49:29.715163+00:00
[2023-01-29T15:49:29.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.702 seconds
[2023-01-29T15:49:40.430+0000] {processor.py:153} INFO - Started process (PID=1355) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:40.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:49:40.438+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:40.438+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:45.379+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:45.475+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:45.475+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:49:45.527+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:45.527+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:49:45.341738+00:00, run_after=2023-01-30T15:49:45.341738+00:00
[2023-01-29T15:49:45.549+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 5.130 seconds
[2023-01-29T15:49:56.316+0000] {processor.py:153} INFO - Started process (PID=1361) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:49:56.321+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:49:56.325+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:49:56.324+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:00.742+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:00.825+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:00.825+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:50:00.844+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:00.844+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:50:00.717986+00:00, run_after=2023-01-30T15:50:00.717986+00:00
[2023-01-29T15:50:00.863+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.555 seconds
[2023-01-29T15:50:11.223+0000] {processor.py:153} INFO - Started process (PID=1367) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:11.229+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:50:11.231+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:11.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:15.177+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:15.213+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:15.212+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:50:15.238+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:15.238+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:50:15.144093+00:00, run_after=2023-01-30T15:50:15.144093+00:00
[2023-01-29T15:50:15.262+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 4.046 seconds
[2023-01-29T15:50:25.642+0000] {processor.py:153} INFO - Started process (PID=1373) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:25.645+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:50:25.646+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:25.646+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:29.551+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:29.579+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:29.578+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T15:50:29.599+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:29.599+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T15:50:29.523134+00:00, run_after=2023-01-30T15:50:29.523134+00:00
[2023-01-29T15:50:29.614+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 3.978 seconds
[2023-01-29T15:50:39.968+0000] {processor.py:153} INFO - Started process (PID=1379) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T15:50:39.971+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T15:50:39.973+0000] {logging_mixin.py:137} INFO - [2023-01-29T15:50:39.972+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:26.436+0000] {processor.py:153} INFO - Started process (PID=164) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:26.450+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:40:26.456+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:26.456+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:27.292+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:27.359+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:27.359+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:40:27.457+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:27.457+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:40:27.154485+00:00, run_after=2023-01-30T19:40:27.154485+00:00
[2023-01-29T19:40:27.516+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.085 seconds
[2023-01-29T19:40:37.687+0000] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:37.695+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:40:37.696+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:37.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:37.936+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:37.957+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:37.957+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:40:38.004+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:38.004+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:40:37.918119+00:00, run_after=2023-01-30T19:40:37.918119+00:00
[2023-01-29T19:40:38.051+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.378 seconds
[2023-01-29T19:40:48.177+0000] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:48.178+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:40:48.179+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:48.179+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:48.330+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:48.457+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:48.457+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:40:48.507+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:48.506+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:40:48.315007+00:00, run_after=2023-01-30T19:40:48.315007+00:00
[2023-01-29T19:40:48.530+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.357 seconds
[2023-01-29T19:40:58.617+0000] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:58.619+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:40:58.620+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:58.620+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:58.779+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:40:58.816+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:58.814+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:40:58.888+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:40:58.887+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:40:58.765000+00:00, run_after=2023-01-30T19:40:58.765000+00:00
[2023-01-29T19:40:58.917+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.306 seconds
[2023-01-29T19:41:09.007+0000] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:09.009+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:41:09.010+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:09.010+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:09.162+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:09.181+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:09.181+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:41:09.239+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:09.239+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:41:09.150189+00:00, run_after=2023-01-30T19:41:09.150189+00:00
[2023-01-29T19:41:09.278+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.282 seconds
[2023-01-29T19:41:19.370+0000] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:19.371+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:41:19.372+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:19.372+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:19.498+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:19.571+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:19.570+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:41:19.598+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:19.598+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:41:19.488698+00:00, run_after=2023-01-30T19:41:19.488698+00:00
[2023-01-29T19:41:19.621+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.256 seconds
[2023-01-29T19:41:29.700+0000] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:29.701+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:41:29.702+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:29.702+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:29.813+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:29.829+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:29.829+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:41:29.858+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:29.857+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:41:29.804014+00:00, run_after=2023-01-30T19:41:29.804014+00:00
[2023-01-29T19:41:29.880+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.185 seconds
[2023-01-29T19:41:39.955+0000] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:39.956+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:41:39.956+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:39.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:40.071+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:40.088+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:40.088+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:41:40.120+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:40.120+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:41:40.061358+00:00, run_after=2023-01-30T19:41:40.061358+00:00
[2023-01-29T19:41:40.141+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.191 seconds
[2023-01-29T19:41:50.218+0000] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:50.219+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:41:50.220+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:50.220+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:50.331+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:41:50.434+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:50.434+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:41:50.465+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:41:50.465+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:41:50.321358+00:00, run_after=2023-01-30T19:41:50.321358+00:00
[2023-01-29T19:41:50.510+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.297 seconds
[2023-01-29T19:42:00.626+0000] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:00.627+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:42:00.628+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:00.628+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:00.782+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:00.798+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:00.798+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:42:00.841+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:00.841+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:42:00.772201+00:00, run_after=2023-01-30T19:42:00.772201+00:00
[2023-01-29T19:42:00.864+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.244 seconds
[2023-01-29T19:42:10.941+0000] {processor.py:153} INFO - Started process (PID=215) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:10.942+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:42:10.943+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:10.943+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:11.055+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:11.071+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:11.071+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:42:11.102+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:11.101+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:42:11.046005+00:00, run_after=2023-01-30T19:42:11.046005+00:00
[2023-01-29T19:42:11.133+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.197 seconds
[2023-01-29T19:42:21.249+0000] {processor.py:153} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:21.257+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:42:21.259+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:21.258+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:21.528+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:21.662+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:21.662+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:42:21.705+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:21.704+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:42:21.514697+00:00, run_after=2023-01-30T19:42:21.514697+00:00
[2023-01-29T19:42:21.769+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.543 seconds
[2023-01-29T19:42:31.947+0000] {processor.py:153} INFO - Started process (PID=225) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:31.949+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:42:31.950+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:31.950+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:32.202+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:32.226+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:32.225+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:42:32.283+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:32.283+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:42:32.187045+00:00, run_after=2023-01-30T19:42:32.187045+00:00
[2023-01-29T19:42:32.321+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.384 seconds
[2023-01-29T19:42:42.402+0000] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:42.403+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:42:42.404+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:42.404+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:42.551+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:42.572+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:42.571+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:42:42.620+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:42.620+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:42:42.537865+00:00, run_after=2023-01-30T19:42:42.537865+00:00
[2023-01-29T19:42:42.650+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.255 seconds
[2023-01-29T19:42:52.740+0000] {processor.py:153} INFO - Started process (PID=239) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:52.743+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:42:52.744+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:52.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:52.850+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:42:52.924+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:52.924+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:42:52.949+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:42:52.949+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:42:52.841017+00:00, run_after=2023-01-30T19:42:52.841017+00:00
[2023-01-29T19:42:52.971+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.235 seconds
[2023-01-29T19:43:03.080+0000] {processor.py:153} INFO - Started process (PID=244) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:03.081+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:43:03.082+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:03.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:03.243+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:03.259+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:03.259+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:43:03.289+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:03.289+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:43:03.229466+00:00, run_after=2023-01-30T19:43:03.229466+00:00
[2023-01-29T19:43:03.345+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.273 seconds
[2023-01-29T19:43:13.594+0000] {processor.py:153} INFO - Started process (PID=249) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:13.604+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:43:13.609+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:13.609+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:14.377+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:14.439+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:14.438+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:43:14.659+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:14.659+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:43:14.357764+00:00, run_after=2023-01-30T19:43:14.357764+00:00
[2023-01-29T19:43:14.860+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 1.294 seconds
[2023-01-29T19:43:25.043+0000] {processor.py:153} INFO - Started process (PID=256) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:25.045+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:43:25.048+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:25.048+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:25.177+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:25.281+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:25.280+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:43:25.306+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:25.306+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:43:25.166976+00:00, run_after=2023-01-30T19:43:25.166976+00:00
[2023-01-29T19:43:25.330+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.293 seconds
[2023-01-29T19:43:35.415+0000] {processor.py:153} INFO - Started process (PID=261) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:35.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:43:35.416+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:35.416+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:35.537+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:35.554+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:35.554+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:43:35.583+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:35.583+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:43:35.527859+00:00, run_after=2023-01-30T19:43:35.527859+00:00
[2023-01-29T19:43:35.605+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.195 seconds
[2023-01-29T19:43:45.682+0000] {processor.py:153} INFO - Started process (PID=266) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:45.683+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:43:45.684+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:45.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:45.797+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:45.815+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:45.815+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:43:45.844+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:45.844+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:43:45.787720+00:00, run_after=2023-01-30T19:43:45.787720+00:00
[2023-01-29T19:43:45.865+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.188 seconds
[2023-01-29T19:43:55.941+0000] {processor.py:153} INFO - Started process (PID=271) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:55.942+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:43:55.944+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:55.944+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:56.051+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:43:56.132+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:56.132+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:43:56.162+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:43:56.161+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:43:56.041303+00:00, run_after=2023-01-30T19:43:56.041303+00:00
[2023-01-29T19:43:56.185+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.248 seconds
[2023-01-29T19:44:06.265+0000] {processor.py:153} INFO - Started process (PID=276) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:06.266+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:44:06.267+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:06.267+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:06.390+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:06.409+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:06.409+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:44:06.447+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:06.447+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:44:06.380441+00:00, run_after=2023-01-30T19:44:06.380441+00:00
[2023-01-29T19:44:06.471+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.210 seconds
[2023-01-29T19:44:16.559+0000] {processor.py:153} INFO - Started process (PID=281) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:16.560+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:44:16.561+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:16.561+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:16.686+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:16.702+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:16.702+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:44:16.731+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:16.731+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:44:16.675390+00:00, run_after=2023-01-30T19:44:16.675390+00:00
[2023-01-29T19:44:16.759+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.207 seconds
[2023-01-29T19:44:26.850+0000] {processor.py:153} INFO - Started process (PID=286) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:26.852+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:44:26.853+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:26.853+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:27.062+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:27.182+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:27.182+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:44:27.245+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:27.245+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:44:27.046363+00:00, run_after=2023-01-30T19:44:27.046363+00:00
[2023-01-29T19:44:27.282+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.438 seconds
[2023-01-29T19:44:37.389+0000] {processor.py:153} INFO - Started process (PID=291) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:37.391+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:44:37.392+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:37.391+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:37.507+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:37.523+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:37.523+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:44:37.552+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:37.552+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:44:37.496750+00:00, run_after=2023-01-30T19:44:37.496750+00:00
[2023-01-29T19:44:37.577+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.193 seconds
[2023-01-29T19:44:47.657+0000] {processor.py:153} INFO - Started process (PID=296) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:47.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:44:47.659+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:47.659+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:47.771+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:47.787+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:47.787+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:44:47.832+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:47.832+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:44:47.760255+00:00, run_after=2023-01-30T19:44:47.760255+00:00
[2023-01-29T19:44:47.856+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.203 seconds
[2023-01-29T19:44:57.931+0000] {processor.py:153} INFO - Started process (PID=301) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:57.932+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:44:57.933+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:57.933+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:58.057+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:44:58.154+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:58.154+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:44:58.184+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:44:58.184+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:44:58.047145+00:00, run_after=2023-01-30T19:44:58.047145+00:00
[2023-01-29T19:44:58.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.281 seconds
[2023-01-29T19:45:08.285+0000] {processor.py:153} INFO - Started process (PID=306) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:08.286+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:45:08.287+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:08.287+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:08.398+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:08.416+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:08.416+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:45:08.446+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:08.446+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:45:08.388701+00:00, run_after=2023-01-30T19:45:08.388701+00:00
[2023-01-29T19:45:08.468+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.187 seconds
[2023-01-29T19:45:18.554+0000] {processor.py:153} INFO - Started process (PID=311) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:18.555+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:45:18.557+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:18.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:18.726+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:18.747+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:18.747+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:45:18.792+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:18.792+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:45:18.712131+00:00, run_after=2023-01-30T19:45:18.712131+00:00
[2023-01-29T19:45:18.824+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.277 seconds
[2023-01-29T19:45:28.922+0000] {processor.py:153} INFO - Started process (PID=316) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:28.924+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:45:28.925+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:28.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:29.092+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:29.206+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:29.206+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:45:29.253+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:29.251+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:45:29.078335+00:00, run_after=2023-01-30T19:45:29.078335+00:00
[2023-01-29T19:45:29.300+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.384 seconds
[2023-01-29T19:45:39.422+0000] {processor.py:153} INFO - Started process (PID=321) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:39.423+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:45:39.424+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:39.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:39.575+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:39.592+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:39.592+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:45:39.623+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:39.623+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:45:39.565189+00:00, run_after=2023-01-30T19:45:39.565189+00:00
[2023-01-29T19:45:39.646+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.229 seconds
[2023-01-29T19:45:49.722+0000] {processor.py:153} INFO - Started process (PID=326) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:49.723+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:45:49.724+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:49.724+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:49.836+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:49.853+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:49.853+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:45:49.884+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:49.883+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:45:49.827469+00:00, run_after=2023-01-30T19:45:49.827469+00:00
[2023-01-29T19:45:49.905+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.188 seconds
[2023-01-29T19:45:59.982+0000] {processor.py:153} INFO - Started process (PID=331) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:45:59.983+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:45:59.984+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:45:59.984+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:00.117+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:00.214+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:00.214+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:46:00.243+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:00.243+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:46:00.103569+00:00, run_after=2023-01-30T19:46:00.103569+00:00
[2023-01-29T19:46:00.265+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.288 seconds
[2023-01-29T19:46:10.355+0000] {processor.py:153} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:10.356+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:46:10.357+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:10.357+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:10.526+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:10.547+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:10.546+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:46:10.591+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:10.591+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:46:10.508173+00:00, run_after=2023-01-30T19:46:10.508173+00:00
[2023-01-29T19:46:10.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.270 seconds
[2023-01-29T19:46:20.717+0000] {processor.py:153} INFO - Started process (PID=341) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:20.718+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:46:20.719+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:20.719+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:20.989+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:21.015+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:21.015+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:46:21.095+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:21.094+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:46:20.975435+00:00, run_after=2023-01-30T19:46:20.975435+00:00
[2023-01-29T19:46:21.148+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.437 seconds
[2023-01-29T19:46:31.257+0000] {processor.py:153} INFO - Started process (PID=346) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:31.259+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:46:31.260+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:31.259+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:31.368+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:31.443+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:31.442+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:46:31.470+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:31.470+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:46:31.358766+00:00, run_after=2023-01-30T19:46:31.358766+00:00
[2023-01-29T19:46:31.495+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.244 seconds
[2023-01-29T19:46:41.584+0000] {processor.py:153} INFO - Started process (PID=351) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:41.585+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:46:41.586+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:41.586+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:41.747+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:41.764+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:41.764+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:46:41.795+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:41.795+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:46:41.734605+00:00, run_after=2023-01-30T19:46:41.734605+00:00
[2023-01-29T19:46:41.816+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.239 seconds
[2023-01-29T19:46:51.912+0000] {processor.py:153} INFO - Started process (PID=356) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:51.917+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:46:51.919+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:51.919+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:52.149+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:46:52.169+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:52.168+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:46:52.216+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:46:52.216+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:46:52.132322+00:00, run_after=2023-01-30T19:46:52.132322+00:00
[2023-01-29T19:46:52.257+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.357 seconds
[2023-01-29T19:47:02.365+0000] {processor.py:153} INFO - Started process (PID=361) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:02.366+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:47:02.367+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:02.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:02.500+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:02.578+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:02.578+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:47:02.604+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:02.604+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:47:02.490620+00:00, run_after=2023-01-30T19:47:02.490620+00:00
[2023-01-29T19:47:02.626+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.266 seconds
[2023-01-29T19:47:12.701+0000] {processor.py:153} INFO - Started process (PID=366) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:12.702+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:47:12.703+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:12.703+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:12.813+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:12.829+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:12.829+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:47:12.859+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:12.859+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:47:12.803243+00:00, run_after=2023-01-30T19:47:12.803243+00:00
[2023-01-29T19:47:12.882+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.186 seconds
[2023-01-29T19:47:22.958+0000] {processor.py:153} INFO - Started process (PID=371) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:22.959+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:47:22.960+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:22.960+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:23.074+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:23.090+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:23.089+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:47:23.118+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:23.118+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:47:23.063585+00:00, run_after=2023-01-30T19:47:23.063585+00:00
[2023-01-29T19:47:23.140+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.187 seconds
[2023-01-29T19:47:33.230+0000] {processor.py:153} INFO - Started process (PID=376) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:33.231+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:47:33.232+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:33.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:33.422+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:33.549+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:33.549+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:47:33.594+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:33.593+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:47:33.406961+00:00, run_after=2023-01-30T19:47:33.406961+00:00
[2023-01-29T19:47:33.634+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.409 seconds
[2023-01-29T19:47:43.743+0000] {processor.py:153} INFO - Started process (PID=381) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:43.745+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:47:43.745+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:43.745+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:43.854+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:43.872+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:43.872+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:47:43.901+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:43.900+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:47:43.844283+00:00, run_after=2023-01-30T19:47:43.844283+00:00
[2023-01-29T19:47:43.924+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.185 seconds
[2023-01-29T19:47:54.013+0000] {processor.py:153} INFO - Started process (PID=386) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:54.014+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:47:54.016+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:54.015+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:54.185+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:47:54.215+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:54.215+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:47:54.267+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:47:54.267+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:47:54.169063+00:00, run_after=2023-01-30T19:47:54.169063+00:00
[2023-01-29T19:47:54.325+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.318 seconds
[2023-01-29T19:48:04.441+0000] {processor.py:153} INFO - Started process (PID=391) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:04.443+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:48:04.444+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:04.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:04.574+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:04.687+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:04.687+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:48:04.762+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:04.762+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:48:04.565119+00:00, run_after=2023-01-30T19:48:04.565119+00:00
[2023-01-29T19:48:04.814+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.377 seconds
[2023-01-29T19:48:14.928+0000] {processor.py:153} INFO - Started process (PID=396) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:14.930+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:48:14.931+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:14.930+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:15.163+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:15.201+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:15.201+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:48:15.275+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:15.275+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:48:15.138349+00:00, run_after=2023-01-30T19:48:15.138349+00:00
[2023-01-29T19:48:15.336+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.413 seconds
[2023-01-29T19:48:25.453+0000] {processor.py:153} INFO - Started process (PID=401) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:25.455+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:48:25.456+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:25.456+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:25.640+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:25.664+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:25.664+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:48:25.704+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:25.703+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:48:25.625964+00:00, run_after=2023-01-30T19:48:25.625964+00:00
[2023-01-29T19:48:25.725+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.280 seconds
[2023-01-29T19:48:35.889+0000] {processor.py:153} INFO - Started process (PID=406) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:35.895+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:48:35.900+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:35.899+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:36.396+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:36.608+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:36.608+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:48:36.645+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:36.645+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:48:36.348451+00:00, run_after=2023-01-30T19:48:36.348451+00:00
[2023-01-29T19:48:36.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.814 seconds
[2023-01-29T19:48:46.747+0000] {processor.py:153} INFO - Started process (PID=411) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:46.749+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:48:46.750+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:46.750+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:46.863+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:46.879+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:46.879+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:48:46.908+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:46.908+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:48:46.854083+00:00, run_after=2023-01-30T19:48:46.854083+00:00
[2023-01-29T19:48:46.931+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.188 seconds
[2023-01-29T19:48:57.013+0000] {processor.py:153} INFO - Started process (PID=416) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:57.014+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:48:57.014+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:57.014+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:57.224+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:48:57.258+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:57.258+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:48:57.320+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:48:57.320+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:48:57.210588+00:00, run_after=2023-01-30T19:48:57.210588+00:00
[2023-01-29T19:48:57.395+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.387 seconds
[2023-01-29T19:49:07.479+0000] {processor.py:153} INFO - Started process (PID=421) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:07.481+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:49:07.482+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:07.482+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:07.611+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:07.694+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:07.694+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:49:07.721+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:07.720+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:49:07.602138+00:00, run_after=2023-01-30T19:49:07.602138+00:00
[2023-01-29T19:49:07.743+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.268 seconds
[2023-01-29T19:49:17.847+0000] {processor.py:153} INFO - Started process (PID=426) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:17.848+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:49:17.850+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:17.849+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:18.010+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:18.032+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:18.032+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:49:18.102+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:18.102+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:49:17.997213+00:00, run_after=2023-01-30T19:49:17.997213+00:00
[2023-01-29T19:49:18.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.317 seconds
[2023-01-29T19:49:28.239+0000] {processor.py:153} INFO - Started process (PID=431) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:28.240+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:49:28.241+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:28.241+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:28.370+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:28.388+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:28.387+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:49:28.436+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:28.436+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:49:28.359317+00:00, run_after=2023-01-30T19:49:28.359317+00:00
[2023-01-29T19:49:28.469+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.235 seconds
[2023-01-29T19:49:38.567+0000] {processor.py:153} INFO - Started process (PID=436) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:38.568+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:49:38.569+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:38.569+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:38.685+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:38.758+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:38.758+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:49:38.784+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:38.784+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:49:38.675590+00:00, run_after=2023-01-30T19:49:38.675590+00:00
[2023-01-29T19:49:38.807+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.244 seconds
[2023-01-29T19:49:48.889+0000] {processor.py:153} INFO - Started process (PID=441) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:48.890+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:49:48.891+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:48.891+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:49.014+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:49.029+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:49.029+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:49:49.061+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:49.061+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:49:49.004344+00:00, run_after=2023-01-30T19:49:49.004344+00:00
[2023-01-29T19:49:49.082+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.198 seconds
[2023-01-29T19:49:59.162+0000] {processor.py:153} INFO - Started process (PID=446) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:59.163+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:49:59.164+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:59.164+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:59.274+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:49:59.290+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:59.290+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:49:59.321+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:49:59.321+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:49:59.265010+00:00, run_after=2023-01-30T19:49:59.265010+00:00
[2023-01-29T19:49:59.343+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.185 seconds
[2023-01-29T19:50:09.430+0000] {processor.py:153} INFO - Started process (PID=451) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:09.431+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:50:09.431+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:09.431+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:09.586+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:09.675+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:09.675+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:50:09.700+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:09.700+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:50:09.568718+00:00, run_after=2023-01-30T19:50:09.568718+00:00
[2023-01-29T19:50:09.723+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.299 seconds
[2023-01-29T19:50:19.804+0000] {processor.py:153} INFO - Started process (PID=456) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:19.806+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:50:19.807+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:19.807+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:20.044+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:20.069+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:20.069+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:50:20.124+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:20.124+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:50:20.023484+00:00, run_after=2023-01-30T19:50:20.023484+00:00
[2023-01-29T19:50:20.170+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.372 seconds
[2023-01-29T19:50:30.267+0000] {processor.py:153} INFO - Started process (PID=461) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:30.268+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:50:30.270+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:30.269+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:30.463+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:30.484+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:30.484+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:50:30.533+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:30.532+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:50:30.446779+00:00, run_after=2023-01-30T19:50:30.446779+00:00
[2023-01-29T19:50:30.564+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.302 seconds
[2023-01-29T19:50:40.674+0000] {processor.py:153} INFO - Started process (PID=466) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:40.675+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:50:40.676+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:40.676+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:40.787+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:40.860+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:40.860+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:50:40.889+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:40.889+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:50:40.777394+00:00, run_after=2023-01-30T19:50:40.777394+00:00
[2023-01-29T19:50:40.916+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.247 seconds
[2023-01-29T19:50:50.996+0000] {processor.py:153} INFO - Started process (PID=471) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:50.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:50:50.998+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:50.998+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:51.144+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:50:51.180+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:51.180+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:50:51.225+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:50:51.225+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:50:51.117255+00:00, run_after=2023-01-30T19:50:51.117255+00:00
[2023-01-29T19:50:51.263+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.272 seconds
[2023-01-29T19:51:01.363+0000] {processor.py:153} INFO - Started process (PID=476) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:01.365+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:51:01.366+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:01.366+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:01.493+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:01.509+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:01.509+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:51:01.540+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:01.540+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:51:01.481370+00:00, run_after=2023-01-30T19:51:01.481370+00:00
[2023-01-29T19:51:01.561+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.204 seconds
[2023-01-29T19:51:11.645+0000] {processor.py:153} INFO - Started process (PID=481) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:11.646+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:51:11.647+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:11.647+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:11.768+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:11.841+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:11.841+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:51:11.871+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:11.871+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:51:11.757345+00:00, run_after=2023-01-30T19:51:11.757345+00:00
[2023-01-29T19:51:11.895+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.256 seconds
[2023-01-29T19:51:21.978+0000] {processor.py:153} INFO - Started process (PID=486) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:21.979+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:51:21.980+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:21.980+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:22.092+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:22.107+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:22.107+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:51:22.137+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:22.137+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:51:22.081392+00:00, run_after=2023-01-30T19:51:22.081392+00:00
[2023-01-29T19:51:22.159+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.185 seconds
[2023-01-29T19:51:32.240+0000] {processor.py:153} INFO - Started process (PID=491) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:32.241+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:51:32.242+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:32.242+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:32.352+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:32.367+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:32.367+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:51:32.396+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:32.396+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:51:32.342332+00:00, run_after=2023-01-30T19:51:32.342332+00:00
[2023-01-29T19:51:32.417+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.182 seconds
[2023-01-29T19:51:42.504+0000] {processor.py:153} INFO - Started process (PID=496) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:42.506+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:51:42.507+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:42.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:42.668+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:42.785+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:42.785+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:51:42.826+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:42.826+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:51:42.654421+00:00, run_after=2023-01-30T19:51:42.654421+00:00
[2023-01-29T19:51:42.867+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.370 seconds
[2023-01-29T19:51:52.957+0000] {processor.py:153} INFO - Started process (PID=501) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:52.958+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:51:52.959+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:52.958+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:53.102+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:51:53.122+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:53.122+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:51:53.175+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:51:53.174+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:51:53.087033+00:00, run_after=2023-01-30T19:51:53.087033+00:00
[2023-01-29T19:51:53.224+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.273 seconds
[2023-01-29T19:52:03.354+0000] {processor.py:153} INFO - Started process (PID=506) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:03.356+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:52:03.357+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:03.357+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:03.541+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:03.566+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:03.566+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:52:03.610+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:03.610+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:52:03.515099+00:00, run_after=2023-01-30T19:52:03.515099+00:00
[2023-01-29T19:52:03.646+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.298 seconds
[2023-01-29T19:52:13.735+0000] {processor.py:153} INFO - Started process (PID=511) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:13.736+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:52:13.737+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:13.737+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:13.848+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:13.925+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:13.925+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:52:13.953+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:13.953+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:52:13.839186+00:00, run_after=2023-01-30T19:52:13.839186+00:00
[2023-01-29T19:52:13.986+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.257 seconds
[2023-01-29T19:52:24.074+0000] {processor.py:153} INFO - Started process (PID=516) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:24.075+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:52:24.076+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:24.076+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:24.199+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:24.215+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:24.215+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:52:24.246+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:24.246+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:52:24.190313+00:00, run_after=2023-01-30T19:52:24.190313+00:00
[2023-01-29T19:52:24.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.199 seconds
[2023-01-29T19:52:34.356+0000] {processor.py:153} INFO - Started process (PID=521) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:34.357+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:52:34.358+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:34.358+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:34.470+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:34.487+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:34.487+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:52:34.517+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:34.516+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:52:34.460496+00:00, run_after=2023-01-30T19:52:34.460496+00:00
[2023-01-29T19:52:34.539+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.188 seconds
[2023-01-29T19:52:44.619+0000] {processor.py:153} INFO - Started process (PID=526) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:44.620+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:52:44.621+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:44.621+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:44.731+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:44.806+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:44.805+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:52:44.834+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:44.833+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:52:44.721811+00:00, run_after=2023-01-30T19:52:44.721811+00:00
[2023-01-29T19:52:44.867+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.253 seconds
[2023-01-29T19:52:54.972+0000] {processor.py:153} INFO - Started process (PID=531) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:54.974+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:52:54.975+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:54.974+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:55.136+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:52:55.156+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:55.156+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:52:55.232+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:52:55.232+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:52:55.121984+00:00, run_after=2023-01-30T19:52:55.121984+00:00
[2023-01-29T19:52:55.306+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.340 seconds
[2023-01-29T19:53:05.412+0000] {processor.py:153} INFO - Started process (PID=536) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:05.413+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:53:05.415+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:05.414+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:05.579+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:05.614+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:05.614+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:53:05.683+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:05.683+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:53:05.564961+00:00, run_after=2023-01-30T19:53:05.564961+00:00
[2023-01-29T19:53:05.724+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.318 seconds
[2023-01-29T19:53:15.822+0000] {processor.py:153} INFO - Started process (PID=541) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:15.823+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:53:15.824+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:15.824+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:15.936+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:16.086+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:16.086+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:53:16.126+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:16.126+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:53:15.926437+00:00, run_after=2023-01-30T19:53:15.926437+00:00
[2023-01-29T19:53:16.153+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.335 seconds
[2023-01-29T19:53:26.233+0000] {processor.py:153} INFO - Started process (PID=546) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:26.234+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:53:26.235+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:26.235+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:26.403+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:26.418+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:26.418+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:53:26.448+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:26.447+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:53:26.393746+00:00, run_after=2023-01-30T19:53:26.393746+00:00
[2023-01-29T19:53:26.469+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.241 seconds
[2023-01-29T19:53:36.600+0000] {processor.py:153} INFO - Started process (PID=551) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:36.604+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:53:36.606+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:36.605+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:36.862+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:36.886+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:36.886+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:53:36.929+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:36.929+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:53:36.851032+00:00, run_after=2023-01-30T19:53:36.851032+00:00
[2023-01-29T19:53:36.956+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.370 seconds
[2023-01-29T19:53:47.045+0000] {processor.py:153} INFO - Started process (PID=556) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:47.046+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:53:47.047+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:47.046+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:47.165+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:47.240+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:47.240+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:53:47.273+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:47.273+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:53:47.154882+00:00, run_after=2023-01-30T19:53:47.154882+00:00
[2023-01-29T19:53:47.303+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.265 seconds
[2023-01-29T19:53:57.396+0000] {processor.py:153} INFO - Started process (PID=561) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:57.397+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:53:57.398+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:57.398+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:57.556+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:53:57.579+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:57.579+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:53:57.646+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:53:57.645+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:53:57.541539+00:00, run_after=2023-01-30T19:53:57.541539+00:00
[2023-01-29T19:53:57.671+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.280 seconds
[2023-01-29T19:54:07.765+0000] {processor.py:153} INFO - Started process (PID=566) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:07.770+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:54:07.771+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:07.771+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:07.912+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:07.933+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:07.933+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:54:07.978+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:07.978+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:54:07.897283+00:00, run_after=2023-01-30T19:54:07.897283+00:00
[2023-01-29T19:54:08.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.248 seconds
[2023-01-29T19:54:18.100+0000] {processor.py:153} INFO - Started process (PID=571) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:18.102+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:54:18.103+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:18.103+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:18.219+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:18.294+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:18.294+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:54:18.327+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:18.326+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:54:18.208806+00:00, run_after=2023-01-30T19:54:18.208806+00:00
[2023-01-29T19:54:18.352+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.258 seconds
[2023-01-29T19:54:28.532+0000] {processor.py:153} INFO - Started process (PID=576) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:28.547+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:54:28.551+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:28.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:28.916+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:28.967+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:28.967+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:54:29.069+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:29.069+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:54:28.878925+00:00, run_after=2023-01-30T19:54:28.878925+00:00
[2023-01-29T19:54:29.161+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.644 seconds
[2023-01-29T19:54:39.273+0000] {processor.py:153} INFO - Started process (PID=581) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:39.274+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:54:39.275+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:39.274+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:39.413+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:39.428+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:39.427+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:54:39.457+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:39.456+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:54:39.404197+00:00, run_after=2023-01-30T19:54:39.404197+00:00
[2023-01-29T19:54:39.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.211 seconds
[2023-01-29T19:54:49.552+0000] {processor.py:153} INFO - Started process (PID=586) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:49.553+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:54:49.554+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:49.554+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:49.664+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:49.758+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:49.758+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:54:49.792+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:49.791+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:54:49.654561+00:00, run_after=2023-01-30T19:54:49.654561+00:00
[2023-01-29T19:54:49.820+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.272 seconds
[2023-01-29T19:54:59.898+0000] {processor.py:153} INFO - Started process (PID=591) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:54:59.899+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:54:59.900+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:54:59.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:00.034+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:00.050+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:00.050+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:55:00.086+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:00.085+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:55:00.024614+00:00, run_after=2023-01-30T19:55:00.024614+00:00
[2023-01-29T19:55:00.117+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.224 seconds
[2023-01-29T19:55:10.198+0000] {processor.py:153} INFO - Started process (PID=596) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:10.200+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:55:10.200+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:10.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:10.313+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:10.329+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:10.329+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:55:10.360+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:10.360+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:55:10.302627+00:00, run_after=2023-01-30T19:55:10.302627+00:00
[2023-01-29T19:55:10.382+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.188 seconds
[2023-01-29T19:55:20.459+0000] {processor.py:153} INFO - Started process (PID=601) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:20.460+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:55:20.461+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:20.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:20.572+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:20.653+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:20.653+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:55:20.685+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:20.684+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:55:20.563290+00:00, run_after=2023-01-30T19:55:20.563290+00:00
[2023-01-29T19:55:20.729+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.275 seconds
[2023-01-29T19:55:30.888+0000] {processor.py:153} INFO - Started process (PID=606) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:30.893+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:55:30.894+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:30.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:31.112+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:31.135+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:31.135+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:55:31.183+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:31.182+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:55:31.097169+00:00, run_after=2023-01-30T19:55:31.097169+00:00
[2023-01-29T19:55:31.212+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.337 seconds
[2023-01-29T19:55:41.302+0000] {processor.py:153} INFO - Started process (PID=611) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:41.303+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:55:41.304+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:41.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:41.474+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:41.503+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:41.503+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:55:41.586+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:41.586+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:55:41.449873+00:00, run_after=2023-01-30T19:55:41.449873+00:00
[2023-01-29T19:55:41.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.372 seconds
[2023-01-29T19:55:51.817+0000] {processor.py:153} INFO - Started process (PID=616) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:51.818+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:55:51.819+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:51.819+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:51.931+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:55:52.007+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:52.006+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:55:52.033+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:55:52.033+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:55:51.922466+00:00, run_after=2023-01-30T19:55:51.922466+00:00
[2023-01-29T19:55:52.061+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.249 seconds
[2023-01-29T19:56:02.160+0000] {processor.py:153} INFO - Started process (PID=621) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:02.161+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:56:02.162+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:02.162+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:02.223+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:02.222+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
ModuleNotFoundError: No module named 'etl'
[2023-01-29T19:56:02.224+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:02.252+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 0.096 seconds
[2023-01-29T19:56:12.335+0000] {processor.py:153} INFO - Started process (PID=626) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:12.337+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:56:12.338+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:12.338+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:22.543+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:22.639+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:22.639+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:56:22.673+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:22.673+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:56:22.533295+00:00, run_after=2023-01-30T19:56:22.533295+00:00
[2023-01-29T19:56:22.700+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.371 seconds
[2023-01-29T19:56:32.811+0000] {processor.py:153} INFO - Started process (PID=632) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:32.812+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:56:32.814+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:32.813+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:40.282+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:40.295+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:40.294+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:56:40.321+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:40.321+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T19:56:40.274103+00:00, run_after=2023-01-30T19:56:40.274103+00:00
[2023-01-29T19:56:40.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.537 seconds
[2023-01-29T19:56:49.431+0000] {processor.py:153} INFO - Started process (PID=638) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:49.432+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:56:49.433+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:49.433+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:59.309+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:56:59.505+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:59.505+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:data_pipeline
[2023-01-29T19:56:59.517+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:59.517+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:data_pipeline
[2023-01-29T19:56:59.527+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:59.527+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:data_pipeline
[2023-01-29T19:56:59.528+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:59.527+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:56:59.541+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:59.540+0000] {dag.py:2711} INFO - Creating ORM DAG for data_pipeline
[2023-01-29T19:56:59.553+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:56:59.553+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:56:59.301408+00:00, run_after=2023-01-30T19:56:59.301408+00:00
[2023-01-29T19:56:59.571+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.146 seconds
[2023-01-29T19:57:09.696+0000] {processor.py:153} INFO - Started process (PID=644) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:57:09.698+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:57:09.700+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:57:09.700+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:57:19.483+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:57:19.495+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:57:19.495+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:57:19.520+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:57:19.520+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:57:19.474435+00:00, run_after=2023-01-30T19:57:19.474435+00:00
[2023-01-29T19:57:19.539+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.856 seconds
[2023-01-29T19:57:29.657+0000] {processor.py:153} INFO - Started process (PID=652) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:57:29.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:57:29.660+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:57:29.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:57:42.704+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:57:42.773+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:57:42.773+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:57:42.811+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:57:42.811+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:57:42.695348+00:00, run_after=2023-01-30T19:57:42.695348+00:00
[2023-01-29T19:57:42.838+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 13.187 seconds
[2023-01-29T19:57:52.933+0000] {processor.py:153} INFO - Started process (PID=661) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:57:52.935+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:57:52.936+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:57:52.936+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:04.395+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:04.408+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:04.407+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:58:04.437+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:04.437+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:58:04.385221+00:00, run_after=2023-01-30T19:58:04.385221+00:00
[2023-01-29T19:58:04.458+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 11.531 seconds
[2023-01-29T19:58:14.561+0000] {processor.py:153} INFO - Started process (PID=667) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:14.563+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:58:14.564+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:14.564+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:23.472+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:23.548+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:23.547+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:58:23.592+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:23.592+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:58:23.464102+00:00, run_after=2023-01-30T19:58:23.464102+00:00
[2023-01-29T19:58:23.626+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.071 seconds
[2023-01-29T19:58:33.761+0000] {processor.py:153} INFO - Started process (PID=673) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:33.762+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:58:33.763+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:33.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:42.974+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:42.991+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:42.990+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:58:43.027+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:43.027+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:58:42.961776+00:00, run_after=2023-01-30T19:58:42.961776+00:00
[2023-01-29T19:58:43.047+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.291 seconds
[2023-01-29T19:58:53.156+0000] {processor.py:153} INFO - Started process (PID=679) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:58:53.158+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:58:53.159+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:58:53.159+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:00.751+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:00.817+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:00.817+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:59:00.843+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:00.843+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:59:00.743236+00:00, run_after=2023-01-30T19:59:00.743236+00:00
[2023-01-29T19:59:00.866+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.716 seconds
[2023-01-29T19:59:10.963+0000] {processor.py:153} INFO - Started process (PID=685) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:10.964+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:59:10.965+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:10.965+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:19.470+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:19.482+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:19.482+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:59:19.508+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:19.508+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:59:19.461949+00:00, run_after=2023-01-30T19:59:19.461949+00:00
[2023-01-29T19:59:19.528+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.570 seconds
[2023-01-29T19:59:29.639+0000] {processor.py:153} INFO - Started process (PID=691) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:29.641+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:59:29.642+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:29.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:37.381+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:37.448+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:37.447+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:59:37.471+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:37.471+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:59:37.372306+00:00, run_after=2023-01-30T19:59:37.372306+00:00
[2023-01-29T19:59:37.492+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.860 seconds
[2023-01-29T19:59:47.577+0000] {processor.py:153} INFO - Started process (PID=697) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:47.578+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T19:59:47.579+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:47.579+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:55.965+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T19:59:55.979+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:55.978+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T19:59:56.007+0000] {logging_mixin.py:137} INFO - [2023-01-29T19:59:56.006+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T19:59:55.953182+00:00, run_after=2023-01-30T19:59:55.953182+00:00
[2023-01-29T19:59:56.029+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.456 seconds
[2023-01-29T20:00:06.160+0000] {processor.py:153} INFO - Started process (PID=703) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:06.170+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:00:06.171+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:06.171+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:14.785+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:14.867+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:14.866+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:00:14.897+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:14.897+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:00:14.776412+00:00, run_after=2023-01-30T20:00:14.776412+00:00
[2023-01-29T20:00:14.927+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.775 seconds
[2023-01-29T20:00:25.016+0000] {processor.py:153} INFO - Started process (PID=709) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:25.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:00:25.017+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:25.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:33.395+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:33.412+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:33.411+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:00:33.495+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:33.495+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:00:33.381633+00:00, run_after=2023-01-30T20:00:33.381633+00:00
[2023-01-29T20:00:33.548+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.537 seconds
[2023-01-29T20:00:43.675+0000] {processor.py:153} INFO - Started process (PID=715) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:43.676+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:00:43.677+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:43.676+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:52.240+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:00:52.305+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:52.305+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:00:52.330+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:00:52.330+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:00:52.231961+00:00, run_after=2023-01-30T20:00:52.231961+00:00
[2023-01-29T20:00:52.351+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.681 seconds
[2023-01-29T20:01:02.457+0000] {processor.py:153} INFO - Started process (PID=721) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:02.459+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:01:02.460+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:02.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:10.341+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:10.357+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:10.356+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:01:10.399+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:10.398+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:01:10.327790+00:00, run_after=2023-01-30T20:01:10.327790+00:00
[2023-01-29T20:01:10.426+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.976 seconds
[2023-01-29T20:01:20.530+0000] {processor.py:153} INFO - Started process (PID=727) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:20.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:01:20.532+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:20.532+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:29.032+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:29.097+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:29.096+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:01:29.122+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:29.122+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:01:29.023875+00:00, run_after=2023-01-30T20:01:29.023875+00:00
[2023-01-29T20:01:29.146+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.621 seconds
[2023-01-29T20:01:39.261+0000] {processor.py:153} INFO - Started process (PID=733) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:39.262+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:01:39.265+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:39.263+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:46.926+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:46.954+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:46.954+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:01:47.039+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:47.039+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:01:46.912361+00:00, run_after=2023-01-30T20:01:46.912361+00:00
[2023-01-29T20:01:47.072+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.820 seconds
[2023-01-29T20:01:57.229+0000] {processor.py:153} INFO - Started process (PID=739) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:01:57.230+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:01:57.231+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:01:57.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:02:05.501+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:02:05.573+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:02:05.572+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:02:05.597+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:02:05.597+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:02:05.490549+00:00, run_after=2023-01-30T20:02:05.490549+00:00
[2023-01-29T20:02:05.620+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.405 seconds
[2023-01-29T20:02:15.722+0000] {processor.py:153} INFO - Started process (PID=745) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:02:15.724+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:02:15.725+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:02:15.725+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:02:22.959+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:02:22.973+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:02:22.973+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:02:23.000+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:02:23.000+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:02:22.951245+00:00, run_after=2023-01-30T20:02:22.951245+00:00
[2023-01-29T20:02:23.026+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.310 seconds
[2023-01-29T20:02:33.178+0000] {processor.py:153} INFO - Started process (PID=753) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:02:33.179+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:02:33.180+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:02:33.180+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:02:50.187+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:02:50.412+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:02:50.411+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:02:50.604+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:02:50.603+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:02:50.163956+00:00, run_after=2023-01-30T20:02:50.163956+00:00
[2023-01-29T20:02:50.697+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 17.525 seconds
[2023-01-29T20:03:00.854+0000] {processor.py:153} INFO - Started process (PID=767) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:00.856+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:03:00.858+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:00.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:12.824+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:12.836+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:12.836+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:03:12.863+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:12.863+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:03:12.815518+00:00, run_after=2023-01-30T20:03:12.815518+00:00
[2023-01-29T20:03:12.882+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 12.038 seconds
[2023-01-29T20:03:22.981+0000] {processor.py:153} INFO - Started process (PID=773) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:22.982+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:03:22.983+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:22.982+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:34.018+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:34.097+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:34.096+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:03:34.124+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:34.124+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:03:34.009124+00:00, run_after=2023-01-30T20:03:34.009124+00:00
[2023-01-29T20:03:34.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 11.176 seconds
[2023-01-29T20:03:44.248+0000] {processor.py:153} INFO - Started process (PID=779) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:44.249+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:03:44.250+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:44.250+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:51.926+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:03:51.939+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:51.938+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:03:51.982+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:03:51.982+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:03:51.918368+00:00, run_after=2023-01-30T20:03:51.918368+00:00
[2023-01-29T20:03:52.011+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.768 seconds
[2023-01-29T20:04:02.124+0000] {processor.py:153} INFO - Started process (PID=785) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:02.125+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:04:02.126+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:02.126+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:10.853+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:10.919+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:10.919+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:04:10.945+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:10.945+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:04:10.844668+00:00, run_after=2023-01-30T20:04:10.844668+00:00
[2023-01-29T20:04:10.967+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.854 seconds
[2023-01-29T20:04:21.061+0000] {processor.py:153} INFO - Started process (PID=791) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:21.063+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:04:21.064+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:21.064+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:29.666+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:29.680+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:29.680+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:04:29.706+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:29.706+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:04:29.656934+00:00, run_after=2023-01-30T20:04:29.656934+00:00
[2023-01-29T20:04:29.728+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.673 seconds
[2023-01-29T20:04:39.821+0000] {processor.py:153} INFO - Started process (PID=797) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:39.822+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:04:39.823+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:39.823+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:49.011+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:49.246+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:49.243+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:04:49.303+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:49.302+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:04:48.975237+00:00, run_after=2023-01-30T20:04:48.975237+00:00
[2023-01-29T20:04:49.360+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.544 seconds
[2023-01-29T20:04:59.480+0000] {processor.py:153} INFO - Started process (PID=803) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:04:59.481+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:04:59.482+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:04:59.482+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:06.999+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:07.012+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:07.012+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:05:07.056+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:07.056+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:05:06.990959+00:00, run_after=2023-01-30T20:05:06.990959+00:00
[2023-01-29T20:05:07.090+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.615 seconds
[2023-01-29T20:05:17.214+0000] {processor.py:153} INFO - Started process (PID=809) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:17.215+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:05:17.215+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:17.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:26.394+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:26.460+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:26.459+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:05:26.484+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:26.484+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:05:26.385551+00:00, run_after=2023-01-30T20:05:26.385551+00:00
[2023-01-29T20:05:26.507+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.299 seconds
[2023-01-29T20:05:36.598+0000] {processor.py:153} INFO - Started process (PID=815) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:36.599+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:05:36.600+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:36.600+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:43.875+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:43.888+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:43.888+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:05:43.913+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:43.913+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:05:43.867387+00:00, run_after=2023-01-30T20:05:43.867387+00:00
[2023-01-29T20:05:43.935+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.341 seconds
[2023-01-29T20:05:54.024+0000] {processor.py:153} INFO - Started process (PID=821) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:05:54.026+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:05:54.026+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:05:54.026+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:02.379+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:02.448+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:02.447+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:06:02.471+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:02.471+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:06:02.370458+00:00, run_after=2023-01-30T20:06:02.370458+00:00
[2023-01-29T20:06:02.499+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.480 seconds
[2023-01-29T20:06:12.599+0000] {processor.py:153} INFO - Started process (PID=827) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:12.600+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:06:12.601+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:12.601+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:19.541+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:19.563+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:19.562+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:06:19.608+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:19.608+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:06:19.531557+00:00, run_after=2023-01-30T20:06:19.531557+00:00
[2023-01-29T20:06:19.636+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.042 seconds
[2023-01-29T20:06:29.693+0000] {processor.py:153} INFO - Started process (PID=833) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:29.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:06:29.695+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:29.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:38.899+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:38.973+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:38.972+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:06:39.010+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:39.009+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:06:38.891282+00:00, run_after=2023-01-30T20:06:38.891282+00:00
[2023-01-29T20:06:39.040+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.352 seconds
[2023-01-29T20:06:39.803+0000] {processor.py:153} INFO - Started process (PID=839) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:39.804+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:06:39.805+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:39.805+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:50.504+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:50.601+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:50.600+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:06:50.640+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:50.640+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T20:06:50.492358+00:00, run_after=2023-01-30T20:06:50.492358+00:00
[2023-01-29T20:06:50.674+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.876 seconds
[2023-01-29T20:06:55.753+0000] {processor.py:153} INFO - Started process (PID=845) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:06:55.755+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:06:55.757+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:06:55.757+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:04.960+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:04.977+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:04.976+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:07:05.015+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:05.015+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T20:07:04.948773+00:00, run_after=2023-01-30T20:07:04.948773+00:00
[2023-01-29T20:07:05.045+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.298 seconds
[2023-01-29T20:07:15.153+0000] {processor.py:153} INFO - Started process (PID=851) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:15.155+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:07:15.156+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:15.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:23.608+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:23.672+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:23.672+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:07:23.698+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:23.698+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T20:07:23.600345+00:00, run_after=2023-01-30T20:07:23.600345+00:00
[2023-01-29T20:07:23.727+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.580 seconds
[2023-01-29T20:07:33.818+0000] {processor.py:153} INFO - Started process (PID=857) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:33.819+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:07:33.820+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:33.820+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:43.627+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:43.755+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:43.755+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:data_pipeline_2
[2023-01-29T20:07:43.766+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:43.766+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:data_pipeline_2
[2023-01-29T20:07:43.775+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:43.774+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:data_pipeline_2
[2023-01-29T20:07:43.776+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:43.775+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:07:43.799+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:43.799+0000] {dag.py:2711} INFO - Creating ORM DAG for data_pipeline_2
[2023-01-29T20:07:43.814+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:43.813+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:07:43.618321+00:00, run_after=2023-01-30T20:07:43.618321+00:00
[2023-01-29T20:07:43.831+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.018 seconds
[2023-01-29T20:07:53.924+0000] {processor.py:153} INFO - Started process (PID=863) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:07:53.925+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:07:53.926+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:07:53.926+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:00.960+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:00.972+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:00.972+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:08:00.997+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:00.997+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:08:00.951265+00:00, run_after=2023-01-30T20:08:00.951265+00:00
[2023-01-29T20:08:01.018+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.099 seconds
[2023-01-29T20:08:11.104+0000] {processor.py:153} INFO - Started process (PID=869) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:11.105+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:08:11.106+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:11.106+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:20.343+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:20.421+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:20.420+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:08:20.448+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:20.448+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:08:20.334428+00:00, run_after=2023-01-30T20:08:20.334428+00:00
[2023-01-29T20:08:20.471+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.372 seconds
[2023-01-29T20:08:30.561+0000] {processor.py:153} INFO - Started process (PID=875) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:30.562+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:08:30.563+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:30.563+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:37.530+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:37.542+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:37.542+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:08:37.568+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:37.568+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:08:37.521439+00:00, run_after=2023-01-30T20:08:37.521439+00:00
[2023-01-29T20:08:37.592+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.035 seconds
[2023-01-29T20:08:47.655+0000] {processor.py:153} INFO - Started process (PID=881) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:47.657+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:08:47.658+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:47.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:56.038+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:08:56.108+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:56.107+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:08:56.146+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:08:56.145+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:08:56.029473+00:00, run_after=2023-01-30T20:08:56.029473+00:00
[2023-01-29T20:08:56.175+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.525 seconds
[2023-01-29T20:09:06.327+0000] {processor.py:153} INFO - Started process (PID=887) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:09:06.328+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:09:06.329+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:09:06.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:09:19.406+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:09:19.421+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:09:19.420+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:09:19.460+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:09:19.460+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:09:19.395067+00:00, run_after=2023-01-30T20:09:19.395067+00:00
[2023-01-29T20:09:19.487+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 13.166 seconds
[2023-01-29T20:09:29.613+0000] {processor.py:153} INFO - Started process (PID=898) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:09:29.617+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:09:29.618+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:09:29.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:09:39.183+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:09:39.314+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:09:39.311+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:09:39.358+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:09:39.358+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:09:39.171992+00:00, run_after=2023-01-30T20:09:39.171992+00:00
[2023-01-29T20:09:39.382+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.779 seconds
[2023-01-29T20:09:49.493+0000] {processor.py:153} INFO - Started process (PID=906) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:09:49.494+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:09:49.496+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:09:49.495+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:04.340+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:04.364+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:04.359+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:10:04.406+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:04.406+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:10:04.326030+00:00, run_after=2023-01-30T20:10:04.326030+00:00
[2023-01-29T20:10:04.434+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 14.947 seconds
[2023-01-29T20:10:14.547+0000] {processor.py:153} INFO - Started process (PID=918) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:14.548+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:10:14.549+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:14.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:22.757+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:22.868+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:22.867+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:10:22.914+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:22.914+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:10:22.730948+00:00, run_after=2023-01-30T20:10:22.730948+00:00
[2023-01-29T20:10:22.945+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.403 seconds
[2023-01-29T20:10:33.041+0000] {processor.py:153} INFO - Started process (PID=924) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:33.043+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:10:33.043+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:33.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:41.522+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:41.536+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:41.536+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:10:41.563+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:41.563+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:10:41.513292+00:00, run_after=2023-01-30T20:10:41.513292+00:00
[2023-01-29T20:10:41.583+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.547 seconds
[2023-01-29T20:10:51.686+0000] {processor.py:153} INFO - Started process (PID=930) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:51.687+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:10:51.688+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:51.688+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:59.548+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:10:59.652+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:59.651+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:10:59.695+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:10:59.695+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:10:59.535659+00:00, run_after=2023-01-30T20:10:59.535659+00:00
[2023-01-29T20:10:59.728+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.048 seconds
[2023-01-29T20:11:09.785+0000] {processor.py:153} INFO - Started process (PID=936) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:09.786+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:11:09.787+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:09.786+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:18.358+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:18.371+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:18.371+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:11:18.397+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:18.397+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:11:18.350334+00:00, run_after=2023-01-30T20:11:18.350334+00:00
[2023-01-29T20:11:18.420+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.641 seconds
[2023-01-29T20:11:28.513+0000] {processor.py:153} INFO - Started process (PID=942) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:28.514+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:11:28.516+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:28.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:35.735+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:35.849+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:35.848+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:11:35.906+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:35.905+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:11:35.722638+00:00, run_after=2023-01-30T20:11:35.722638+00:00
[2023-01-29T20:11:35.936+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.428 seconds
[2023-01-29T20:11:46.023+0000] {processor.py:153} INFO - Started process (PID=948) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:46.024+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:11:46.025+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:46.025+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:54.157+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:11:54.172+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:54.171+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:11:54.211+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:11:54.211+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:11:54.145885+00:00, run_after=2023-01-30T20:11:54.145885+00:00
[2023-01-29T20:11:54.232+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.214 seconds
[2023-01-29T20:12:04.324+0000] {processor.py:153} INFO - Started process (PID=954) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:04.325+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:12:04.326+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:04.326+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:11.363+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:11.494+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:11.493+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:12:11.531+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:11.531+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:12:11.342491+00:00, run_after=2023-01-30T20:12:11.342491+00:00
[2023-01-29T20:12:11.553+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.234 seconds
[2023-01-29T20:12:21.640+0000] {processor.py:153} INFO - Started process (PID=960) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:21.641+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:12:21.642+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:21.641+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:30.013+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:30.026+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:30.025+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:12:30.053+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:30.053+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:12:30.004948+00:00, run_after=2023-01-30T20:12:30.004948+00:00
[2023-01-29T20:12:30.083+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.448 seconds
[2023-01-29T20:12:40.190+0000] {processor.py:153} INFO - Started process (PID=966) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:40.191+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:12:40.192+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:40.192+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:47.517+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:47.580+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:47.580+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:12:47.603+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:47.603+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:12:47.508726+00:00, run_after=2023-01-30T20:12:47.508726+00:00
[2023-01-29T20:12:47.633+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.448 seconds
[2023-01-29T20:12:57.760+0000] {processor.py:153} INFO - Started process (PID=972) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:12:57.761+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:12:57.763+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:12:57.762+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:06.837+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:06.849+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:06.849+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:13:06.876+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:06.876+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:13:06.828480+00:00, run_after=2023-01-30T20:13:06.828480+00:00
[2023-01-29T20:13:06.899+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.147 seconds
[2023-01-29T20:13:16.988+0000] {processor.py:153} INFO - Started process (PID=978) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:16.990+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:13:16.990+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:16.990+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:25.599+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:25.703+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:25.702+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:13:25.745+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:25.745+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:13:25.586026+00:00, run_after=2023-01-30T20:13:25.586026+00:00
[2023-01-29T20:13:25.775+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.793 seconds
[2023-01-29T20:13:35.881+0000] {processor.py:153} INFO - Started process (PID=984) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:35.882+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:13:35.883+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:35.883+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:44.270+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:44.282+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:44.282+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:13:44.310+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:44.310+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:13:44.261484+00:00, run_after=2023-01-30T20:13:44.261484+00:00
[2023-01-29T20:13:44.332+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.455 seconds
[2023-01-29T20:13:54.424+0000] {processor.py:153} INFO - Started process (PID=990) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:13:54.425+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:13:54.426+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:13:54.426+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:01.629+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:01.696+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:01.695+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:14:01.721+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:01.721+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:14:01.617049+00:00, run_after=2023-01-30T20:14:01.617049+00:00
[2023-01-29T20:14:01.764+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.344 seconds
[2023-01-29T20:14:11.866+0000] {processor.py:153} INFO - Started process (PID=996) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:11.867+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:14:11.868+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:11.868+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:20.059+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:20.072+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:20.072+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:14:20.098+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:20.098+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:14:20.051339+00:00, run_after=2023-01-30T20:14:20.051339+00:00
[2023-01-29T20:14:20.118+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.257 seconds
[2023-01-29T20:14:30.210+0000] {processor.py:153} INFO - Started process (PID=1002) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:30.212+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:14:30.212+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:30.212+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:37.252+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:37.319+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:37.318+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:14:37.343+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:37.342+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:14:37.243807+00:00, run_after=2023-01-30T20:14:37.243807+00:00
[2023-01-29T20:14:37.364+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.159 seconds
[2023-01-29T20:14:47.458+0000] {processor.py:153} INFO - Started process (PID=1008) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:47.459+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:14:47.460+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:47.459+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:55.994+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:14:56.007+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:56.007+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:14:56.033+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:14:56.032+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:14:55.986178+00:00, run_after=2023-01-30T20:14:55.986178+00:00
[2023-01-29T20:14:56.054+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.601 seconds
[2023-01-29T20:15:06.154+0000] {processor.py:153} INFO - Started process (PID=1014) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:06.155+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:15:06.156+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:06.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:13.408+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:13.489+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:13.488+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:15:13.522+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:13.521+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:15:13.400187+00:00, run_after=2023-01-30T20:15:13.400187+00:00
[2023-01-29T20:15:13.549+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.400 seconds
[2023-01-29T20:15:23.651+0000] {processor.py:153} INFO - Started process (PID=1020) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:23.652+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:15:23.653+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:23.653+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:32.047+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:32.060+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:32.059+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:15:32.087+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:32.087+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:15:32.039039+00:00, run_after=2023-01-30T20:15:32.039039+00:00
[2023-01-29T20:15:32.107+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.462 seconds
[2023-01-29T20:15:42.213+0000] {processor.py:153} INFO - Started process (PID=1026) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:42.216+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:15:42.218+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:42.217+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:49.364+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:49.448+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:49.448+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:15:49.477+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:49.477+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:15:49.350518+00:00, run_after=2023-01-30T20:15:49.350518+00:00
[2023-01-29T20:15:49.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.310 seconds
[2023-01-29T20:15:59.620+0000] {processor.py:153} INFO - Started process (PID=1032) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:15:59.623+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:15:59.625+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:15:59.625+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:07.830+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:07.846+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:07.846+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:16:07.873+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:07.873+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:16:07.818194+00:00, run_after=2023-01-30T20:16:07.818194+00:00
[2023-01-29T20:16:07.893+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.290 seconds
[2023-01-29T20:16:17.988+0000] {processor.py:153} INFO - Started process (PID=1038) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:17.990+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:16:17.991+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:17.991+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:25.583+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:25.647+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:25.647+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:16:25.671+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:25.671+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:16:25.575154+00:00, run_after=2023-01-30T20:16:25.575154+00:00
[2023-01-29T20:16:25.695+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.713 seconds
[2023-01-29T20:16:35.795+0000] {processor.py:153} INFO - Started process (PID=1044) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:35.796+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:16:35.797+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:35.797+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:44.073+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:44.085+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:44.084+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:16:44.114+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:44.114+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:16:44.063760+00:00, run_after=2023-01-30T20:16:44.063760+00:00
[2023-01-29T20:16:44.137+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.346 seconds
[2023-01-29T20:16:54.226+0000] {processor.py:153} INFO - Started process (PID=1050) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:16:54.237+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:16:54.238+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:16:54.238+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:01.745+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:01.812+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:01.811+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:17:01.840+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:01.839+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:17:01.736516+00:00, run_after=2023-01-30T20:17:01.736516+00:00
[2023-01-29T20:17:01.862+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.646 seconds
[2023-01-29T20:17:11.955+0000] {processor.py:153} INFO - Started process (PID=1056) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:11.956+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:17:11.957+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:11.957+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:20.235+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:20.249+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:20.248+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:17:20.274+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:20.274+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:17:20.221265+00:00, run_after=2023-01-30T20:17:20.221265+00:00
[2023-01-29T20:17:20.294+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.344 seconds
[2023-01-29T20:17:30.431+0000] {processor.py:153} INFO - Started process (PID=1062) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:30.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:17:30.437+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:30.437+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:38.398+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:38.482+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:38.481+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:17:38.507+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:38.507+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:17:38.385258+00:00, run_after=2023-01-30T20:17:38.385258+00:00
[2023-01-29T20:17:38.530+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.118 seconds
[2023-01-29T20:17:48.622+0000] {processor.py:153} INFO - Started process (PID=1068) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:48.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:17:48.625+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:48.624+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:57.029+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:17:57.042+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:57.042+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:17:57.071+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:17:57.071+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:17:57.020939+00:00, run_after=2023-01-30T20:17:57.020939+00:00
[2023-01-29T20:17:57.096+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.478 seconds
[2023-01-29T20:18:07.199+0000] {processor.py:153} INFO - Started process (PID=1074) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:07.200+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:18:07.202+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:07.202+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:15.567+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:15.631+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:15.631+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:18:15.656+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:15.655+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:18:15.559304+00:00, run_after=2023-01-30T20:18:15.559304+00:00
[2023-01-29T20:18:15.677+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.487 seconds
[2023-01-29T20:18:25.771+0000] {processor.py:153} INFO - Started process (PID=1080) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:25.772+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:18:25.773+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:25.773+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:33.597+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:33.626+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:33.625+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:18:33.670+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:33.670+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:18:33.555319+00:00, run_after=2023-01-30T20:18:33.555319+00:00
[2023-01-29T20:18:33.707+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.941 seconds
[2023-01-29T20:18:43.824+0000] {processor.py:153} INFO - Started process (PID=1086) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:43.830+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:18:43.832+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:43.832+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:53.477+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:53.542+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:53.541+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:18:53.565+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:53.565+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:18:53.468624+00:00, run_after=2023-01-30T20:18:53.468624+00:00
[2023-01-29T20:18:53.590+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.773 seconds
[2023-01-29T20:18:54.657+0000] {processor.py:153} INFO - Started process (PID=1092) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:18:54.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:18:54.660+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:18:54.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:03.758+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:03.771+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:03.770+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:19:03.798+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:03.797+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:19:03.750049+00:00, run_after=2023-01-30T20:19:03.750049+00:00
[2023-01-29T20:19:03.826+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.175 seconds
[2023-01-29T20:19:13.920+0000] {processor.py:153} INFO - Started process (PID=1098) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:13.921+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:19:13.922+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:13.922+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:22.172+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:22.197+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:22.196+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:19:22.233+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:22.233+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:19:22.154938+00:00, run_after=2023-01-30T20:19:22.154938+00:00
[2023-01-29T20:19:22.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.353 seconds
[2023-01-29T20:19:32.416+0000] {processor.py:153} INFO - Started process (PID=1104) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:32.418+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:19:32.419+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:32.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:41.954+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:42.031+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:42.030+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:19:42.105+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:42.104+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T20:19:41.945308+00:00, run_after=2023-01-30T20:19:41.945308+00:00
[2023-01-29T20:19:42.148+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.738 seconds
[2023-01-29T20:19:52.275+0000] {processor.py:153} INFO - Started process (PID=1110) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:52.276+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:19:52.277+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:19:52.277+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:19:59.825+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:20:00.049+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:00.049+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:data_pipeline_3
[2023-01-29T20:20:00.064+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:00.063+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:data_pipeline_3
[2023-01-29T20:20:00.075+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:00.074+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:data_pipeline_3
[2023-01-29T20:20:00.076+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:00.075+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:20:00.098+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:00.097+0000] {dag.py:2711} INFO - Creating ORM DAG for data_pipeline_3
[2023-01-29T20:20:00.116+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:00.116+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:19:59.810842+00:00, run_after=2023-01-30T20:19:59.810842+00:00
[2023-01-29T20:20:00.141+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.871 seconds
[2023-01-29T20:20:10.278+0000] {processor.py:153} INFO - Started process (PID=1116) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:20:10.280+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:20:10.281+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:10.280+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:20:25.270+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:20:25.286+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:25.285+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:20:25.324+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:25.324+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:20:25.258805+00:00, run_after=2023-01-30T20:20:25.258805+00:00
[2023-01-29T20:20:25.354+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 15.088 seconds
[2023-01-29T20:20:35.496+0000] {processor.py:153} INFO - Started process (PID=1127) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:20:35.502+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:20:35.504+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:35.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:20:46.735+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:20:46.806+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:46.805+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:20:46.832+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:46.832+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:20:46.724524+00:00, run_after=2023-01-30T20:20:46.724524+00:00
[2023-01-29T20:20:46.862+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 11.377 seconds
[2023-01-29T20:20:56.982+0000] {processor.py:153} INFO - Started process (PID=1135) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:20:56.984+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:20:56.986+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:20:56.985+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:21:12.472+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:21:12.491+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:21:12.490+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:21:12.539+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:21:12.539+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:21:12.463780+00:00, run_after=2023-01-30T20:21:12.463780+00:00
[2023-01-29T20:21:12.565+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 15.589 seconds
[2023-01-29T20:21:22.716+0000] {processor.py:153} INFO - Started process (PID=1146) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:21:22.718+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:21:22.719+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:21:22.719+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:21:31.198+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:21:31.272+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:21:31.272+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:21:31.312+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:21:31.312+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:21:31.189830+00:00, run_after=2023-01-30T20:21:31.189830+00:00
[2023-01-29T20:21:31.347+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.637 seconds
[2023-01-29T20:21:41.488+0000] {processor.py:153} INFO - Started process (PID=1155) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:21:41.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:21:41.490+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:21:41.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:21:50.256+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:21:50.269+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:21:50.268+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:21:50.298+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:21:50.298+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:21:50.247001+00:00, run_after=2023-01-30T20:21:50.247001+00:00
[2023-01-29T20:21:50.320+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.841 seconds
[2023-01-29T20:22:00.431+0000] {processor.py:153} INFO - Started process (PID=1161) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:00.432+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:22:00.433+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:00.433+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:07.598+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:07.666+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:07.666+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:22:07.697+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:07.697+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:22:07.589307+00:00, run_after=2023-01-30T20:22:07.589307+00:00
[2023-01-29T20:22:07.719+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.293 seconds
[2023-01-29T20:22:17.812+0000] {processor.py:153} INFO - Started process (PID=1167) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:17.813+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:22:17.814+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:17.814+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:26.726+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:26.740+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:26.739+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:22:26.765+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:26.765+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:22:26.716910+00:00, run_after=2023-01-30T20:22:26.716910+00:00
[2023-01-29T20:22:26.785+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.978 seconds
[2023-01-29T20:22:36.884+0000] {processor.py:153} INFO - Started process (PID=1173) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:36.888+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:22:36.889+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:36.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:44.364+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:44.432+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:44.431+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:22:44.460+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:44.459+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:22:44.356060+00:00, run_after=2023-01-30T20:22:44.356060+00:00
[2023-01-29T20:22:44.482+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.604 seconds
[2023-01-29T20:22:54.581+0000] {processor.py:153} INFO - Started process (PID=1179) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:22:54.582+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:22:54.582+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:22:54.582+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:02.927+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:02.940+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:02.939+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:23:02.965+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:02.965+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:23:02.919246+00:00, run_after=2023-01-30T20:23:02.919246+00:00
[2023-01-29T20:23:02.985+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.409 seconds
[2023-01-29T20:23:13.080+0000] {processor.py:153} INFO - Started process (PID=1185) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:13.081+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:23:13.082+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:13.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:20.589+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:20.658+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:20.658+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:23:20.688+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:20.688+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:23:20.580765+00:00, run_after=2023-01-30T20:23:20.580765+00:00
[2023-01-29T20:23:20.713+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.638 seconds
[2023-01-29T20:23:30.812+0000] {processor.py:153} INFO - Started process (PID=1191) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:30.813+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:23:30.814+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:30.814+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:39.376+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:39.399+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:39.398+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:23:39.449+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:39.449+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:23:39.360461+00:00, run_after=2023-01-30T20:23:39.360461+00:00
[2023-01-29T20:23:39.471+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.663 seconds
[2023-01-29T20:23:49.563+0000] {processor.py:153} INFO - Started process (PID=1197) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:49.564+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:23:49.565+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:49.565+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:56.962+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:23:57.054+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:57.053+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:23:57.078+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:23:57.078+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:23:56.943729+00:00, run_after=2023-01-30T20:23:56.943729+00:00
[2023-01-29T20:23:57.102+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.544 seconds
[2023-01-29T20:24:07.214+0000] {processor.py:153} INFO - Started process (PID=1203) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:07.215+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:24:07.216+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:07.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:16.043+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:16.055+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:16.055+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:24:16.081+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:16.081+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:24:16.034699+00:00, run_after=2023-01-30T20:24:16.034699+00:00
[2023-01-29T20:24:16.101+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.893 seconds
[2023-01-29T20:24:26.203+0000] {processor.py:153} INFO - Started process (PID=1209) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:26.205+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:24:26.207+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:26.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:33.770+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:33.854+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:33.853+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:24:33.878+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:33.878+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:24:33.759995+00:00, run_after=2023-01-30T20:24:33.759995+00:00
[2023-01-29T20:24:33.900+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.704 seconds
[2023-01-29T20:24:43.983+0000] {processor.py:153} INFO - Started process (PID=1215) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:43.985+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:24:43.985+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:43.985+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:52.793+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:24:52.806+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:52.805+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:24:52.832+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:24:52.832+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:24:52.785172+00:00, run_after=2023-01-30T20:24:52.785172+00:00
[2023-01-29T20:24:52.853+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.874 seconds
[2023-01-29T20:25:02.950+0000] {processor.py:153} INFO - Started process (PID=1221) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:02.951+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:25:02.952+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:02.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:10.037+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:10.118+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:10.117+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:25:10.142+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:10.142+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:25:10.029297+00:00, run_after=2023-01-30T20:25:10.029297+00:00
[2023-01-29T20:25:10.170+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.225 seconds
[2023-01-29T20:25:20.256+0000] {processor.py:153} INFO - Started process (PID=1227) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:20.257+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:25:20.257+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:20.257+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:28.786+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:28.803+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:28.802+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:25:28.835+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:28.835+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:25:28.776031+00:00, run_after=2023-01-30T20:25:28.776031+00:00
[2023-01-29T20:25:28.855+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.604 seconds
[2023-01-29T20:25:38.967+0000] {processor.py:153} INFO - Started process (PID=1233) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:38.968+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:25:38.969+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:38.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:46.415+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:46.478+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:46.477+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:25:46.516+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:46.516+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:25:46.404655+00:00, run_after=2023-01-30T20:25:46.404655+00:00
[2023-01-29T20:25:46.538+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.577 seconds
[2023-01-29T20:25:56.625+0000] {processor.py:153} INFO - Started process (PID=1239) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:25:56.626+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:25:56.627+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:25:56.627+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:05.112+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:05.124+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:05.124+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:26:05.151+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:05.150+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:26:05.103688+00:00, run_after=2023-01-30T20:26:05.103688+00:00
[2023-01-29T20:26:05.171+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.551 seconds
[2023-01-29T20:26:15.273+0000] {processor.py:153} INFO - Started process (PID=1245) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:15.275+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:26:15.276+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:15.276+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:22.873+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:22.950+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:22.949+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:26:22.977+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:22.977+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:26:22.865144+00:00, run_after=2023-01-30T20:26:22.865144+00:00
[2023-01-29T20:26:23.002+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.733 seconds
[2023-01-29T20:26:33.095+0000] {processor.py:153} INFO - Started process (PID=1251) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:33.096+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:26:33.097+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:33.096+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:41.276+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:41.288+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:41.288+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:26:41.314+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:41.313+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:26:41.268258+00:00, run_after=2023-01-30T20:26:41.268258+00:00
[2023-01-29T20:26:41.333+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.243 seconds
[2023-01-29T20:26:51.439+0000] {processor.py:153} INFO - Started process (PID=1257) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:51.443+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:26:51.444+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:51.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:58.984+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:26:59.076+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:59.075+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:26:59.100+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:26:59.099+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:26:58.976135+00:00, run_after=2023-01-30T20:26:58.976135+00:00
[2023-01-29T20:26:59.123+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.696 seconds
[2023-01-29T20:27:09.221+0000] {processor.py:153} INFO - Started process (PID=1263) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:09.223+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:27:09.224+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:09.223+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:18.049+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:18.062+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:18.062+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:27:18.090+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:18.090+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:27:18.041223+00:00, run_after=2023-01-30T20:27:18.041223+00:00
[2023-01-29T20:27:18.115+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.899 seconds
[2023-01-29T20:27:28.232+0000] {processor.py:153} INFO - Started process (PID=1269) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:28.233+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:27:28.235+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:28.234+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:35.436+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:35.514+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:35.514+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:27:35.539+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:35.539+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:27:35.427802+00:00, run_after=2023-01-30T20:27:35.427802+00:00
[2023-01-29T20:27:35.561+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.335 seconds
[2023-01-29T20:27:45.653+0000] {processor.py:153} INFO - Started process (PID=1275) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:45.654+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:27:45.655+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:45.655+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:54.397+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:27:54.415+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:54.414+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:27:54.456+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:27:54.456+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:27:54.383922+00:00, run_after=2023-01-30T20:27:54.383922+00:00
[2023-01-29T20:27:54.476+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.828 seconds
[2023-01-29T20:28:04.579+0000] {processor.py:153} INFO - Started process (PID=1281) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:04.581+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:28:04.582+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:04.582+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:12.338+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:12.405+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:12.405+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:28:12.431+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:12.431+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:28:12.329644+00:00, run_after=2023-01-30T20:28:12.329644+00:00
[2023-01-29T20:28:12.453+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.880 seconds
[2023-01-29T20:28:22.527+0000] {processor.py:153} INFO - Started process (PID=1287) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:22.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:28:22.528+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:22.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:31.262+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:31.274+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:31.274+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:28:31.300+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:31.300+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:28:31.253951+00:00, run_after=2023-01-30T20:28:31.253951+00:00
[2023-01-29T20:28:31.325+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.803 seconds
[2023-01-29T20:28:41.509+0000] {processor.py:153} INFO - Started process (PID=1293) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:41.519+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:28:41.521+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:41.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:48.766+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:48.829+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:48.829+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:28:48.852+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:48.852+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:28:48.758143+00:00, run_after=2023-01-30T20:28:48.758143+00:00
[2023-01-29T20:28:48.880+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.391 seconds
[2023-01-29T20:28:58.972+0000] {processor.py:153} INFO - Started process (PID=1299) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:28:58.973+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:28:58.974+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:28:58.974+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:07.354+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:07.367+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:07.366+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:29:07.396+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:07.396+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:29:07.345630+00:00, run_after=2023-01-30T20:29:07.345630+00:00
[2023-01-29T20:29:07.423+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.455 seconds
[2023-01-29T20:29:17.564+0000] {processor.py:153} INFO - Started process (PID=1305) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:17.577+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:29:17.578+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:17.578+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:25.525+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:25.644+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:25.643+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:29:25.729+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:25.729+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:29:25.512572+00:00, run_after=2023-01-30T20:29:25.512572+00:00
[2023-01-29T20:29:25.792+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.237 seconds
[2023-01-29T20:29:35.916+0000] {processor.py:153} INFO - Started process (PID=1311) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:35.917+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:29:35.917+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:35.917+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:44.669+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:44.681+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:44.680+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:29:44.707+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:44.707+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:29:44.660741+00:00, run_after=2023-01-30T20:29:44.660741+00:00
[2023-01-29T20:29:44.728+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.817 seconds
[2023-01-29T20:29:54.823+0000] {processor.py:153} INFO - Started process (PID=1317) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:29:54.825+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:29:54.826+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:29:54.826+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:02.631+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:02.697+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:02.696+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:30:02.722+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:02.722+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:30:02.623121+00:00, run_after=2023-01-30T20:30:02.623121+00:00
[2023-01-29T20:30:02.744+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.929 seconds
[2023-01-29T20:30:12.849+0000] {processor.py:153} INFO - Started process (PID=1323) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:12.850+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:30:12.851+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:12.851+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:23.434+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:23.446+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:23.446+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:30:23.472+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:23.471+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:30:23.424756+00:00, run_after=2023-01-30T20:30:23.424756+00:00
[2023-01-29T20:30:23.491+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.646 seconds
[2023-01-29T20:30:33.637+0000] {processor.py:153} INFO - Started process (PID=1329) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:33.645+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:30:33.647+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:33.646+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:42.538+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_3']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:42.605+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:42.605+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:30:42.645+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:42.645+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_3 to 2023-01-29T20:30:42.530049+00:00, run_after=2023-01-30T20:30:42.530049+00:00
[2023-01-29T20:30:42.673+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.052 seconds
[2023-01-29T20:30:52.795+0000] {processor.py:153} INFO - Started process (PID=1335) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:30:52.796+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:30:52.798+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:30:52.797+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:02.653+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:31:02.652+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:31:02.654+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:02.673+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.885 seconds
[2023-01-29T20:31:05.736+0000] {processor.py:153} INFO - Started process (PID=1341) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:05.737+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:31:05.738+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:31:05.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:14.555+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:31:14.553+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:31:14.556+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:14.579+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.849 seconds
[2023-01-29T20:31:21.969+0000] {processor.py:153} INFO - Started process (PID=1347) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:21.970+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:31:21.971+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:31:21.970+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:30.419+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:31:30.417+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:31:30.419+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:30.439+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.476 seconds
[2023-01-29T20:31:35.510+0000] {processor.py:153} INFO - Started process (PID=1353) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:35.511+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:31:35.512+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:31:35.511+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:43.755+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:31:43.752+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:31:43.755+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:43.779+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.275 seconds
[2023-01-29T20:31:53.874+0000] {processor.py:153} INFO - Started process (PID=1359) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:31:53.875+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:31:53.876+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:31:53.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:01.131+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:32:01.129+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:32:01.131+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:01.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.281 seconds
[2023-01-29T20:32:11.256+0000] {processor.py:153} INFO - Started process (PID=1365) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:11.258+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:32:11.259+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:32:11.258+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:19.773+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:32:19.771+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:32:19.774+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:19.792+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.543 seconds
[2023-01-29T20:32:29.891+0000] {processor.py:153} INFO - Started process (PID=1371) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:29.892+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:32:29.893+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:32:29.893+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:37.495+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:32:37.493+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:32:37.496+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:37.521+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.635 seconds
[2023-01-29T20:32:47.610+0000] {processor.py:153} INFO - Started process (PID=1377) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:47.611+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:32:47.616+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:32:47.615+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:56.246+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:32:56.244+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:32:56.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:32:56.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.664 seconds
[2023-01-29T20:33:06.367+0000] {processor.py:153} INFO - Started process (PID=1383) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:06.368+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:33:06.369+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:33:06.369+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:14.068+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:33:14.067+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:33:14.069+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:14.091+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.728 seconds
[2023-01-29T20:33:24.190+0000] {processor.py:153} INFO - Started process (PID=1389) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:24.191+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:33:24.192+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:33:24.192+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:32.797+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:33:32.795+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:33:32.797+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:32.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.631 seconds
[2023-01-29T20:33:42.925+0000] {processor.py:153} INFO - Started process (PID=1395) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:42.927+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:33:42.928+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:33:42.928+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:50.018+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:33:50.015+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:33:50.018+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:33:50.046+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.127 seconds
[2023-01-29T20:34:00.135+0000] {processor.py:153} INFO - Started process (PID=1401) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:00.136+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:34:00.137+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:00.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:08.464+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:08.462+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:34:08.465+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:08.485+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.355 seconds
[2023-01-29T20:34:18.575+0000] {processor.py:153} INFO - Started process (PID=1407) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:18.577+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:34:18.578+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:18.577+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:25.901+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:25.899+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:34:25.902+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:25.925+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.354 seconds
[2023-01-29T20:34:36.017+0000] {processor.py:153} INFO - Started process (PID=1413) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:36.018+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:34:36.019+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:36.018+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:45.236+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:45.233+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:34:45.243+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:45.289+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.277 seconds
[2023-01-29T20:34:47.110+0000] {processor.py:153} INFO - Started process (PID=1419) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:47.111+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:34:47.112+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:47.111+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:56.015+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:56.011+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:34:56.016+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:56.055+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.950 seconds
[2023-01-29T20:34:59.121+0000] {processor.py:153} INFO - Started process (PID=1425) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:34:59.122+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:34:59.122+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:34:59.122+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:08.194+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:35:08.191+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:35:08.194+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:08.244+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.128 seconds
[2023-01-29T20:35:18.381+0000] {processor.py:153} INFO - Started process (PID=1431) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:18.383+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:35:18.394+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:35:18.393+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:27.557+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:35:27.556+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 104, in <module>
    op_kwargs={"job": "Data Scientist"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:35:27.558+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:27.581+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.207 seconds
[2023-01-29T20:35:29.459+0000] {processor.py:153} INFO - Started process (PID=1437) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:29.460+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:35:29.461+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:35:29.461+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:38.532+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:35:38.530+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 120, in <module>
    op_kwargs={"job": "Machine Learning Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'extract_data' has already been added to the DAG
[2023-01-29T20:35:38.532+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:38.551+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.098 seconds
[2023-01-29T20:35:43.605+0000] {processor.py:153} INFO - Started process (PID=1443) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:43.606+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:35:43.607+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:35:43.607+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:52.771+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:35:52.769+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:35:52.772+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:35:52.791+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.190 seconds
[2023-01-29T20:36:02.884+0000] {processor.py:153} INFO - Started process (PID=1449) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:02.885+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:36:02.886+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:36:02.886+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:10.214+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:36:10.208+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:36:10.215+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:10.262+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.384 seconds
[2023-01-29T20:36:20.409+0000] {processor.py:153} INFO - Started process (PID=1455) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:20.410+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:36:20.411+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:36:20.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:28.989+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:36:28.987+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:36:28.990+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:29.010+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.607 seconds
[2023-01-29T20:36:39.092+0000] {processor.py:153} INFO - Started process (PID=1461) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:39.093+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:36:39.094+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:36:39.094+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:46.226+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:36:46.224+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:36:46.227+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:46.257+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.170 seconds
[2023-01-29T20:36:56.380+0000] {processor.py:153} INFO - Started process (PID=1467) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:36:56.381+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:36:56.382+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:36:56.382+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:05.068+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:37:05.067+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:37:05.069+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:05.089+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.714 seconds
[2023-01-29T20:37:15.185+0000] {processor.py:153} INFO - Started process (PID=1473) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:15.186+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:37:15.187+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:37:15.187+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:22.543+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:37:22.541+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:37:22.543+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:22.563+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.383 seconds
[2023-01-29T20:37:32.664+0000] {processor.py:153} INFO - Started process (PID=1479) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:32.666+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:37:32.667+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:37:32.667+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:41.146+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:37:41.144+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:37:41.147+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:41.174+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.516 seconds
[2023-01-29T20:37:45.728+0000] {processor.py:153} INFO - Started process (PID=1485) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:45.729+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:37:45.731+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:37:45.730+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:54.021+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:37:54.019+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:37:54.021+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:37:54.050+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.327 seconds
[2023-01-29T20:38:04.158+0000] {processor.py:153} INFO - Started process (PID=1491) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:04.159+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:38:04.160+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:38:04.160+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:11.365+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:38:11.363+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 148, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:38:11.365+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:11.386+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.234 seconds
[2023-01-29T20:38:16.229+0000] {processor.py:153} INFO - Started process (PID=1497) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:16.230+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:38:16.231+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:38:16.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:24.272+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:38:24.269+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 150, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:38:24.272+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:24.311+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.087 seconds
[2023-01-29T20:38:34.423+0000] {processor.py:153} INFO - Started process (PID=1503) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:34.425+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:38:34.426+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:38:34.426+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:43.063+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:38:43.061+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 150, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:38:43.063+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:43.090+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.672 seconds
[2023-01-29T20:38:53.191+0000] {processor.py:153} INFO - Started process (PID=1509) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:38:53.192+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:38:53.193+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:38:53.193+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:00.268+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:39:00.265+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 150, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:39:00.268+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:00.294+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.109 seconds
[2023-01-29T20:39:10.393+0000] {processor.py:153} INFO - Started process (PID=1515) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:10.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:39:10.395+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:39:10.394+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:18.715+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:39:18.714+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 150, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:39:18.716+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:18.735+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.348 seconds
[2023-01-29T20:39:28.826+0000] {processor.py:153} INFO - Started process (PID=1521) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:28.827+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:39:28.827+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:39:28.827+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:36.249+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:39:36.247+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 150, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:39:36.249+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:36.313+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.492 seconds
[2023-01-29T20:39:46.409+0000] {processor.py:153} INFO - Started process (PID=1527) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:46.410+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:39:46.411+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:39:46.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:55.510+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:39:55.509+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 150, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:39:55.511+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:39:55.537+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.132 seconds
[2023-01-29T20:40:05.658+0000] {processor.py:153} INFO - Started process (PID=1533) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:05.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:40:05.660+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:05.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:13.335+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:13.334+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 150, in <module>
    op_kwargs={"job": "Data Engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data' has already been added to the DAG
[2023-01-29T20:40:13.336+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:13.355+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.702 seconds
[2023-01-29T20:40:15.740+0000] {processor.py:153} INFO - Started process (PID=1539) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:15.742+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:40:15.743+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:15.743+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:25.332+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:25.331+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 140, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:40:25.333+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:25.353+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.628 seconds
[2023-01-29T20:40:27.788+0000] {processor.py:153} INFO - Started process (PID=1545) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:27.789+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:40:27.790+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:27.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:36.303+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:36.301+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 141, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:40:36.303+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:36.327+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.544 seconds
[2023-01-29T20:40:46.434+0000] {processor.py:153} INFO - Started process (PID=1551) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:46.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:40:46.436+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:46.436+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:55.085+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:55.082+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 141, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:40:55.085+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:55.132+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.702 seconds
[2023-01-29T20:40:56.277+0000] {processor.py:153} INFO - Started process (PID=1557) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:40:56.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:40:56.280+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:40:56.280+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:04.417+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:41:04.415+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 141, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:41:04.418+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:04.437+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.167 seconds
[2023-01-29T20:41:06.407+0000] {processor.py:153} INFO - Started process (PID=1563) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:06.408+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:41:06.409+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:41:06.409+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:14.729+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:41:14.727+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:41:14.729+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:14.751+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.358 seconds
[2023-01-29T20:41:24.837+0000] {processor.py:153} INFO - Started process (PID=1569) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:24.838+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:41:24.839+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:41:24.839+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:33.246+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:41:33.244+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:41:33.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:33.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.435 seconds
[2023-01-29T20:41:43.377+0000] {processor.py:153} INFO - Started process (PID=1575) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:43.379+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:41:43.381+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:41:43.380+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:51.878+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:41:51.877+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:41:51.879+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:41:51.898+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.528 seconds
[2023-01-29T20:42:02.001+0000] {processor.py:153} INFO - Started process (PID=1581) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:02.003+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:42:02.003+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:42:02.003+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:09.907+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:42:09.904+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:42:09.908+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:09.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.938 seconds
[2023-01-29T20:42:20.040+0000] {processor.py:153} INFO - Started process (PID=1587) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:20.041+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:42:20.042+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:42:20.042+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:29.172+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:42:29.170+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:42:29.172+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:29.192+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.157 seconds
[2023-01-29T20:42:39.279+0000] {processor.py:153} INFO - Started process (PID=1593) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:39.280+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:42:39.281+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:42:39.281+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:47.702+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:42:47.700+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:42:47.703+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:47.731+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.458 seconds
[2023-01-29T20:42:57.837+0000] {processor.py:153} INFO - Started process (PID=1599) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:42:57.838+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:42:57.839+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:42:57.839+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:06.041+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:43:06.040+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:43:06.042+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:06.064+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.232 seconds
[2023-01-29T20:43:16.161+0000] {processor.py:153} INFO - Started process (PID=1605) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:16.162+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:43:16.163+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:43:16.163+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:24.244+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:43:24.241+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:43:24.245+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:24.272+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.116 seconds
[2023-01-29T20:43:34.464+0000] {processor.py:153} INFO - Started process (PID=1611) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:34.465+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:43:34.466+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:43:34.466+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:42.611+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:43:42.609+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:43:42.612+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:42.632+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.172 seconds
[2023-01-29T20:43:52.720+0000] {processor.py:153} INFO - Started process (PID=1617) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:52.721+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:43:52.722+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:43:52.721+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:59.608+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:43:59.605+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:43:59.609+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:43:59.632+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.917 seconds
[2023-01-29T20:44:09.717+0000] {processor.py:153} INFO - Started process (PID=1623) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:09.719+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:44:09.719+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:44:09.719+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:17.932+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:44:17.931+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:44:17.933+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:17.953+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.241 seconds
[2023-01-29T20:44:28.045+0000] {processor.py:153} INFO - Started process (PID=1629) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:28.046+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:44:28.047+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:44:28.047+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:35.186+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:44:35.185+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:44:35.187+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:35.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.167 seconds
[2023-01-29T20:44:45.298+0000] {processor.py:153} INFO - Started process (PID=1635) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:45.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:44:45.301+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:44:45.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:53.609+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:44:53.608+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:44:53.610+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:44:53.629+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.337 seconds
[2023-01-29T20:45:03.723+0000] {processor.py:153} INFO - Started process (PID=1641) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:03.724+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:45:03.725+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:45:03.725+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:10.610+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:45:10.608+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:45:10.610+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:10.630+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.911 seconds
[2023-01-29T20:45:20.735+0000] {processor.py:153} INFO - Started process (PID=1647) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:20.736+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:45:20.738+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:45:20.737+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:29.366+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:45:29.363+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:45:29.366+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:29.389+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.661 seconds
[2023-01-29T20:45:39.501+0000] {processor.py:153} INFO - Started process (PID=1653) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:39.502+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:45:39.503+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:45:39.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:46.519+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:45:46.517+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:45:46.519+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:46.542+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.045 seconds
[2023-01-29T20:45:56.599+0000] {processor.py:153} INFO - Started process (PID=1659) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:45:56.601+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:45:56.602+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:45:56.602+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:05.037+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:46:05.035+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:46:05.037+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:05.058+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.464 seconds
[2023-01-29T20:46:15.152+0000] {processor.py:153} INFO - Started process (PID=1665) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:15.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:46:15.154+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:46:15.154+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:22.186+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:46:22.184+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:46:22.187+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:22.210+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.063 seconds
[2023-01-29T20:46:32.302+0000] {processor.py:153} INFO - Started process (PID=1671) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:32.304+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:46:32.305+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:46:32.305+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:44.968+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:46:44.966+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:46:44.969+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:44.999+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 12.706 seconds
[2023-01-29T20:46:55.207+0000] {processor.py:153} INFO - Started process (PID=1677) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:46:55.209+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:46:55.210+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:46:55.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:47:14.050+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:47:14.047+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:47:14.050+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:47:14.104+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 18.914 seconds
[2023-01-29T20:47:24.243+0000] {processor.py:153} INFO - Started process (PID=1683) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:47:24.244+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:47:24.245+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:47:24.245+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:47:31.660+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:47:31.658+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:47:31.660+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:47:31.680+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.442 seconds
[2023-01-29T20:47:41.772+0000] {processor.py:153} INFO - Started process (PID=1689) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:47:41.773+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:47:41.774+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:47:41.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:47:50.191+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:47:50.189+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:47:50.191+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:47:50.210+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.442 seconds
[2023-01-29T20:48:00.306+0000] {processor.py:153} INFO - Started process (PID=1695) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:00.307+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:48:00.308+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:48:00.308+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:07.100+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:48:07.098+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:48:07.101+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:07.127+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.828 seconds
[2023-01-29T20:48:17.245+0000] {processor.py:153} INFO - Started process (PID=1701) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:17.247+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:48:17.248+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:48:17.247+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:26.589+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:48:26.587+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:48:26.589+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:26.610+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.371 seconds
[2023-01-29T20:48:36.706+0000] {processor.py:153} INFO - Started process (PID=1707) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:36.708+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:48:36.709+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:48:36.709+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:44.169+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:48:44.168+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:48:44.170+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:44.189+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.490 seconds
[2023-01-29T20:48:54.297+0000] {processor.py:153} INFO - Started process (PID=1713) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:48:54.298+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:48:54.299+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:48:54.299+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:02.853+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:49:02.851+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:49:02.853+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:02.882+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.591 seconds
[2023-01-29T20:49:12.986+0000] {processor.py:153} INFO - Started process (PID=1719) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:12.987+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:49:12.988+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:49:12.988+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:20.700+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:49:20.698+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:49:20.700+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:20.720+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.741 seconds
[2023-01-29T20:49:30.816+0000] {processor.py:153} INFO - Started process (PID=1725) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:30.817+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:49:30.818+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:49:30.818+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:38.593+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:49:38.590+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:49:38.594+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:38.620+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.809 seconds
[2023-01-29T20:49:48.721+0000] {processor.py:153} INFO - Started process (PID=1731) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:48.722+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:49:48.723+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:49:48.723+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:56.506+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:49:56.504+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:49:56.506+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:49:56.526+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.809 seconds
[2023-01-29T20:50:06.616+0000] {processor.py:153} INFO - Started process (PID=1737) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:06.617+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:50:06.618+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:50:06.618+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:13.507+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:50:13.505+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:50:13.508+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:13.528+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.918 seconds
[2023-01-29T20:50:23.615+0000] {processor.py:153} INFO - Started process (PID=1743) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:23.616+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:50:23.617+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:50:23.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:32.219+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:50:32.217+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:50:32.220+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:32.239+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.628 seconds
[2023-01-29T20:50:42.338+0000] {processor.py:153} INFO - Started process (PID=1749) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:42.340+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:50:42.341+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:50:42.341+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:49.260+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:50:49.259+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:50:49.261+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:49.280+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.947 seconds
[2023-01-29T20:50:59.394+0000] {processor.py:153} INFO - Started process (PID=1755) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:50:59.395+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:50:59.396+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:50:59.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:07.530+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:51:07.527+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:51:07.530+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:07.567+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.178 seconds
[2023-01-29T20:51:17.656+0000] {processor.py:153} INFO - Started process (PID=1761) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:17.657+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:51:17.658+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:51:17.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:24.573+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:51:24.572+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:51:24.574+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:24.593+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.943 seconds
[2023-01-29T20:51:34.678+0000] {processor.py:153} INFO - Started process (PID=1767) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:34.679+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:51:34.680+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:51:34.679+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:43.037+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:51:43.035+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:51:43.038+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:43.060+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.388 seconds
[2023-01-29T20:51:53.172+0000] {processor.py:153} INFO - Started process (PID=1773) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:51:53.174+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:51:53.175+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:51:53.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:00.253+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:52:00.252+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:52:00.254+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:00.275+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.109 seconds
[2023-01-29T20:52:10.359+0000] {processor.py:153} INFO - Started process (PID=1779) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:10.360+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:52:10.360+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:52:10.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:18.729+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:52:18.727+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:52:18.730+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:18.751+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.397 seconds
[2023-01-29T20:52:28.987+0000] {processor.py:153} INFO - Started process (PID=1785) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:28.995+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:52:28.999+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:52:28.999+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:38.425+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:52:38.423+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:52:38.425+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:38.445+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.478 seconds
[2023-01-29T20:52:46.024+0000] {processor.py:153} INFO - Started process (PID=1791) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:46.026+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:52:46.026+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:52:46.026+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:53.727+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:52:53.725+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:52:53.728+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:53.753+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.734 seconds
[2023-01-29T20:52:59.620+0000] {processor.py:153} INFO - Started process (PID=1797) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:52:59.621+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:52:59.622+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:52:59.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:08.171+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:53:08.169+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:53:08.171+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:08.196+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.580 seconds
[2023-01-29T20:53:12.907+0000] {processor.py:153} INFO - Started process (PID=1803) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:12.908+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:53:12.909+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:53:12.909+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:23.150+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:53:23.148+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:53:23.151+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:23.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.270 seconds
[2023-01-29T20:53:26.995+0000] {processor.py:153} INFO - Started process (PID=1809) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:26.996+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:53:26.997+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:53:26.997+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:35.723+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:53:35.721+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:53:35.724+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:35.743+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.753 seconds
[2023-01-29T20:53:45.841+0000] {processor.py:153} INFO - Started process (PID=1815) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:45.842+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:53:45.843+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:53:45.843+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:53.226+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:53:53.225+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:53:53.227+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:53:53.247+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.411 seconds
[2023-01-29T20:54:03.348+0000] {processor.py:153} INFO - Started process (PID=1821) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:03.349+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:54:03.350+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:54:03.350+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:14.140+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:54:14.138+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:54:14.141+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:14.173+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.831 seconds
[2023-01-29T20:54:24.292+0000] {processor.py:153} INFO - Started process (PID=1827) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:24.294+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:54:24.295+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:54:24.295+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:32.267+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:54:32.265+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:54:32.267+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:32.286+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.000 seconds
[2023-01-29T20:54:42.413+0000] {processor.py:153} INFO - Started process (PID=1833) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:42.415+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:54:42.415+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:54:42.415+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:52.373+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:54:52.372+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:54:52.374+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:52.393+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.985 seconds
[2023-01-29T20:54:53.277+0000] {processor.py:153} INFO - Started process (PID=1839) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:54:53.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:54:53.279+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:54:53.279+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:02.728+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:55:02.727+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:55:02.729+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:02.749+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.477 seconds
[2023-01-29T20:55:03.555+0000] {processor.py:153} INFO - Started process (PID=1845) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:03.556+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:55:03.556+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:55:03.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:10.833+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:55:10.832+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:55:10.834+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:10.856+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.306 seconds
[2023-01-29T20:55:20.949+0000] {processor.py:153} INFO - Started process (PID=1851) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:20.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:55:20.951+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:55:20.951+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:29.969+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:55:29.967+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 142, in <module>
    op_kwargs={"task_id": "extract_data_task_ml_engineer"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:55:29.970+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:29.990+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.045 seconds
[2023-01-29T20:55:40.068+0000] {processor.py:153} INFO - Started process (PID=1857) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:40.070+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:55:40.070+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:55:40.070+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:46.977+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:55:46.976+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 143, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:55:46.978+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:46.997+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.934 seconds
[2023-01-29T20:55:57.102+0000] {processor.py:153} INFO - Started process (PID=1863) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:55:57.104+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:55:57.105+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:55:57.105+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:05.709+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:05.707+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 143, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:56:05.709+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:05.729+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.633 seconds
[2023-01-29T20:56:15.824+0000] {processor.py:153} INFO - Started process (PID=1869) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:15.825+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:56:15.826+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:15.826+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:23.179+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:23.177+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 143, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 160, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 760, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 220, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'transform_data_task' has already been added to the DAG
[2023-01-29T20:56:23.179+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:23.203+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.384 seconds
[2023-01-29T20:56:24.909+0000] {processor.py:153} INFO - Started process (PID=1875) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:24.910+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:56:24.911+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:24.911+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:33.593+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:33.736+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:33.734+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:56:33.784+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:33.784+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:56:33.580735+00:00, run_after=2023-01-30T20:56:33.580735+00:00
[2023-01-29T20:56:33.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.920 seconds
[2023-01-29T20:56:37.908+0000] {processor.py:153} INFO - Started process (PID=1881) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:37.909+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:56:37.911+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:37.910+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:46.370+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:46.382+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:46.381+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:56:46.408+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:46.408+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:56:46.360948+00:00, run_after=2023-01-30T20:56:46.360948+00:00
[2023-01-29T20:56:46.430+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.529 seconds
[2023-01-29T20:56:56.488+0000] {processor.py:153} INFO - Started process (PID=1887) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:56:56.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:56:56.490+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:56:56.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:57:05.044+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:57:05.126+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:57:05.125+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:57:05.164+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:57:05.164+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:57:05.034560+00:00, run_after=2023-01-30T20:57:05.034560+00:00
[2023-01-29T20:57:05.195+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.712 seconds
[2023-01-29T20:57:15.391+0000] {processor.py:153} INFO - Started process (PID=1893) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:57:15.393+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:57:15.394+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:57:15.394+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:57:23.460+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:57:23.472+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:57:23.472+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:57:23.498+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:57:23.498+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:57:23.451997+00:00, run_after=2023-01-30T20:57:23.451997+00:00
[2023-01-29T20:57:23.518+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.133 seconds
[2023-01-29T20:57:33.601+0000] {processor.py:153} INFO - Started process (PID=1899) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:57:33.602+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:57:33.603+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:57:33.603+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:57:53.734+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:57:54.060+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:57:54.056+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:57:54.172+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:57:54.172+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:57:53.669781+00:00, run_after=2023-01-30T20:57:53.669781+00:00
[2023-01-29T20:57:54.229+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 20.633 seconds
[2023-01-29T20:58:04.429+0000] {processor.py:153} INFO - Started process (PID=1915) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:58:04.434+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:58:04.435+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:58:04.435+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:58:18.281+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:58:18.297+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:58:18.296+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:58:18.343+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:58:18.342+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:58:18.268199+00:00, run_after=2023-01-30T20:58:18.268199+00:00
[2023-01-29T20:58:18.383+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 13.965 seconds
[2023-01-29T20:58:28.597+0000] {processor.py:153} INFO - Started process (PID=1928) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:58:28.609+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:58:28.610+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:58:28.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:58:51.933+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:58:52.173+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:58:52.168+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:58:52.294+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:58:52.294+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:58:51.906315+00:00, run_after=2023-01-30T20:58:51.906315+00:00
[2023-01-29T20:58:52.337+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 23.750 seconds
[2023-01-29T20:59:02.460+0000] {processor.py:153} INFO - Started process (PID=1944) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:02.462+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:59:02.463+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:02.463+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:10.364+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:10.382+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:10.381+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:59:10.412+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:10.412+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:59:10.350488+00:00, run_after=2023-01-30T20:59:10.350488+00:00
[2023-01-29T20:59:10.434+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.979 seconds
[2023-01-29T20:59:20.526+0000] {processor.py:153} INFO - Started process (PID=1953) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:20.527+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:59:20.528+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:20.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:28.978+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:29.057+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:29.056+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:59:29.083+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:29.083+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:59:28.969822+00:00, run_after=2023-01-30T20:59:28.969822+00:00
[2023-01-29T20:59:29.106+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.585 seconds
[2023-01-29T20:59:39.199+0000] {processor.py:153} INFO - Started process (PID=1959) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:39.200+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:59:39.201+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:39.201+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:46.336+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:46.348+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:46.348+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T20:59:46.374+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:46.374+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T20:59:46.327831+00:00, run_after=2023-01-30T20:59:46.327831+00:00
[2023-01-29T20:59:46.393+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.199 seconds
[2023-01-29T20:59:56.480+0000] {processor.py:153} INFO - Started process (PID=1965) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T20:59:56.481+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T20:59:56.482+0000] {logging_mixin.py:137} INFO - [2023-01-29T20:59:56.481+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:05.280+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:05.347+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:05.347+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:00:05.370+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:05.370+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:00:05.271001+00:00, run_after=2023-01-30T21:00:05.271001+00:00
[2023-01-29T21:00:05.391+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.916 seconds
[2023-01-29T21:00:15.497+0000] {processor.py:153} INFO - Started process (PID=1971) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:15.499+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:00:15.500+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:15.499+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:22.517+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:22.529+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:22.529+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:00:22.555+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:22.554+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:00:22.508598+00:00, run_after=2023-01-30T21:00:22.508598+00:00
[2023-01-29T21:00:22.574+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.086 seconds
[2023-01-29T21:00:32.660+0000] {processor.py:153} INFO - Started process (PID=1977) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:32.661+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:00:32.662+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:32.662+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:41.173+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:41.239+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:41.238+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:00:41.275+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:41.274+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:00:41.164525+00:00, run_after=2023-01-30T21:00:41.164525+00:00
[2023-01-29T21:00:41.300+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.645 seconds
[2023-01-29T21:00:51.401+0000] {processor.py:153} INFO - Started process (PID=1983) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:51.403+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:00:51.404+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:51.403+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:58.607+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:00:58.621+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:58.620+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:00:58.654+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:00:58.653+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:00:58.598094+00:00, run_after=2023-01-30T21:00:58.598094+00:00
[2023-01-29T21:00:58.674+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.279 seconds
[2023-01-29T21:01:08.765+0000] {processor.py:153} INFO - Started process (PID=1989) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:08.766+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:01:08.768+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:08.767+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:18.358+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:18.441+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:18.440+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:01:18.466+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:18.466+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:01:18.347750+00:00, run_after=2023-01-30T21:01:18.347750+00:00
[2023-01-29T21:01:18.487+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.727 seconds
[2023-01-29T21:01:28.608+0000] {processor.py:153} INFO - Started process (PID=1995) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:28.609+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:01:28.611+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:28.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:37.486+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:37.506+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:37.505+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:01:37.536+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:37.536+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:01:37.476886+00:00, run_after=2023-01-30T21:01:37.476886+00:00
[2023-01-29T21:01:37.558+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.956 seconds
[2023-01-29T21:01:47.656+0000] {processor.py:153} INFO - Started process (PID=2001) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:47.657+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:01:47.658+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:47.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:56.670+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:01:56.792+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:56.791+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:01:56.830+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:01:56.830+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:01:56.661455+00:00, run_after=2023-01-30T21:01:56.661455+00:00
[2023-01-29T21:01:56.854+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.203 seconds
[2023-01-29T21:02:06.945+0000] {processor.py:153} INFO - Started process (PID=2007) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:06.946+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:02:06.947+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:06.947+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:15.098+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:15.111+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:15.111+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:02:15.137+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:15.137+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:02:15.089109+00:00, run_after=2023-01-30T21:02:15.089109+00:00
[2023-01-29T21:02:15.159+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.219 seconds
[2023-01-29T21:02:25.247+0000] {processor.py:153} INFO - Started process (PID=2013) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:25.248+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:02:25.249+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:25.249+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:33.327+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:33.411+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:33.411+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:02:33.454+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:33.453+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:02:33.317994+00:00, run_after=2023-01-30T21:02:33.317994+00:00
[2023-01-29T21:02:33.491+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.250 seconds
[2023-01-29T21:02:43.604+0000] {processor.py:153} INFO - Started process (PID=2019) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:43.605+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:02:43.606+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:43.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:50.606+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:02:50.618+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:50.618+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:02:50.647+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:02:50.647+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:02:50.596903+00:00, run_after=2023-01-30T21:02:50.596903+00:00
[2023-01-29T21:02:53.732+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.132 seconds
[2023-01-29T21:03:03.886+0000] {processor.py:153} INFO - Started process (PID=2025) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:03.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:03:03.895+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:03.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:12.094+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:12.160+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:12.160+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:03:12.184+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:12.184+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:03:12.085308+00:00, run_after=2023-01-30T21:03:12.085308+00:00
[2023-01-29T21:03:12.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.331 seconds
[2023-01-29T21:03:22.303+0000] {processor.py:153} INFO - Started process (PID=2031) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:22.305+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:03:22.306+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:22.306+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:30.142+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:30.184+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:30.183+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:03:30.225+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:30.225+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:03:30.127673+00:00, run_after=2023-01-30T21:03:30.127673+00:00
[2023-01-29T21:03:30.260+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.964 seconds
[2023-01-29T21:03:40.462+0000] {processor.py:153} INFO - Started process (PID=2037) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:40.464+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:03:40.465+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:40.465+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:51.375+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:03:51.472+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:51.471+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:03:51.505+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:03:51.504+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:03:51.362184+00:00, run_after=2023-01-30T21:03:51.362184+00:00
[2023-01-29T21:03:51.540+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 11.127 seconds
[2023-01-29T21:04:01.636+0000] {processor.py:153} INFO - Started process (PID=2043) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:01.637+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:04:01.638+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:01.637+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:09.992+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:10.011+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:10.010+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:04:10.045+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:10.045+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:04:09.980871+00:00, run_after=2023-01-30T21:04:09.980871+00:00
[2023-01-29T21:04:10.067+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.436 seconds
[2023-01-29T21:04:20.186+0000] {processor.py:153} INFO - Started process (PID=2049) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:20.188+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:04:20.190+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:20.190+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:28.286+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:28.351+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:28.351+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:04:28.377+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:28.376+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:04:28.277138+00:00, run_after=2023-01-30T21:04:28.277138+00:00
[2023-01-29T21:04:28.402+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.223 seconds
[2023-01-29T21:04:38.492+0000] {processor.py:153} INFO - Started process (PID=2055) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:38.493+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:04:38.494+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:38.494+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:47.452+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:47.470+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:47.469+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:04:47.513+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:47.513+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:04:47.436695+00:00, run_after=2023-01-30T21:04:47.436695+00:00
[2023-01-29T21:04:47.543+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.056 seconds
[2023-01-29T21:04:57.651+0000] {processor.py:153} INFO - Started process (PID=2061) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:04:57.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:04:57.660+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:04:57.659+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:07.698+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:07.770+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:07.769+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:05:07.794+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:07.794+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:05:07.689127+00:00, run_after=2023-01-30T21:05:07.689127+00:00
[2023-01-29T21:05:07.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.174 seconds
[2023-01-29T21:05:17.912+0000] {processor.py:153} INFO - Started process (PID=2067) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:17.913+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:05:17.914+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:17.914+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:27.945+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:27.963+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:27.962+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:05:28.003+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:28.003+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:05:27.929631+00:00, run_after=2023-01-30T21:05:27.929631+00:00
[2023-01-29T21:05:28.045+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.138 seconds
[2023-01-29T21:05:35.018+0000] {processor.py:153} INFO - Started process (PID=2073) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:35.019+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:05:35.020+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:35.020+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:43.227+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:43.293+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:43.293+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:05:43.317+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:43.317+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:05:43.217767+00:00, run_after=2023-01-30T21:05:43.217767+00:00
[2023-01-29T21:05:43.340+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.327 seconds
[2023-01-29T21:05:53.432+0000] {processor.py:153} INFO - Started process (PID=2079) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:05:53.433+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:05:53.434+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:05:53.434+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:00.536+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:00.548+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:00.548+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:06:00.575+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:00.575+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:06:00.526227+00:00, run_after=2023-01-30T21:06:00.526227+00:00
[2023-01-29T21:06:00.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.173 seconds
[2023-01-29T21:06:10.689+0000] {processor.py:153} INFO - Started process (PID=2085) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:10.690+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:06:10.691+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:10.691+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:18.993+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:19.060+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:19.059+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:06:19.084+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:19.084+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:06:18.982445+00:00, run_after=2023-01-30T21:06:18.982445+00:00
[2023-01-29T21:06:19.106+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.422 seconds
[2023-01-29T21:06:29.198+0000] {processor.py:153} INFO - Started process (PID=2091) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:29.199+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:06:29.200+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:29.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:36.359+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:36.372+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:36.371+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:06:36.442+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:36.441+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:06:36.348864+00:00, run_after=2023-01-30T21:06:36.348864+00:00
[2023-01-29T21:06:36.489+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.296 seconds
[2023-01-29T21:06:46.604+0000] {processor.py:153} INFO - Started process (PID=2097) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:46.605+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:06:46.606+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:46.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:55.499+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:06:55.570+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:55.569+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:06:55.594+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:06:55.594+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:06:55.488907+00:00, run_after=2023-01-30T21:06:55.488907+00:00
[2023-01-29T21:06:55.628+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.030 seconds
[2023-01-29T21:07:05.717+0000] {processor.py:153} INFO - Started process (PID=2103) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:05.718+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:07:05.719+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:05.719+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:12.951+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:12.964+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:12.964+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:07:12.989+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:12.989+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:07:12.941709+00:00, run_after=2023-01-30T21:07:12.941709+00:00
[2023-01-29T21:07:13.011+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.297 seconds
[2023-01-29T21:07:23.100+0000] {processor.py:153} INFO - Started process (PID=2109) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:23.101+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:07:23.102+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:23.102+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:31.450+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:31.516+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:31.515+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:07:31.542+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:31.542+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:07:31.439994+00:00, run_after=2023-01-30T21:07:31.439994+00:00
[2023-01-29T21:07:31.564+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.469 seconds
[2023-01-29T21:07:41.661+0000] {processor.py:153} INFO - Started process (PID=2115) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:41.662+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:07:41.663+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:41.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:49.115+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:49.128+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:49.127+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:07:49.153+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:49.153+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:07:49.105875+00:00, run_after=2023-01-30T21:07:49.105875+00:00
[2023-01-29T21:07:49.174+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.518 seconds
[2023-01-29T21:07:59.270+0000] {processor.py:153} INFO - Started process (PID=2121) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:07:59.271+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:07:59.272+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:07:59.272+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:07.427+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:07.504+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:07.504+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:08:07.531+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:07.530+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:08:07.417110+00:00, run_after=2023-01-30T21:08:07.417110+00:00
[2023-01-29T21:08:07.554+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.290 seconds
[2023-01-29T21:08:17.646+0000] {processor.py:153} INFO - Started process (PID=2127) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:17.647+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:08:17.648+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:17.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:24.955+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:24.972+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:24.972+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:08:25.011+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:25.011+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:08:24.941757+00:00, run_after=2023-01-30T21:08:24.941757+00:00
[2023-01-29T21:08:25.037+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.395 seconds
[2023-01-29T21:08:35.140+0000] {processor.py:153} INFO - Started process (PID=2133) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:35.142+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:08:35.142+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:35.142+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:43.448+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:43.514+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:43.513+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:08:43.537+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:43.537+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:08:43.437866+00:00, run_after=2023-01-30T21:08:43.437866+00:00
[2023-01-29T21:08:43.559+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.423 seconds
[2023-01-29T21:08:53.664+0000] {processor.py:153} INFO - Started process (PID=2139) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:08:53.666+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:08:53.667+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:08:53.667+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:09:00.759+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:09:00.772+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:09:00.771+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:09:00.797+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:09:00.797+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:09:00.749819+00:00, run_after=2023-01-30T21:09:00.749819+00:00
[2023-01-29T21:09:00.820+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.162 seconds
[2023-01-29T21:09:10.909+0000] {processor.py:153} INFO - Started process (PID=2145) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:09:10.910+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:09:10.911+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:09:10.911+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:09:33.913+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:09:34.239+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:09:34.239+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:09:34.339+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:09:34.338+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:09:33.854652+00:00, run_after=2023-01-30T21:09:33.854652+00:00
[2023-01-29T21:09:34.410+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 23.506 seconds
[2023-01-29T21:09:44.730+0000] {processor.py:153} INFO - Started process (PID=2159) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:09:44.737+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:09:44.738+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:09:44.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:10:14.745+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:10:14.744+0000] {timeout.py:68} ERROR - Process timed out, PID: 2159
[2023-01-29T21:10:14.749+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:10:14.745+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 12, in <module>
    from spacy.lang.fr.stop_words import STOP_WORDS
  File "/home/airflow/.local/lib/python3.7/site-packages/spacy/lang/fr/__init__.py", line 5, in <module>
    from .tokenizer_exceptions import TOKENIZER_EXCEPTIONS, TOKEN_MATCH
  File "/home/airflow/.local/lib/python3.7/site-packages/spacy/lang/fr/tokenizer_exceptions.py", line 443, in <module>
    "(?iu)" + "|".join("(?:{})".format(m) for m in _regular_exp)
  File "/usr/local/lib/python3.7/re.py", line 236, in compile
    return _compile(pattern, flags)
  File "/usr/local/lib/python3.7/re.py", line 288, in _compile
    p = sre_compile.compile(pattern, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 768, in compile
    code = _code(p, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 607, in _code
    _compile(code, p.data, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 209, in _compile
    _compile(code, av, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 148, in _compile
    _compile(code, av[2], flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 120, in _compile
    charset, hascased = _optimize_charset(av, iscased, tolower, fixes)
  File "/usr/local/lib/python3.7/sre_compile.py", line 300, in _optimize_charset
    for i in map(fixup, r):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.5.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.5.1/best-practices.html#reducing-dag-complexity, PID: 2159
[2023-01-29T21:10:14.805+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:10:14.846+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 30.149 seconds
[2023-01-29T21:10:25.016+0000] {processor.py:153} INFO - Started process (PID=2165) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:10:25.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:10:25.018+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:10:25.018+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:10:32.886+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:10:32.951+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:10:32.950+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:10:32.977+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:10:32.977+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:10:32.875972+00:00, run_after=2023-01-30T21:10:32.875972+00:00
[2023-01-29T21:10:33.004+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.993 seconds
[2023-01-29T21:10:43.114+0000] {processor.py:153} INFO - Started process (PID=2171) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:10:43.116+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:10:43.116+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:10:43.116+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:10:51.769+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:10:51.794+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:10:51.792+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:10:51.824+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:10:51.824+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:10:51.755004+00:00, run_after=2023-01-30T21:10:51.755004+00:00
[2023-01-29T21:10:51.845+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.735 seconds
[2023-01-29T21:11:01.945+0000] {processor.py:153} INFO - Started process (PID=2177) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:01.947+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:11:01.948+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:01.948+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:09.479+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:09.577+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:09.576+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:11:09.612+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:09.612+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:11:09.452762+00:00, run_after=2023-01-30T21:11:09.452762+00:00
[2023-01-29T21:11:09.640+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.702 seconds
[2023-01-29T21:11:19.747+0000] {processor.py:153} INFO - Started process (PID=2183) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:19.748+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:11:19.749+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:19.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:28.495+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:28.508+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:28.507+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:11:28.533+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:28.533+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:11:28.485454+00:00, run_after=2023-01-30T21:11:28.485454+00:00
[2023-01-29T21:11:28.554+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.812 seconds
[2023-01-29T21:11:38.651+0000] {processor.py:153} INFO - Started process (PID=2189) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:38.652+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:11:38.653+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:38.653+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:46.248+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:46.314+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:46.314+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:11:46.337+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:46.337+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:11:46.238771+00:00, run_after=2023-01-30T21:11:46.238771+00:00
[2023-01-29T21:11:46.371+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.726 seconds
[2023-01-29T21:11:56.482+0000] {processor.py:153} INFO - Started process (PID=2195) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:11:56.484+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:11:56.485+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:11:56.485+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:05.148+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:05.160+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:05.159+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:12:05.186+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:05.185+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:12:05.137225+00:00, run_after=2023-01-30T21:12:05.137225+00:00
[2023-01-29T21:12:05.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.731 seconds
[2023-01-29T21:12:15.311+0000] {processor.py:153} INFO - Started process (PID=2201) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:15.312+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:12:15.313+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:15.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:22.856+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:22.936+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:22.935+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:12:22.959+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:22.959+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:12:22.835008+00:00, run_after=2023-01-30T21:12:22.835008+00:00
[2023-01-29T21:12:22.987+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.681 seconds
[2023-01-29T21:12:33.087+0000] {processor.py:153} INFO - Started process (PID=2207) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:33.088+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:12:33.089+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:33.089+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:41.642+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:41.656+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:41.655+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:12:41.682+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:41.682+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:12:41.630223+00:00, run_after=2023-01-30T21:12:41.630223+00:00
[2023-01-29T21:12:41.702+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.620 seconds
[2023-01-29T21:12:51.834+0000] {processor.py:153} INFO - Started process (PID=2213) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:51.836+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:12:51.837+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:51.837+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:59.196+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:12:59.262+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:59.262+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:12:59.285+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:12:59.285+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:12:59.186663+00:00, run_after=2023-01-30T21:12:59.186663+00:00
[2023-01-29T21:12:59.307+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.480 seconds
[2023-01-29T21:13:09.409+0000] {processor.py:153} INFO - Started process (PID=2219) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:13:09.411+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:13:09.412+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:13:09.412+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:13:18.072+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:13:18.085+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:13:18.084+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:13:18.110+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:13:18.110+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:13:18.059813+00:00, run_after=2023-01-30T21:13:18.059813+00:00
[2023-01-29T21:13:18.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.727 seconds
[2023-01-29T21:13:28.222+0000] {processor.py:153} INFO - Started process (PID=2225) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:13:28.223+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:13:28.224+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:13:28.224+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:13:35.538+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:13:35.604+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:13:35.603+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:13:35.628+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:13:35.627+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:13:35.528146+00:00, run_after=2023-01-30T21:13:35.528146+00:00
[2023-01-29T21:13:35.649+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.432 seconds
[2023-01-29T21:13:45.745+0000] {processor.py:153} INFO - Started process (PID=2231) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:13:45.746+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:13:45.746+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:13:45.746+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:14:15.699+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:14:16.241+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:14:16.237+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:14:16.466+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:14:16.466+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline to 2023-01-29T21:14:15.588212+00:00, run_after=2023-01-30T21:14:15.588212+00:00
[2023-01-29T21:14:16.651+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 30.912 seconds
[2023-01-29T21:14:20.728+0000] {processor.py:153} INFO - Started process (PID=2245) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:14:20.750+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:14:20.751+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:14:20.751+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:14:50.754+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:14:50.752+0000] {timeout.py:68} ERROR - Process timed out, PID: 2245
[2023-01-29T21:14:50.757+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:14:50.755+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 12, in <module>
    from spacy.lang.fr.stop_words import STOP_WORDS
  File "/home/airflow/.local/lib/python3.7/site-packages/spacy/lang/fr/__init__.py", line 5, in <module>
    from .tokenizer_exceptions import TOKENIZER_EXCEPTIONS, TOKEN_MATCH
  File "/home/airflow/.local/lib/python3.7/site-packages/spacy/lang/fr/tokenizer_exceptions.py", line 443, in <module>
    "(?iu)" + "|".join("(?:{})".format(m) for m in _regular_exp)
  File "/usr/local/lib/python3.7/re.py", line 236, in compile
    return _compile(pattern, flags)
  File "/usr/local/lib/python3.7/re.py", line 288, in _compile
    p = sre_compile.compile(pattern, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 768, in compile
    code = _code(p, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 607, in _code
    _compile(code, p.data, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 209, in _compile
    _compile(code, av, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 120, in _compile
    charset, hascased = _optimize_charset(av, iscased, tolower, fixes)
  File "/usr/local/lib/python3.7/sre_compile.py", line 300, in _optimize_charset
    for i in map(fixup, r):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.5.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.5.1/best-practices.html#reducing-dag-complexity, PID: 2245
[2023-01-29T21:14:50.778+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:14:50.818+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 30.095 seconds
[2023-01-29T21:15:00.967+0000] {processor.py:153} INFO - Started process (PID=2251) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:15:00.968+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:15:00.969+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:00.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:15:10.075+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_dag']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:15:10.217+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:10.217+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:data_pipeline_dag
[2023-01-29T21:15:10.229+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:10.229+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:data_pipeline_dag
[2023-01-29T21:15:10.237+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:10.237+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:data_pipeline_dag
[2023-01-29T21:15:10.238+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:10.238+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:15:10.252+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:10.251+0000] {dag.py:2711} INFO - Creating ORM DAG for data_pipeline_dag
[2023-01-29T21:15:10.265+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:10.265+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_dag to 2023-01-29T21:15:10.060386+00:00, run_after=2023-01-30T21:15:10.060386+00:00
[2023-01-29T21:15:10.291+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.332 seconds
[2023-01-29T21:15:20.415+0000] {processor.py:153} INFO - Started process (PID=2257) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:15:20.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:15:20.431+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:20.431+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:15:50.442+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:50.441+0000] {timeout.py:68} ERROR - Process timed out, PID: 2257
[2023-01-29T21:15:50.449+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:15:50.443+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 12, in <module>
    from spacy.lang.fr.stop_words import STOP_WORDS
  File "/home/airflow/.local/lib/python3.7/site-packages/spacy/lang/fr/__init__.py", line 5, in <module>
    from .tokenizer_exceptions import TOKENIZER_EXCEPTIONS, TOKEN_MATCH
  File "/home/airflow/.local/lib/python3.7/site-packages/spacy/lang/fr/tokenizer_exceptions.py", line 443, in <module>
    "(?iu)" + "|".join("(?:{})".format(m) for m in _regular_exp)
  File "/usr/local/lib/python3.7/re.py", line 236, in compile
    return _compile(pattern, flags)
  File "/usr/local/lib/python3.7/re.py", line 288, in _compile
    p = sre_compile.compile(pattern, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 768, in compile
    code = _code(p, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 607, in _code
    _compile(code, p.data, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 209, in _compile
    _compile(code, av, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 148, in _compile
    _compile(code, av[2], flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 120, in _compile
    charset, hascased = _optimize_charset(av, iscased, tolower, fixes)
  File "/usr/local/lib/python3.7/sre_compile.py", line 300, in _optimize_charset
    for i in map(fixup, r):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.5.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.5.1/best-practices.html#reducing-dag-complexity, PID: 2257
[2023-01-29T21:15:50.517+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:15:50.608+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 30.210 seconds
[2023-01-29T21:16:00.863+0000] {processor.py:153} INFO - Started process (PID=2271) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:16:00.866+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:16:00.868+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:16:00.867+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:16:30.875+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:16:30.874+0000] {timeout.py:68} ERROR - Process timed out, PID: 2271
[2023-01-29T21:16:30.891+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:16:30.875+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 7, in <module>
    from etl import ExtractTransformLoad
  File "/opt/airflow/dags/etl.py", line 12, in <module>
    from spacy.lang.fr.stop_words import STOP_WORDS
  File "/home/airflow/.local/lib/python3.7/site-packages/spacy/lang/fr/__init__.py", line 5, in <module>
    from .tokenizer_exceptions import TOKENIZER_EXCEPTIONS, TOKEN_MATCH
  File "/home/airflow/.local/lib/python3.7/site-packages/spacy/lang/fr/tokenizer_exceptions.py", line 443, in <module>
    "(?iu)" + "|".join("(?:{})".format(m) for m in _regular_exp)
  File "/usr/local/lib/python3.7/re.py", line 236, in compile
    return _compile(pattern, flags)
  File "/usr/local/lib/python3.7/re.py", line 288, in _compile
    p = sre_compile.compile(pattern, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 768, in compile
    code = _code(p, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 607, in _code
    _compile(code, p.data, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 209, in _compile
    _compile(code, av, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 120, in _compile
    charset, hascased = _optimize_charset(av, iscased, tolower, fixes)
  File "/usr/local/lib/python3.7/sre_compile.py", line 301, in _optimize_charset
    charmap[i] = 1
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.5.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.5.1/best-practices.html#reducing-dag-complexity, PID: 2271
[2023-01-29T21:16:31.004+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:16:31.048+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 30.208 seconds
[2023-01-29T21:16:41.230+0000] {processor.py:153} INFO - Started process (PID=2285) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:16:41.237+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:16:41.238+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:16:41.238+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:16:58.685+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_dag']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:16:58.905+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:16:58.904+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:16:58.995+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:16:58.995+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_dag to 2023-01-29T21:16:58.659867+00:00, run_after=2023-01-30T21:16:58.659867+00:00
[2023-01-29T21:16:59.054+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 17.841 seconds
[2023-01-29T21:17:09.242+0000] {processor.py:153} INFO - Started process (PID=2295) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:09.244+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:17:09.245+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:17:09.245+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:21.942+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_dag']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:21.954+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:17:21.954+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:17:21.979+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:17:21.979+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_dag to 2023-01-29T21:17:21.931920+00:00, run_after=2023-01-30T21:17:21.931920+00:00
[2023-01-29T21:17:22.001+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 12.778 seconds
[2023-01-29T21:17:32.092+0000] {processor.py:153} INFO - Started process (PID=2301) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:32.093+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:17:32.094+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:17:32.094+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:41.377+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_dag']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:41.492+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:17:41.491+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-01-29T21:17:41.552+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:17:41.551+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_dag to 2023-01-29T21:17:41.359836+00:00, run_after=2023-01-30T21:17:41.359836+00:00
[2023-01-29T21:17:41.590+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.502 seconds
[2023-01-29T21:17:49.695+0000] {processor.py:153} INFO - Started process (PID=2307) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:49.696+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:17:49.697+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:17:49.697+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:58.687+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:17:58.686+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 119, in <module>
    dag=dag,
NameError: name 'dag' is not defined
[2023-01-29T21:17:58.688+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:17:58.708+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.018 seconds
[2023-01-29T21:18:08.802+0000] {processor.py:153} INFO - Started process (PID=2313) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:08.803+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:18:08.803+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:18:08.803+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:15.993+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:18:15.992+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 119, in <module>
    dag=dag,
NameError: name 'dag' is not defined
[2023-01-29T21:18:15.993+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:16.014+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.218 seconds
[2023-01-29T21:18:26.116+0000] {processor.py:153} INFO - Started process (PID=2319) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:26.117+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:18:26.118+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:18:26.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:35.610+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:18:35.609+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 119, in <module>
    dag=dag_1,
NameError: name 'dag' is not defined
[2023-01-29T21:18:35.610+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:35.632+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.521 seconds
[2023-01-29T21:18:45.778+0000] {processor.py:153} INFO - Started process (PID=2325) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:45.785+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:18:45.786+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:18:45.786+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:53.438+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:18:53.437+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 135, in <module>
    dag=dag,
NameError: name 'dag' is not defined
[2023-01-29T21:18:53.439+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:18:53.459+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.696 seconds
[2023-01-29T21:19:03.556+0000] {processor.py:153} INFO - Started process (PID=2331) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:03.557+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:19:03.559+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:03.558+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:12.781+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:12.780+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/etl_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dag.py", line 135, in <module>
    dag=dag_2,
NameError: name 'dag' is not defined
[2023-01-29T21:19:12.781+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:12.802+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.253 seconds
[2023-01-29T21:19:22.909+0000] {processor.py:153} INFO - Started process (PID=2337) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:22.911+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:19:22.912+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:22.912+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:30.478+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:30.590+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:30.589+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:19:30.615+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:30.614+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:19:30.467532+00:00, run_after=2023-01-30T21:19:30.467532+00:00
[2023-01-29T21:19:30.618+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:30.618+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:19:30.467532+00:00, run_after=2023-01-30T21:19:30.467532+00:00
[2023-01-29T21:19:30.652+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.748 seconds
[2023-01-29T21:19:40.761+0000] {processor.py:153} INFO - Started process (PID=2343) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:40.762+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:19:40.763+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:40.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:49.604+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:49.618+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:49.617+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:19:49.643+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:49.643+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:19:49.594051+00:00, run_after=2023-01-30T21:19:49.594051+00:00
[2023-01-29T21:19:49.646+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:49.646+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:19:49.594051+00:00, run_after=2023-01-30T21:19:49.594051+00:00
[2023-01-29T21:19:49.666+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.909 seconds
[2023-01-29T21:19:59.767+0000] {processor.py:153} INFO - Started process (PID=2349) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:19:59.768+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:19:59.769+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:19:59.769+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:07.348+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:07.422+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:07.421+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:20:07.447+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:07.447+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:20:07.337589+00:00, run_after=2023-01-30T21:20:07.337589+00:00
[2023-01-29T21:20:07.450+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:07.450+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:20:07.337589+00:00, run_after=2023-01-30T21:20:07.337589+00:00
[2023-01-29T21:20:07.471+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.711 seconds
[2023-01-29T21:20:17.567+0000] {processor.py:153} INFO - Started process (PID=2355) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:17.569+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:20:17.570+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:17.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:26.389+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:26.403+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:26.402+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:20:26.436+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:26.435+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:20:26.379116+00:00, run_after=2023-01-30T21:20:26.379116+00:00
[2023-01-29T21:20:26.442+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:26.442+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:20:26.379116+00:00, run_after=2023-01-30T21:20:26.379116+00:00
[2023-01-29T21:20:26.464+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.901 seconds
[2023-01-29T21:20:36.620+0000] {processor.py:153} INFO - Started process (PID=2361) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:36.629+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:20:36.638+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:36.631+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:43.798+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:43.884+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:43.884+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:20:43.909+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:43.909+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:20:43.788055+00:00, run_after=2023-01-30T21:20:43.788055+00:00
[2023-01-29T21:20:43.912+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:43.912+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:20:43.788055+00:00, run_after=2023-01-30T21:20:43.788055+00:00
[2023-01-29T21:20:43.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.327 seconds
[2023-01-29T21:20:54.067+0000] {processor.py:153} INFO - Started process (PID=2371) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:20:54.078+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:20:54.079+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:20:54.079+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:21:17.256+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:21:17.490+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:21:17.489+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:21:17.572+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:21:17.571+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:21:17.212758+00:00, run_after=2023-01-30T21:21:17.212758+00:00
[2023-01-29T21:21:17.581+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:21:17.581+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:21:17.212758+00:00, run_after=2023-01-30T21:21:17.212758+00:00
[2023-01-29T21:21:17.661+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 23.601 seconds
[2023-01-29T21:21:27.848+0000] {processor.py:153} INFO - Started process (PID=2383) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:21:27.849+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:21:27.851+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:21:27.851+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:21:50.974+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:21:51.229+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:21:51.228+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:21:51.295+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:21:51.294+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:21:50.934705+00:00, run_after=2023-01-30T21:21:50.934705+00:00
[2023-01-29T21:21:51.304+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:21:51.304+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:21:50.934705+00:00, run_after=2023-01-30T21:21:50.934705+00:00
[2023-01-29T21:21:51.425+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 23.585 seconds
[2023-01-29T21:22:01.629+0000] {processor.py:153} INFO - Started process (PID=2398) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:01.632+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:22:01.633+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:01.633+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:21.125+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:21.267+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:21.266+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:22:21.331+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:21.331+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:22:21.107326+00:00, run_after=2023-01-30T21:22:21.107326+00:00
[2023-01-29T21:22:21.336+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:21.336+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:22:21.107326+00:00, run_after=2023-01-30T21:22:21.107326+00:00
[2023-01-29T21:22:21.413+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 19.794 seconds
[2023-01-29T21:22:31.719+0000] {processor.py:153} INFO - Started process (PID=2415) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:31.720+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:22:31.721+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:31.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:40.150+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:40.165+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:40.163+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:22:40.191+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:40.191+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:22:40.140276+00:00, run_after=2023-01-30T21:22:40.140276+00:00
[2023-01-29T21:22:40.195+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:40.195+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:22:40.140276+00:00, run_after=2023-01-30T21:22:40.140276+00:00
[2023-01-29T21:22:40.213+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.500 seconds
[2023-01-29T21:22:50.305+0000] {processor.py:153} INFO - Started process (PID=2421) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:50.306+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:22:50.307+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:50.307+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:57.380+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:22:57.466+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:57.466+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:22:57.502+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:57.502+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:22:57.362706+00:00, run_after=2023-01-30T21:22:57.362706+00:00
[2023-01-29T21:22:57.516+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:22:57.516+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:22:57.362706+00:00, run_after=2023-01-30T21:22:57.362706+00:00
[2023-01-29T21:22:57.562+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.262 seconds
[2023-01-29T21:23:07.673+0000] {processor.py:153} INFO - Started process (PID=2427) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:23:07.674+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:23:07.676+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:07.675+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:23:16.734+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:23:16.749+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:16.748+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:23:16.779+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:16.779+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:23:16.722032+00:00, run_after=2023-01-30T21:23:16.722032+00:00
[2023-01-29T21:23:16.783+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:16.783+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:23:16.722032+00:00, run_after=2023-01-30T21:23:16.722032+00:00
[2023-01-29T21:23:16.801+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.135 seconds
[2023-01-29T21:23:26.892+0000] {processor.py:153} INFO - Started process (PID=2433) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:23:26.894+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:23:26.894+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:26.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:23:43.551+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:23:43.690+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:43.689+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:23:43.766+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:43.765+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:23:43.533865+00:00, run_after=2023-01-30T21:23:43.533865+00:00
[2023-01-29T21:23:43.779+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:43.778+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:23:43.533865+00:00, run_after=2023-01-30T21:23:43.533865+00:00
[2023-01-29T21:23:43.831+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 16.943 seconds
[2023-01-29T21:23:54.089+0000] {processor.py:153} INFO - Started process (PID=2447) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:23:54.095+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:23:54.096+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:23:54.096+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:24:11.191+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:24:11.205+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:24:11.204+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:24:11.230+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:24:11.230+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:24:11.181219+00:00, run_after=2023-01-30T21:24:11.181219+00:00
[2023-01-29T21:24:11.234+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:24:11.234+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:24:11.181219+00:00, run_after=2023-01-30T21:24:11.181219+00:00
[2023-01-29T21:24:11.255+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 17.209 seconds
[2023-01-29T21:24:21.370+0000] {processor.py:153} INFO - Started process (PID=2455) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:24:21.372+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:24:21.373+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:24:21.373+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:24:43.096+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:24:43.326+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:24:43.325+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:24:43.399+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:24:43.399+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:24:43.049774+00:00, run_after=2023-01-30T21:24:43.049774+00:00
[2023-01-29T21:24:43.407+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:24:43.407+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:24:43.049774+00:00, run_after=2023-01-30T21:24:43.049774+00:00
[2023-01-29T21:24:43.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 22.116 seconds
[2023-01-29T21:24:53.671+0000] {processor.py:153} INFO - Started process (PID=2474) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:24:53.672+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:24:53.673+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:24:53.673+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:12.375+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:12.402+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:12.401+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:25:12.452+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:12.451+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:25:12.336958+00:00, run_after=2023-01-30T21:25:12.336958+00:00
[2023-01-29T21:25:12.458+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:12.457+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:25:12.336958+00:00, run_after=2023-01-30T21:25:12.336958+00:00
[2023-01-29T21:25:12.520+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 18.860 seconds
[2023-01-29T21:25:22.707+0000] {processor.py:153} INFO - Started process (PID=2487) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:22.708+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:25:22.709+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:22.709+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:31.246+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:31.327+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:31.327+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:25:31.354+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:31.354+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:25:31.236236+00:00, run_after=2023-01-30T21:25:31.236236+00:00
[2023-01-29T21:25:31.357+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:31.357+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:25:31.236236+00:00, run_after=2023-01-30T21:25:31.236236+00:00
[2023-01-29T21:25:31.378+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.675 seconds
[2023-01-29T21:25:41.480+0000] {processor.py:153} INFO - Started process (PID=2493) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:41.481+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:25:41.483+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:41.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:49.520+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:49.540+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:49.538+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:25:49.585+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:49.585+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:25:49.499282+00:00, run_after=2023-01-30T21:25:49.499282+00:00
[2023-01-29T21:25:49.591+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:49.591+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:25:49.499282+00:00, run_after=2023-01-30T21:25:49.499282+00:00
[2023-01-29T21:25:49.623+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.148 seconds
[2023-01-29T21:25:59.726+0000] {processor.py:153} INFO - Started process (PID=2499) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:25:59.728+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:25:59.729+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:25:59.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:08.172+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:08.247+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:08.246+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:26:08.272+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:08.272+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:26:08.159414+00:00, run_after=2023-01-30T21:26:08.159414+00:00
[2023-01-29T21:26:08.278+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:08.278+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:26:08.159414+00:00, run_after=2023-01-30T21:26:08.159414+00:00
[2023-01-29T21:26:08.299+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.577 seconds
[2023-01-29T21:26:18.398+0000] {processor.py:153} INFO - Started process (PID=2505) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:18.400+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:26:18.400+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:18.400+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:25.693+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:25.714+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:25.713+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:26:25.792+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:25.792+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:26:25.675706+00:00, run_after=2023-01-30T21:26:25.675706+00:00
[2023-01-29T21:26:25.803+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:25.802+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:26:25.675706+00:00, run_after=2023-01-30T21:26:25.675706+00:00
[2023-01-29T21:26:25.829+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.435 seconds
[2023-01-29T21:26:35.925+0000] {processor.py:153} INFO - Started process (PID=2511) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:35.926+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:26:35.927+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:35.927+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:44.274+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:44.351+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:44.350+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:26:44.379+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:44.379+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:26:44.262685+00:00, run_after=2023-01-30T21:26:44.262685+00:00
[2023-01-29T21:26:44.382+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:44.382+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:26:44.262685+00:00, run_after=2023-01-30T21:26:44.262685+00:00
[2023-01-29T21:26:44.408+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.488 seconds
[2023-01-29T21:26:54.513+0000] {processor.py:153} INFO - Started process (PID=2517) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:26:54.515+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:26:54.516+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:26:54.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:01.719+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:01.740+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:01.739+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:27:01.776+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:01.776+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:27:01.708734+00:00, run_after=2023-01-30T21:27:01.708734+00:00
[2023-01-29T21:27:01.780+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:01.780+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:27:01.708734+00:00, run_after=2023-01-30T21:27:01.708734+00:00
[2023-01-29T21:27:01.800+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.294 seconds
[2023-01-29T21:27:11.895+0000] {processor.py:153} INFO - Started process (PID=2523) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:11.897+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:27:11.898+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:11.898+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:20.408+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:20.516+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:20.516+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:27:20.541+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:20.541+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:27:20.384871+00:00, run_after=2023-01-30T21:27:20.384871+00:00
[2023-01-29T21:27:20.545+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:20.545+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:27:20.384871+00:00, run_after=2023-01-30T21:27:20.384871+00:00
[2023-01-29T21:27:20.566+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.675 seconds
[2023-01-29T21:27:30.676+0000] {processor.py:153} INFO - Started process (PID=2529) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:30.677+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:27:30.678+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:30.677+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:37.668+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:37.682+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:37.681+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:27:37.710+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:37.710+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:27:37.658053+00:00, run_after=2023-01-30T21:27:37.658053+00:00
[2023-01-29T21:27:37.713+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:37.713+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:27:37.658053+00:00, run_after=2023-01-30T21:27:37.658053+00:00
[2023-01-29T21:27:37.734+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.064 seconds
[2023-01-29T21:27:47.821+0000] {processor.py:153} INFO - Started process (PID=2535) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:47.823+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:27:47.824+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:47.824+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:56.335+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:27:56.415+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:56.414+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:27:56.456+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:56.455+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:27:56.324903+00:00, run_after=2023-01-30T21:27:56.324903+00:00
[2023-01-29T21:27:56.461+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:27:56.461+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:27:56.324903+00:00, run_after=2023-01-30T21:27:56.324903+00:00
[2023-01-29T21:27:56.487+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.672 seconds
[2023-01-29T21:28:06.595+0000] {processor.py:153} INFO - Started process (PID=2541) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:06.596+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:28:06.597+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:06.597+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:14.174+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:14.189+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:14.188+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:28:14.231+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:14.231+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:28:14.164354+00:00, run_after=2023-01-30T21:28:14.164354+00:00
[2023-01-29T21:28:14.235+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:14.235+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:28:14.164354+00:00, run_after=2023-01-30T21:28:14.164354+00:00
[2023-01-29T21:28:14.257+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.670 seconds
[2023-01-29T21:28:24.349+0000] {processor.py:153} INFO - Started process (PID=2547) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:24.351+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:28:24.352+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:24.352+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:33.264+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:33.346+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:33.345+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:28:33.371+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:33.371+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:28:33.247339+00:00, run_after=2023-01-30T21:28:33.247339+00:00
[2023-01-29T21:28:33.375+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:33.375+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:28:33.247339+00:00, run_after=2023-01-30T21:28:33.247339+00:00
[2023-01-29T21:28:33.397+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.053 seconds
[2023-01-29T21:28:43.458+0000] {processor.py:153} INFO - Started process (PID=2553) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:43.459+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:28:43.460+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:43.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:50.691+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:28:50.705+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:50.704+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:28:50.739+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:50.739+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:28:50.680987+00:00, run_after=2023-01-30T21:28:50.680987+00:00
[2023-01-29T21:28:50.745+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:28:50.745+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:28:50.680987+00:00, run_after=2023-01-30T21:28:50.680987+00:00
[2023-01-29T21:28:50.832+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.379 seconds
[2023-01-29T21:29:00.596+0000] {processor.py:153} INFO - Started process (PID=2559) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:00.597+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:29:00.599+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:00.598+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:15.720+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:15.878+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:15.878+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:29:15.925+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:15.924+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:29:15.676119+00:00, run_after=2023-01-30T21:29:15.676119+00:00
[2023-01-29T21:29:15.930+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:15.930+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:29:15.676119+00:00, run_after=2023-01-30T21:29:15.676119+00:00
[2023-01-29T21:29:15.966+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 15.377 seconds
[2023-01-29T21:29:24.780+0000] {processor.py:153} INFO - Started process (PID=2565) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:24.782+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:29:24.782+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:24.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:32.755+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:32.862+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:32.858+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:29:33.078+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:33.078+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:29:32.733279+00:00, run_after=2023-01-30T21:29:32.733279+00:00
[2023-01-29T21:29:33.096+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:33.096+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:29:32.733279+00:00, run_after=2023-01-30T21:29:32.733279+00:00
[2023-01-29T21:29:33.227+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.451 seconds
[2023-01-29T21:29:43.349+0000] {processor.py:153} INFO - Started process (PID=2571) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:43.351+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:29:43.352+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:43.352+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:53.060+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:29:53.170+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:53.170+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:29:53.204+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:53.204+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:29:53.049339+00:00, run_after=2023-01-30T21:29:53.049339+00:00
[2023-01-29T21:29:53.207+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:29:53.207+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:29:53.049339+00:00, run_after=2023-01-30T21:29:53.049339+00:00
[2023-01-29T21:29:53.229+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.886 seconds
[2023-01-29T21:30:03.327+0000] {processor.py:153} INFO - Started process (PID=2577) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:03.328+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:30:03.329+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:03.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:11.215+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:11.246+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:11.245+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:30:11.338+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:11.338+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:30:11.190584+00:00, run_after=2023-01-30T21:30:11.190584+00:00
[2023-01-29T21:30:11.350+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:11.350+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:30:11.190584+00:00, run_after=2023-01-30T21:30:11.190584+00:00
[2023-01-29T21:30:11.387+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.064 seconds
[2023-01-29T21:30:21.487+0000] {processor.py:153} INFO - Started process (PID=2583) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:21.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:30:21.490+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:21.489+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:30.309+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:30.384+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:30.384+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:30:30.410+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:30.410+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:30:30.298386+00:00, run_after=2023-01-30T21:30:30.298386+00:00
[2023-01-29T21:30:30.413+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:30.413+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:30:30.298386+00:00, run_after=2023-01-30T21:30:30.298386+00:00
[2023-01-29T21:30:30.434+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.951 seconds
[2023-01-29T21:30:40.551+0000] {processor.py:153} INFO - Started process (PID=2589) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:40.552+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:30:40.553+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:40.552+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:47.842+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:47.877+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:47.876+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:30:47.914+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:47.914+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:30:47.826206+00:00, run_after=2023-01-30T21:30:47.826206+00:00
[2023-01-29T21:30:47.919+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:47.919+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:30:47.826206+00:00, run_after=2023-01-30T21:30:47.826206+00:00
[2023-01-29T21:30:47.944+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.398 seconds
[2023-01-29T21:30:58.056+0000] {processor.py:153} INFO - Started process (PID=2595) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:30:58.057+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:30:58.059+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:30:58.059+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:06.914+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:06.990+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:06.989+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:31:07.030+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:07.029+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:31:06.904342+00:00, run_after=2023-01-30T21:31:06.904342+00:00
[2023-01-29T21:31:07.033+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:07.033+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:31:06.904342+00:00, run_after=2023-01-30T21:31:06.904342+00:00
[2023-01-29T21:31:07.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.005 seconds
[2023-01-29T21:31:17.148+0000] {processor.py:153} INFO - Started process (PID=2601) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:17.149+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:31:17.150+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:17.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:25.832+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:25.874+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:25.873+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:31:25.938+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:25.938+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:31:25.814109+00:00, run_after=2023-01-30T21:31:25.814109+00:00
[2023-01-29T21:31:25.948+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:25.948+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:31:25.814109+00:00, run_after=2023-01-30T21:31:25.814109+00:00
[2023-01-29T21:31:25.993+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.849 seconds
[2023-01-29T21:31:36.147+0000] {processor.py:153} INFO - Started process (PID=2607) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:36.148+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:31:36.149+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:36.149+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:44.390+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:44.469+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:44.468+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:31:44.493+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:44.493+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:31:44.380102+00:00, run_after=2023-01-30T21:31:44.380102+00:00
[2023-01-29T21:31:44.497+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:44.497+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:31:44.380102+00:00, run_after=2023-01-30T21:31:44.380102+00:00
[2023-01-29T21:31:44.518+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.376 seconds
[2023-01-29T21:31:54.619+0000] {processor.py:153} INFO - Started process (PID=2613) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:31:54.621+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:31:54.622+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:31:54.621+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:02.040+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:02.078+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:02.077+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:32:02.141+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:02.141+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:32:02.012821+00:00, run_after=2023-01-30T21:32:02.012821+00:00
[2023-01-29T21:32:02.147+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:02.146+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:32:02.012821+00:00, run_after=2023-01-30T21:32:02.012821+00:00
[2023-01-29T21:32:02.188+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.574 seconds
[2023-01-29T21:32:12.320+0000] {processor.py:153} INFO - Started process (PID=2619) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:12.323+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:32:12.324+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:12.324+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:26.139+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:26.214+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:26.213+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:32:26.242+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:26.242+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:32:26.129464+00:00, run_after=2023-01-30T21:32:26.129464+00:00
[2023-01-29T21:32:26.247+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:26.247+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:32:26.129464+00:00, run_after=2023-01-30T21:32:26.129464+00:00
[2023-01-29T21:32:26.275+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 13.963 seconds
[2023-01-29T21:32:36.379+0000] {processor.py:153} INFO - Started process (PID=2625) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:36.380+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:32:36.381+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:36.381+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:46.763+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:46.779+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:46.778+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:32:46.804+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:46.804+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:32:46.745620+00:00, run_after=2023-01-30T21:32:46.745620+00:00
[2023-01-29T21:32:46.808+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:46.807+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:32:46.745620+00:00, run_after=2023-01-30T21:32:46.745620+00:00
[2023-01-29T21:32:46.826+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.455 seconds
[2023-01-29T21:32:56.928+0000] {processor.py:153} INFO - Started process (PID=2631) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:32:56.930+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:32:56.930+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:32:56.930+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:04.644+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:04.721+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:04.721+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:33:04.749+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:04.749+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:33:04.633447+00:00, run_after=2023-01-30T21:33:04.633447+00:00
[2023-01-29T21:33:04.752+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:04.752+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:33:04.633447+00:00, run_after=2023-01-30T21:33:04.633447+00:00
[2023-01-29T21:33:04.776+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.853 seconds
[2023-01-29T21:33:14.916+0000] {processor.py:153} INFO - Started process (PID=2637) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:14.917+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:33:14.918+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:14.918+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:27.354+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:27.372+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:27.371+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:33:27.413+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:27.413+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:33:27.339294+00:00, run_after=2023-01-30T21:33:27.339294+00:00
[2023-01-29T21:33:27.418+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:27.418+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:33:27.339294+00:00, run_after=2023-01-30T21:33:27.339294+00:00
[2023-01-29T21:33:27.444+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 12.533 seconds
[2023-01-29T21:33:37.589+0000] {processor.py:153} INFO - Started process (PID=2643) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:37.590+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:33:37.591+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:37.591+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:45.076+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:45.220+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:45.219+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:33:45.260+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:45.260+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:33:45.060913+00:00, run_after=2023-01-30T21:33:45.060913+00:00
[2023-01-29T21:33:45.265+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:45.265+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:33:45.060913+00:00, run_after=2023-01-30T21:33:45.060913+00:00
[2023-01-29T21:33:45.298+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.713 seconds
[2023-01-29T21:33:55.407+0000] {processor.py:153} INFO - Started process (PID=2649) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:33:55.408+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:33:55.410+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:33:55.409+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:09.737+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:09.751+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:09.750+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:34:09.782+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:09.782+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:34:09.727413+00:00, run_after=2023-01-30T21:34:09.727413+00:00
[2023-01-29T21:34:09.786+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:09.785+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:34:09.727413+00:00, run_after=2023-01-30T21:34:09.727413+00:00
[2023-01-29T21:34:09.805+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 14.404 seconds
[2023-01-29T21:34:19.902+0000] {processor.py:153} INFO - Started process (PID=2655) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:19.903+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:34:19.904+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:19.904+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:28.246+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:28.322+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:28.321+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:34:28.347+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:28.347+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:34:28.235910+00:00, run_after=2023-01-30T21:34:28.235910+00:00
[2023-01-29T21:34:28.350+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:28.350+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:34:28.235910+00:00, run_after=2023-01-30T21:34:28.235910+00:00
[2023-01-29T21:34:28.371+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.473 seconds
[2023-01-29T21:34:38.468+0000] {processor.py:153} INFO - Started process (PID=2661) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:38.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:34:38.470+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:38.469+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:45.884+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:45.902+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:45.901+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:34:45.929+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:45.929+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:34:45.871441+00:00, run_after=2023-01-30T21:34:45.871441+00:00
[2023-01-29T21:34:45.933+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:45.933+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:34:45.871441+00:00, run_after=2023-01-30T21:34:45.871441+00:00
[2023-01-29T21:34:45.951+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.489 seconds
[2023-01-29T21:34:56.042+0000] {processor.py:153} INFO - Started process (PID=2667) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:34:56.043+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:34:56.044+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:34:56.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:04.284+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:04.384+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:04.383+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:35:04.418+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:04.418+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:35:04.274293+00:00, run_after=2023-01-30T21:35:04.274293+00:00
[2023-01-29T21:35:04.421+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:04.421+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:35:04.274293+00:00, run_after=2023-01-30T21:35:04.274293+00:00
[2023-01-29T21:35:04.443+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.406 seconds
[2023-01-29T21:35:14.540+0000] {processor.py:153} INFO - Started process (PID=2673) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:14.541+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:35:14.541+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:14.541+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:21.966+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:21.980+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:21.979+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:35:22.007+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:22.007+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:35:21.955806+00:00, run_after=2023-01-30T21:35:21.955806+00:00
[2023-01-29T21:35:22.011+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:22.011+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:35:21.955806+00:00, run_after=2023-01-30T21:35:21.955806+00:00
[2023-01-29T21:35:22.030+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.495 seconds
[2023-01-29T21:35:32.128+0000] {processor.py:153} INFO - Started process (PID=2679) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:32.129+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:35:32.130+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:32.129+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:40.428+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:40.544+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:40.544+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:35:40.584+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:40.584+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:35:40.412598+00:00, run_after=2023-01-30T21:35:40.412598+00:00
[2023-01-29T21:35:40.590+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:40.590+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:35:40.412598+00:00, run_after=2023-01-30T21:35:40.412598+00:00
[2023-01-29T21:35:40.618+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.495 seconds
[2023-01-29T21:35:50.743+0000] {processor.py:153} INFO - Started process (PID=2685) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:50.744+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:35:50.744+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:50.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:59.340+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:35:59.354+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:59.353+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:35:59.392+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:59.392+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:35:59.330098+00:00, run_after=2023-01-30T21:35:59.330098+00:00
[2023-01-29T21:35:59.396+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:35:59.396+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:35:59.330098+00:00, run_after=2023-01-30T21:35:59.330098+00:00
[2023-01-29T21:35:59.415+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.677 seconds
[2023-01-29T21:36:09.508+0000] {processor.py:153} INFO - Started process (PID=2691) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:09.509+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:36:09.510+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:09.510+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:19.460+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:19.544+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:19.543+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:36:19.570+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:19.570+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:36:19.445635+00:00, run_after=2023-01-30T21:36:19.445635+00:00
[2023-01-29T21:36:19.573+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:19.573+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:36:19.445635+00:00, run_after=2023-01-30T21:36:19.445635+00:00
[2023-01-29T21:36:19.605+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.102 seconds
[2023-01-29T21:36:29.661+0000] {processor.py:153} INFO - Started process (PID=2697) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:29.662+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:36:29.663+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:29.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:37.449+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:37.463+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:37.462+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:36:37.488+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:37.488+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:36:37.438431+00:00, run_after=2023-01-30T21:36:37.438431+00:00
[2023-01-29T21:36:37.491+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:37.491+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:36:37.438431+00:00, run_after=2023-01-30T21:36:37.438431+00:00
[2023-01-29T21:36:37.509+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.853 seconds
[2023-01-29T21:36:47.619+0000] {processor.py:153} INFO - Started process (PID=2703) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:47.620+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:36:47.620+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:47.620+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:56.691+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:36:56.826+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:56.825+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:36:56.855+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:56.855+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:36:56.679532+00:00, run_after=2023-01-30T21:36:56.679532+00:00
[2023-01-29T21:36:56.858+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:36:56.858+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:36:56.679532+00:00, run_after=2023-01-30T21:36:56.679532+00:00
[2023-01-29T21:36:56.883+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.270 seconds
[2023-01-29T21:37:06.939+0000] {processor.py:153} INFO - Started process (PID=2709) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:06.941+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:37:06.941+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:06.941+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:15.117+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:15.131+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:15.130+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:37:15.157+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:15.157+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:37:15.106766+00:00, run_after=2023-01-30T21:37:15.106766+00:00
[2023-01-29T21:37:15.161+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:15.161+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:37:15.106766+00:00, run_after=2023-01-30T21:37:15.106766+00:00
[2023-01-29T21:37:15.181+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.253 seconds
[2023-01-29T21:37:25.273+0000] {processor.py:153} INFO - Started process (PID=2715) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:25.274+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:37:25.275+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:25.275+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:35.181+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:35.274+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:35.273+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:37:35.299+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:35.299+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:37:35.170619+00:00, run_after=2023-01-30T21:37:35.170619+00:00
[2023-01-29T21:37:35.302+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:35.302+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:37:35.170619+00:00, run_after=2023-01-30T21:37:35.170619+00:00
[2023-01-29T21:37:35.325+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 10.057 seconds
[2023-01-29T21:37:45.454+0000] {processor.py:153} INFO - Started process (PID=2721) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:45.457+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:37:45.458+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:45.458+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:53.777+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:37:53.797+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:53.796+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:37:53.839+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:53.839+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:37:53.760947+00:00, run_after=2023-01-30T21:37:53.760947+00:00
[2023-01-29T21:37:53.844+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:37:53.844+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:37:53.760947+00:00, run_after=2023-01-30T21:37:53.760947+00:00
[2023-01-29T21:37:53.871+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.427 seconds
[2023-01-29T21:38:03.997+0000] {processor.py:153} INFO - Started process (PID=2727) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:03.998+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:38:03.999+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:03.999+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:13.222+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:13.296+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:13.296+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:38:13.319+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:13.319+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:38:13.211551+00:00, run_after=2023-01-30T21:38:13.211551+00:00
[2023-01-29T21:38:13.323+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:13.323+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:38:13.211551+00:00, run_after=2023-01-30T21:38:13.211551+00:00
[2023-01-29T21:38:13.344+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.352 seconds
[2023-01-29T21:38:23.454+0000] {processor.py:153} INFO - Started process (PID=2733) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:23.457+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:38:23.459+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:23.458+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:32.998+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:33.024+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:33.022+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:38:33.066+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:33.065+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:38:32.980544+00:00, run_after=2023-01-30T21:38:32.980544+00:00
[2023-01-29T21:38:33.071+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:33.071+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:38:32.980544+00:00, run_after=2023-01-30T21:38:32.980544+00:00
[2023-01-29T21:38:33.098+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.650 seconds
[2023-01-29T21:38:43.232+0000] {processor.py:153} INFO - Started process (PID=2739) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:43.234+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:38:43.235+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:43.235+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:51.350+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:38:51.426+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:51.426+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:38:51.449+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:51.449+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:38:51.339557+00:00, run_after=2023-01-30T21:38:51.339557+00:00
[2023-01-29T21:38:51.454+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:38:51.454+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:38:51.339557+00:00, run_after=2023-01-30T21:38:51.339557+00:00
[2023-01-29T21:38:51.475+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.249 seconds
[2023-01-29T21:39:01.568+0000] {processor.py:153} INFO - Started process (PID=2745) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:01.569+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:39:01.570+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:01.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:09.544+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:09.563+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:09.561+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:39:09.601+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:09.601+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:39:09.525273+00:00, run_after=2023-01-30T21:39:09.525273+00:00
[2023-01-29T21:39:09.607+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:09.607+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:39:09.525273+00:00, run_after=2023-01-30T21:39:09.525273+00:00
[2023-01-29T21:39:09.646+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.082 seconds
[2023-01-29T21:39:19.769+0000] {processor.py:153} INFO - Started process (PID=2751) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:19.770+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:39:19.771+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:19.771+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:31.354+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:31.431+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:31.430+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:39:31.456+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:31.456+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:39:31.343342+00:00, run_after=2023-01-30T21:39:31.343342+00:00
[2023-01-29T21:39:31.460+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:31.460+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:39:31.343342+00:00, run_after=2023-01-30T21:39:31.343342+00:00
[2023-01-29T21:39:31.482+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 11.717 seconds
[2023-01-29T21:39:41.581+0000] {processor.py:153} INFO - Started process (PID=2757) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:41.582+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:39:41.583+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:41.583+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:49.242+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:49.261+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:49.260+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:39:49.306+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:49.306+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:39:49.226193+00:00, run_after=2023-01-30T21:39:49.226193+00:00
[2023-01-29T21:39:49.311+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:49.311+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:39:49.226193+00:00, run_after=2023-01-30T21:39:49.226193+00:00
[2023-01-29T21:39:49.337+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.760 seconds
[2023-01-29T21:39:59.518+0000] {processor.py:153} INFO - Started process (PID=2763) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:39:59.519+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:39:59.520+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:39:59.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:07.607+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:07.694+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:07.693+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:40:07.724+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:07.724+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:40:07.597241+00:00, run_after=2023-01-30T21:40:07.597241+00:00
[2023-01-29T21:40:07.728+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:07.728+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:40:07.597241+00:00, run_after=2023-01-30T21:40:07.597241+00:00
[2023-01-29T21:40:07.749+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.235 seconds
[2023-01-29T21:40:17.845+0000] {processor.py:153} INFO - Started process (PID=2769) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:17.847+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:40:17.848+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:17.847+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:25.127+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:25.151+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:25.150+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:40:25.208+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:25.208+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:40:25.088445+00:00, run_after=2023-01-30T21:40:25.088445+00:00
[2023-01-29T21:40:25.216+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:25.216+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:40:25.088445+00:00, run_after=2023-01-30T21:40:25.088445+00:00
[2023-01-29T21:40:25.254+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.414 seconds
[2023-01-29T21:40:35.373+0000] {processor.py:153} INFO - Started process (PID=2775) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:35.375+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:40:35.375+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:35.375+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:43.770+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:43.857+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:43.856+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:40:43.880+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:43.880+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:40:43.760116+00:00, run_after=2023-01-30T21:40:43.760116+00:00
[2023-01-29T21:40:43.884+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:43.884+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:40:43.760116+00:00, run_after=2023-01-30T21:40:43.760116+00:00
[2023-01-29T21:40:43.904+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.541 seconds
[2023-01-29T21:40:53.997+0000] {processor.py:153} INFO - Started process (PID=2781) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:40:53.999+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:40:54.000+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:40:53.999+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:01.076+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:01.107+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:01.106+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:41:01.152+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:01.152+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:41:01.060300+00:00, run_after=2023-01-30T21:41:01.060300+00:00
[2023-01-29T21:41:01.161+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:01.160+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:41:01.060300+00:00, run_after=2023-01-30T21:41:01.060300+00:00
[2023-01-29T21:41:01.201+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.208 seconds
[2023-01-29T21:41:11.299+0000] {processor.py:153} INFO - Started process (PID=2787) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:11.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:41:11.301+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:11.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:19.926+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:20.003+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:20.003+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:41:20.028+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:20.028+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:41:19.915967+00:00, run_after=2023-01-30T21:41:19.915967+00:00
[2023-01-29T21:41:20.032+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:20.032+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:41:19.915967+00:00, run_after=2023-01-30T21:41:19.915967+00:00
[2023-01-29T21:41:20.053+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.758 seconds
[2023-01-29T21:41:30.155+0000] {processor.py:153} INFO - Started process (PID=2793) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:30.156+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:41:30.157+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:30.157+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:37.080+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:37.095+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:37.094+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:41:37.120+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:37.120+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:41:37.070566+00:00, run_after=2023-01-30T21:41:37.070566+00:00
[2023-01-29T21:41:37.124+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:37.124+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:41:37.070566+00:00, run_after=2023-01-30T21:41:37.070566+00:00
[2023-01-29T21:41:37.142+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 6.992 seconds
[2023-01-29T21:41:47.239+0000] {processor.py:153} INFO - Started process (PID=2799) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:47.240+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:41:47.241+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:47.240+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:55.758+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:41:55.834+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:55.833+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:41:55.860+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:55.859+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:41:55.747801+00:00, run_after=2023-01-30T21:41:55.747801+00:00
[2023-01-29T21:41:55.865+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:41:55.865+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:41:55.747801+00:00, run_after=2023-01-30T21:41:55.747801+00:00
[2023-01-29T21:41:55.886+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.652 seconds
[2023-01-29T21:42:05.979+0000] {processor.py:153} INFO - Started process (PID=2805) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:05.981+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:42:05.982+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:05.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:12.942+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:12.956+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:12.955+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:42:12.984+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:12.983+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:42:12.932502+00:00, run_after=2023-01-30T21:42:12.932502+00:00
[2023-01-29T21:42:12.987+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:12.987+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:42:12.932502+00:00, run_after=2023-01-30T21:42:12.932502+00:00
[2023-01-29T21:42:13.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.033 seconds
[2023-01-29T21:42:23.084+0000] {processor.py:153} INFO - Started process (PID=2811) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:23.086+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:42:23.087+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:23.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:31.644+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:31.724+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:31.723+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:42:31.749+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:31.749+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:42:31.625286+00:00, run_after=2023-01-30T21:42:31.625286+00:00
[2023-01-29T21:42:31.753+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:31.753+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:42:31.625286+00:00, run_after=2023-01-30T21:42:31.625286+00:00
[2023-01-29T21:42:31.774+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.696 seconds
[2023-01-29T21:42:41.875+0000] {processor.py:153} INFO - Started process (PID=2817) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:41.876+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:42:41.878+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:41.877+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:48.858+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:48.872+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:48.871+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:42:48.897+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:48.897+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:42:48.848100+00:00, run_after=2023-01-30T21:42:48.848100+00:00
[2023-01-29T21:42:48.901+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:48.900+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:42:48.848100+00:00, run_after=2023-01-30T21:42:48.848100+00:00
[2023-01-29T21:42:48.921+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.051 seconds
[2023-01-29T21:42:58.979+0000] {processor.py:153} INFO - Started process (PID=2823) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:42:58.980+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:42:58.981+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:42:58.980+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:07.311+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:07.397+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:07.396+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:43:07.424+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:07.424+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:43:07.300909+00:00, run_after=2023-01-30T21:43:07.300909+00:00
[2023-01-29T21:43:07.429+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:07.428+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:43:07.300909+00:00, run_after=2023-01-30T21:43:07.300909+00:00
[2023-01-29T21:43:07.454+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.480 seconds
[2023-01-29T21:43:17.592+0000] {processor.py:153} INFO - Started process (PID=2829) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:17.594+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:43:17.595+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:17.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:25.111+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:25.127+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:25.127+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:43:25.153+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:25.153+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:43:25.100817+00:00, run_after=2023-01-30T21:43:25.100817+00:00
[2023-01-29T21:43:25.157+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:25.157+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:43:25.100817+00:00, run_after=2023-01-30T21:43:25.100817+00:00
[2023-01-29T21:43:25.175+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.594 seconds
[2023-01-29T21:43:35.264+0000] {processor.py:153} INFO - Started process (PID=2835) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:35.265+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:43:35.266+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:35.266+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:43.844+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:43.924+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:43.923+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:43:43.950+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:43.950+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:43:43.816346+00:00, run_after=2023-01-30T21:43:43.816346+00:00
[2023-01-29T21:43:43.954+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:43.953+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:43:43.816346+00:00, run_after=2023-01-30T21:43:43.816346+00:00
[2023-01-29T21:43:43.977+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.718 seconds
[2023-01-29T21:43:54.086+0000] {processor.py:153} INFO - Started process (PID=2841) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:43:54.088+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:43:54.089+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:43:54.089+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:02.353+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:02.372+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:02.372+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:44:02.400+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:02.400+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:44:02.336411+00:00, run_after=2023-01-30T21:44:02.336411+00:00
[2023-01-29T21:44:02.404+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:02.404+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:44:02.336411+00:00, run_after=2023-01-30T21:44:02.336411+00:00
[2023-01-29T21:44:02.423+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.344 seconds
[2023-01-29T21:44:12.512+0000] {processor.py:153} INFO - Started process (PID=2847) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:12.513+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:44:12.514+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:12.514+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:20.685+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:20.804+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:20.803+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:44:20.845+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:20.844+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:44:20.668157+00:00, run_after=2023-01-30T21:44:20.668157+00:00
[2023-01-29T21:44:20.850+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:20.850+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:44:20.668157+00:00, run_after=2023-01-30T21:44:20.668157+00:00
[2023-01-29T21:44:20.879+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.371 seconds
[2023-01-29T21:44:31.028+0000] {processor.py:153} INFO - Started process (PID=2853) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:31.037+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:44:31.038+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:31.038+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:39.281+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:39.295+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:39.294+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:44:39.321+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:39.320+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:44:39.271087+00:00, run_after=2023-01-30T21:44:39.271087+00:00
[2023-01-29T21:44:39.324+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:39.324+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:44:39.271087+00:00, run_after=2023-01-30T21:44:39.271087+00:00
[2023-01-29T21:44:39.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.326 seconds
[2023-01-29T21:44:49.442+0000] {processor.py:153} INFO - Started process (PID=2859) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:49.444+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:44:49.445+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:49.445+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:56.751+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:44:56.905+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:56.904+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:44:56.944+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:56.944+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:44:56.735263+00:00, run_after=2023-01-30T21:44:56.735263+00:00
[2023-01-29T21:44:56.949+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:44:56.949+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:44:56.735263+00:00, run_after=2023-01-30T21:44:56.735263+00:00
[2023-01-29T21:44:56.980+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.545 seconds
[2023-01-29T21:45:07.098+0000] {processor.py:153} INFO - Started process (PID=2865) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:07.099+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:45:07.100+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:07.100+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:15.439+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:15.453+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:15.452+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:45:15.479+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:15.478+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:45:15.428518+00:00, run_after=2023-01-30T21:45:15.428518+00:00
[2023-01-29T21:45:15.482+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:15.482+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:45:15.428518+00:00, run_after=2023-01-30T21:45:15.428518+00:00
[2023-01-29T21:45:15.501+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.409 seconds
[2023-01-29T21:45:25.606+0000] {processor.py:153} INFO - Started process (PID=2871) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:25.607+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:45:25.608+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:25.608+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:32.606+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:32.681+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:32.680+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:45:32.707+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:32.707+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:45:32.596399+00:00, run_after=2023-01-30T21:45:32.596399+00:00
[2023-01-29T21:45:32.710+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:32.710+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:45:32.596399+00:00, run_after=2023-01-30T21:45:32.596399+00:00
[2023-01-29T21:45:32.731+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.132 seconds
[2023-01-29T21:45:42.838+0000] {processor.py:153} INFO - Started process (PID=2877) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:42.839+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:45:42.840+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:42.840+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:51.074+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:45:51.088+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:51.088+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:45:51.115+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:51.115+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:45:51.064003+00:00, run_after=2023-01-30T21:45:51.064003+00:00
[2023-01-29T21:45:51.119+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:45:51.118+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:45:51.064003+00:00, run_after=2023-01-30T21:45:51.064003+00:00
[2023-01-29T21:45:51.139+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.306 seconds
[2023-01-29T21:46:01.235+0000] {processor.py:153} INFO - Started process (PID=2883) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:01.236+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:46:01.237+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:01.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:08.499+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:08.592+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:08.591+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:46:08.620+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:08.620+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:46:08.488393+00:00, run_after=2023-01-30T21:46:08.488393+00:00
[2023-01-29T21:46:08.623+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:08.623+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:46:08.488393+00:00, run_after=2023-01-30T21:46:08.488393+00:00
[2023-01-29T21:46:08.646+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.415 seconds
[2023-01-29T21:46:18.749+0000] {processor.py:153} INFO - Started process (PID=2889) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:18.750+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:46:18.751+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:18.751+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:27.014+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:27.028+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:27.027+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:46:27.053+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:27.053+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:46:27.002872+00:00, run_after=2023-01-30T21:46:27.002872+00:00
[2023-01-29T21:46:27.057+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:27.056+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:46:27.002872+00:00, run_after=2023-01-30T21:46:27.002872+00:00
[2023-01-29T21:46:27.075+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.333 seconds
[2023-01-29T21:46:37.171+0000] {processor.py:153} INFO - Started process (PID=2895) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:37.172+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:46:37.173+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:37.173+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:44.488+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:44.565+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:44.564+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:46:44.589+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:44.589+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:46:44.477596+00:00, run_after=2023-01-30T21:46:44.477596+00:00
[2023-01-29T21:46:44.593+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:44.593+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:46:44.477596+00:00, run_after=2023-01-30T21:46:44.477596+00:00
[2023-01-29T21:46:44.614+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.447 seconds
[2023-01-29T21:46:54.712+0000] {processor.py:153} INFO - Started process (PID=2901) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:46:54.713+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:46:54.714+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:46:54.714+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:02.805+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:02.820+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:02.819+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:47:02.845+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:02.845+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:47:02.795419+00:00, run_after=2023-01-30T21:47:02.795419+00:00
[2023-01-29T21:47:02.850+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:02.850+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:47:02.795419+00:00, run_after=2023-01-30T21:47:02.795419+00:00
[2023-01-29T21:47:02.868+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.161 seconds
[2023-01-29T21:47:12.961+0000] {processor.py:153} INFO - Started process (PID=2907) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:12.962+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:47:12.963+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:12.963+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:20.108+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:20.189+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:20.188+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:47:20.214+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:20.214+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:47:20.091343+00:00, run_after=2023-01-30T21:47:20.091343+00:00
[2023-01-29T21:47:20.218+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:20.218+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:47:20.091343+00:00, run_after=2023-01-30T21:47:20.091343+00:00
[2023-01-29T21:47:20.239+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.283 seconds
[2023-01-29T21:47:30.329+0000] {processor.py:153} INFO - Started process (PID=2913) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:30.330+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:47:30.331+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:30.331+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:39.109+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:39.123+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:39.122+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:47:39.150+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:39.149+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:47:39.097188+00:00, run_after=2023-01-30T21:47:39.097188+00:00
[2023-01-29T21:47:39.153+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:39.153+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:47:39.097188+00:00, run_after=2023-01-30T21:47:39.097188+00:00
[2023-01-29T21:47:39.173+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.848 seconds
[2023-01-29T21:47:49.265+0000] {processor.py:153} INFO - Started process (PID=2919) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:49.266+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:47:49.267+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:49.267+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:56.423+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:47:56.501+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:56.500+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:47:56.528+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:56.527+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:47:56.413137+00:00, run_after=2023-01-30T21:47:56.413137+00:00
[2023-01-29T21:47:56.532+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:47:56.531+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:47:56.413137+00:00, run_after=2023-01-30T21:47:56.413137+00:00
[2023-01-29T21:47:56.557+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.296 seconds
[2023-01-29T21:48:06.659+0000] {processor.py:153} INFO - Started process (PID=2925) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:06.660+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:48:06.661+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:06.661+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:14.781+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:14.813+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:14.812+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:48:14.842+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:14.841+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:48:14.768827+00:00, run_after=2023-01-30T21:48:14.768827+00:00
[2023-01-29T21:48:14.848+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:14.847+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:48:14.768827+00:00, run_after=2023-01-30T21:48:14.768827+00:00
[2023-01-29T21:48:14.886+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.233 seconds
[2023-01-29T21:48:25.007+0000] {processor.py:153} INFO - Started process (PID=2931) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:25.009+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:48:25.010+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:25.010+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:32.528+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:32.603+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:32.602+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:48:32.630+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:32.630+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:48:32.517528+00:00, run_after=2023-01-30T21:48:32.517528+00:00
[2023-01-29T21:48:32.634+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:32.634+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:48:32.517528+00:00, run_after=2023-01-30T21:48:32.517528+00:00
[2023-01-29T21:48:32.655+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.655 seconds
[2023-01-29T21:48:42.771+0000] {processor.py:153} INFO - Started process (PID=2937) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:42.772+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:48:42.773+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:42.772+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:51.231+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:48:51.245+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:51.244+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:48:51.270+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:51.270+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:48:51.219890+00:00, run_after=2023-01-30T21:48:51.219890+00:00
[2023-01-29T21:48:51.274+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:48:51.274+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:48:51.219890+00:00, run_after=2023-01-30T21:48:51.219890+00:00
[2023-01-29T21:48:51.292+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.529 seconds
[2023-01-29T21:49:01.406+0000] {processor.py:153} INFO - Started process (PID=2943) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:01.407+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:49:01.408+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:01.408+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:08.848+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:08.924+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:08.923+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:49:08.949+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:08.949+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:49:08.837946+00:00, run_after=2023-01-30T21:49:08.837946+00:00
[2023-01-29T21:49:08.953+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:08.953+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:49:08.837946+00:00, run_after=2023-01-30T21:49:08.837946+00:00
[2023-01-29T21:49:08.974+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.576 seconds
[2023-01-29T21:49:19.078+0000] {processor.py:153} INFO - Started process (PID=2949) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:19.079+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:49:19.080+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:19.080+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:27.453+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:27.477+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:27.476+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:49:27.520+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:27.520+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:49:27.442854+00:00, run_after=2023-01-30T21:49:27.442854+00:00
[2023-01-29T21:49:27.524+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:27.524+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:49:27.442854+00:00, run_after=2023-01-30T21:49:27.442854+00:00
[2023-01-29T21:49:27.543+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.469 seconds
[2023-01-29T21:49:37.645+0000] {processor.py:153} INFO - Started process (PID=2955) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:37.646+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:49:37.647+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:37.647+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:45.526+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:45.619+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:45.618+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:49:45.655+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:45.655+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:49:45.516268+00:00, run_after=2023-01-30T21:49:45.516268+00:00
[2023-01-29T21:49:45.660+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:45.660+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:49:45.516268+00:00, run_after=2023-01-30T21:49:45.516268+00:00
[2023-01-29T21:49:45.685+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.046 seconds
[2023-01-29T21:49:55.788+0000] {processor.py:153} INFO - Started process (PID=2961) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:49:55.789+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:49:55.790+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:49:55.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:04.109+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:04.123+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:04.123+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:50:04.149+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:04.149+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:50:04.094776+00:00, run_after=2023-01-30T21:50:04.094776+00:00
[2023-01-29T21:50:04.153+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:04.153+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:50:04.094776+00:00, run_after=2023-01-30T21:50:04.094776+00:00
[2023-01-29T21:50:04.172+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.389 seconds
[2023-01-29T21:50:14.301+0000] {processor.py:153} INFO - Started process (PID=2967) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:14.302+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:50:14.303+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:14.303+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:22.663+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:22.749+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:22.748+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:50:22.772+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:22.772+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:50:22.652559+00:00, run_after=2023-01-30T21:50:22.652559+00:00
[2023-01-29T21:50:22.775+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:22.775+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:50:22.652559+00:00, run_after=2023-01-30T21:50:22.652559+00:00
[2023-01-29T21:50:22.796+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.508 seconds
[2023-01-29T21:50:32.893+0000] {processor.py:153} INFO - Started process (PID=2973) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:32.894+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:50:32.895+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:32.895+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:40.741+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:40.779+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:40.778+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:50:40.841+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:40.841+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:50:40.711295+00:00, run_after=2023-01-30T21:50:40.711295+00:00
[2023-01-29T21:50:40.854+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:40.853+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:50:40.711295+00:00, run_after=2023-01-30T21:50:40.711295+00:00
[2023-01-29T21:50:40.881+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.993 seconds
[2023-01-29T21:50:51.007+0000] {processor.py:153} INFO - Started process (PID=2979) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:51.008+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:50:51.009+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:51.009+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:59.304+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:50:59.382+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:59.381+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:50:59.406+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:59.406+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:50:59.294326+00:00, run_after=2023-01-30T21:50:59.294326+00:00
[2023-01-29T21:50:59.409+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:50:59.409+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:50:59.294326+00:00, run_after=2023-01-30T21:50:59.294326+00:00
[2023-01-29T21:50:59.437+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.434 seconds
[2023-01-29T21:51:09.532+0000] {processor.py:153} INFO - Started process (PID=2985) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:09.533+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:51:09.534+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:09.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:17.181+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:17.206+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:17.205+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:51:17.253+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:17.253+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:51:17.165883+00:00, run_after=2023-01-30T21:51:17.165883+00:00
[2023-01-29T21:51:17.258+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:17.258+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:51:17.165883+00:00, run_after=2023-01-30T21:51:17.165883+00:00
[2023-01-29T21:51:17.284+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.757 seconds
[2023-01-29T21:51:27.386+0000] {processor.py:153} INFO - Started process (PID=2991) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:27.387+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:51:27.388+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:27.388+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:35.887+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:35.963+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:35.963+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:51:35.988+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:35.988+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:51:35.875930+00:00, run_after=2023-01-30T21:51:35.875930+00:00
[2023-01-29T21:51:35.993+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:35.993+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:51:35.875930+00:00, run_after=2023-01-30T21:51:35.875930+00:00
[2023-01-29T21:51:36.015+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.633 seconds
[2023-01-29T21:51:46.109+0000] {processor.py:153} INFO - Started process (PID=2997) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:46.111+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:51:46.111+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:46.111+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:53.315+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:51:53.329+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:53.328+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:51:53.355+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:53.355+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:51:53.305407+00:00, run_after=2023-01-30T21:51:53.305407+00:00
[2023-01-29T21:51:53.359+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:51:53.359+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:51:53.305407+00:00, run_after=2023-01-30T21:51:53.305407+00:00
[2023-01-29T21:51:53.379+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.274 seconds
[2023-01-29T21:52:03.492+0000] {processor.py:153} INFO - Started process (PID=3003) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:03.494+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:52:03.495+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:03.495+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:11.946+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:12.025+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:12.024+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:52:12.050+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:12.050+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:52:11.934018+00:00, run_after=2023-01-30T21:52:11.934018+00:00
[2023-01-29T21:52:12.054+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:12.054+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:52:11.934018+00:00, run_after=2023-01-30T21:52:11.934018+00:00
[2023-01-29T21:52:12.075+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.589 seconds
[2023-01-29T21:52:22.173+0000] {processor.py:153} INFO - Started process (PID=3009) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:22.174+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:52:22.175+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:22.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:29.862+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:29.876+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:29.875+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:52:29.901+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:29.901+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:52:29.851840+00:00, run_after=2023-01-30T21:52:29.851840+00:00
[2023-01-29T21:52:29.904+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:29.904+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:52:29.851840+00:00, run_after=2023-01-30T21:52:29.851840+00:00
[2023-01-29T21:52:29.923+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.755 seconds
[2023-01-29T21:52:40.019+0000] {processor.py:153} INFO - Started process (PID=3015) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:40.020+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:52:40.022+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:40.021+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:48.456+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:48.561+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:48.561+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:52:48.585+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:48.585+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:52:48.440122+00:00, run_after=2023-01-30T21:52:48.440122+00:00
[2023-01-29T21:52:48.589+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:48.589+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:52:48.440122+00:00, run_after=2023-01-30T21:52:48.440122+00:00
[2023-01-29T21:52:48.631+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.617 seconds
[2023-01-29T21:52:58.751+0000] {processor.py:153} INFO - Started process (PID=3021) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:52:58.753+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:52:58.754+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:52:58.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:05.844+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:05.858+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:05.857+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:53:05.883+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:05.883+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:53:05.834100+00:00, run_after=2023-01-30T21:53:05.834100+00:00
[2023-01-29T21:53:05.887+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:05.887+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:53:05.834100+00:00, run_after=2023-01-30T21:53:05.834100+00:00
[2023-01-29T21:53:05.908+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.163 seconds
[2023-01-29T21:53:15.998+0000] {processor.py:153} INFO - Started process (PID=3027) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:15.999+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:53:16.000+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:16.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:24.291+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:24.369+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:24.369+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:53:24.394+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:24.394+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:53:24.281286+00:00, run_after=2023-01-30T21:53:24.281286+00:00
[2023-01-29T21:53:24.398+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:24.398+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:53:24.281286+00:00, run_after=2023-01-30T21:53:24.281286+00:00
[2023-01-29T21:53:24.429+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.436 seconds
[2023-01-29T21:53:34.523+0000] {processor.py:153} INFO - Started process (PID=3033) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:34.524+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:53:34.525+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:34.525+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:41.597+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:41.612+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:41.611+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:53:41.638+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:41.638+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:53:41.587120+00:00, run_after=2023-01-30T21:53:41.587120+00:00
[2023-01-29T21:53:41.642+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:41.642+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:53:41.587120+00:00, run_after=2023-01-30T21:53:41.587120+00:00
[2023-01-29T21:53:41.660+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.142 seconds
[2023-01-29T21:53:51.836+0000] {processor.py:153} INFO - Started process (PID=3039) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:53:51.855+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:53:51.856+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:53:51.856+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:00.351+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:00.425+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:00.424+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:54:00.462+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:00.462+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:54:00.341510+00:00, run_after=2023-01-30T21:54:00.341510+00:00
[2023-01-29T21:54:00.466+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:00.466+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:54:00.341510+00:00, run_after=2023-01-30T21:54:00.341510+00:00
[2023-01-29T21:54:00.495+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.689 seconds
[2023-01-29T21:54:10.610+0000] {processor.py:153} INFO - Started process (PID=3045) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:10.611+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:54:10.612+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:10.612+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:17.740+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:17.755+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:17.753+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:54:17.781+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:17.780+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:54:17.729871+00:00, run_after=2023-01-30T21:54:17.729871+00:00
[2023-01-29T21:54:17.784+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:17.784+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:54:17.729871+00:00, run_after=2023-01-30T21:54:17.729871+00:00
[2023-01-29T21:54:17.803+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.199 seconds
[2023-01-29T21:54:27.895+0000] {processor.py:153} INFO - Started process (PID=3051) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:27.901+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:54:27.903+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:27.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:36.210+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:36.293+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:36.292+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:54:36.323+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:36.323+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:54:36.199460+00:00, run_after=2023-01-30T21:54:36.199460+00:00
[2023-01-29T21:54:36.330+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:36.330+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:54:36.199460+00:00, run_after=2023-01-30T21:54:36.199460+00:00
[2023-01-29T21:54:36.351+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.463 seconds
[2023-01-29T21:54:46.451+0000] {processor.py:153} INFO - Started process (PID=3057) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:46.453+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:54:46.454+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:46.454+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:53.936+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:54:53.949+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:53.948+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:54:53.974+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:53.974+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:54:53.925744+00:00, run_after=2023-01-30T21:54:53.925744+00:00
[2023-01-29T21:54:53.978+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:54:53.978+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:54:53.925744+00:00, run_after=2023-01-30T21:54:53.925744+00:00
[2023-01-29T21:54:53.996+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.552 seconds
[2023-01-29T21:55:04.089+0000] {processor.py:153} INFO - Started process (PID=3063) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:04.090+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:55:04.091+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:04.090+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:12.948+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:13.089+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:13.088+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:55:13.114+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:13.114+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:55:12.932633+00:00, run_after=2023-01-30T21:55:12.932633+00:00
[2023-01-29T21:55:13.118+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:13.117+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:55:12.932633+00:00, run_after=2023-01-30T21:55:12.932633+00:00
[2023-01-29T21:55:13.138+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 9.056 seconds
[2023-01-29T21:55:23.290+0000] {processor.py:153} INFO - Started process (PID=3069) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:23.292+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:55:23.293+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:23.293+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:31.353+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:31.366+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:31.366+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:55:31.392+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:31.392+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:55:31.343245+00:00, run_after=2023-01-30T21:55:31.343245+00:00
[2023-01-29T21:55:31.395+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:31.395+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:55:31.343245+00:00, run_after=2023-01-30T21:55:31.343245+00:00
[2023-01-29T21:55:31.414+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.148 seconds
[2023-01-29T21:55:41.509+0000] {processor.py:153} INFO - Started process (PID=3075) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:41.511+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:55:41.512+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:41.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:49.994+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:55:50.071+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:50.071+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:55:50.096+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:50.096+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:55:49.984184+00:00, run_after=2023-01-30T21:55:49.984184+00:00
[2023-01-29T21:55:50.099+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:55:50.099+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:55:49.984184+00:00, run_after=2023-01-30T21:55:49.984184+00:00
[2023-01-29T21:55:50.119+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.617 seconds
[2023-01-29T21:56:00.247+0000] {processor.py:153} INFO - Started process (PID=3081) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:00.249+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:56:00.250+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:00.250+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:08.057+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:08.070+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:08.069+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:56:08.095+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:08.095+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:56:08.047166+00:00, run_after=2023-01-30T21:56:08.047166+00:00
[2023-01-29T21:56:08.099+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:08.099+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:56:08.047166+00:00, run_after=2023-01-30T21:56:08.047166+00:00
[2023-01-29T21:56:08.118+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.892 seconds
[2023-01-29T21:56:18.214+0000] {processor.py:153} INFO - Started process (PID=3087) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:18.215+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:56:18.216+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:18.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:26.735+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:26.810+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:26.809+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:56:26.835+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:26.835+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:56:26.724277+00:00, run_after=2023-01-30T21:56:26.724277+00:00
[2023-01-29T21:56:26.839+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:26.838+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:56:26.724277+00:00, run_after=2023-01-30T21:56:26.724277+00:00
[2023-01-29T21:56:26.860+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.650 seconds
[2023-01-29T21:56:36.968+0000] {processor.py:153} INFO - Started process (PID=3093) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:36.970+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:56:36.971+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:36.971+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:44.243+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:44.257+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:44.257+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:56:44.288+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:44.287+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:56:44.232782+00:00, run_after=2023-01-30T21:56:44.232782+00:00
[2023-01-29T21:56:44.293+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:44.293+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:56:44.232782+00:00, run_after=2023-01-30T21:56:44.232782+00:00
[2023-01-29T21:56:44.321+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.361 seconds
[2023-01-29T21:56:54.425+0000] {processor.py:153} INFO - Started process (PID=3099) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:56:54.428+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:56:54.429+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:56:54.429+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:03.270+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:03.346+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:03.345+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:57:03.370+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:03.370+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:57:03.259088+00:00, run_after=2023-01-30T21:57:03.259088+00:00
[2023-01-29T21:57:03.373+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:03.373+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:57:03.259088+00:00, run_after=2023-01-30T21:57:03.259088+00:00
[2023-01-29T21:57:03.394+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.975 seconds
[2023-01-29T21:57:13.496+0000] {processor.py:153} INFO - Started process (PID=3105) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:13.498+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:57:13.499+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:13.499+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:20.792+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_1', 'data_pipeline_2']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:20.806+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:20.805+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:57:20.834+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:20.834+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:57:20.782140+00:00, run_after=2023-01-30T21:57:20.782140+00:00
[2023-01-29T21:57:20.840+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:20.840+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:57:20.782140+00:00, run_after=2023-01-30T21:57:20.782140+00:00
[2023-01-29T21:57:20.889+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 7.400 seconds
[2023-01-29T21:57:31.029+0000] {processor.py:153} INFO - Started process (PID=3111) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:31.030+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:57:31.031+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:31.031+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:39.267+0000] {processor.py:753} INFO - DAG(s) dict_keys(['data_pipeline_2', 'data_pipeline_1']) retrieved from /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:39.359+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:39.358+0000] {dag.py:2690} INFO - Sync 2 DAGs
[2023-01-29T21:57:39.388+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:39.388+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_1 to 2023-01-29T21:57:39.257383+00:00, run_after=2023-01-30T21:57:39.257383+00:00
[2023-01-29T21:57:39.396+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:39.396+0000] {dag.py:3441} INFO - Setting next_dagrun for data_pipeline_2 to 2023-01-29T21:57:39.257383+00:00, run_after=2023-01-30T21:57:39.257383+00:00
[2023-01-29T21:57:39.425+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/etl_dag.py took 8.401 seconds
[2023-01-29T21:57:49.537+0000] {processor.py:153} INFO - Started process (PID=3117) to work on /opt/airflow/dags/etl_dag.py
[2023-01-29T21:57:49.539+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/etl_dag.py for tasks to queue
[2023-01-29T21:57:49.540+0000] {logging_mixin.py:137} INFO - [2023-01-29T21:57:49.540+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dag.py
