[2023-01-23T14:30:24.703+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: data_extraction_and_loading_3.extract_data scheduled__2022-01-25T00:00:00+00:00 [queued]>
[2023-01-23T14:30:24.738+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: data_extraction_and_loading_3.extract_data scheduled__2022-01-25T00:00:00+00:00 [queued]>
[2023-01-23T14:30:24.742+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-01-23T14:30:24.747+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2023-01-23T14:30:24.750+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-01-23T14:30:24.896+0000] {taskinstance.py:1300} INFO - Executing <Task(PythonOperator): extract_data> on 2022-01-25 00:00:00+00:00
[2023-01-23T14:30:25.142+0000] {standard_task_runner.py:55} INFO - Started process 1507 to run task
[2023-01-23T14:30:25.205+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'data_extraction_and_loading_3', 'extract_data', 'scheduled__2022-01-25T00:00:00+00:00', '--job-id', '70', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpt14ae4b0']
[2023-01-23T14:30:25.244+0000] {standard_task_runner.py:83} INFO - Job 70: Subtask extract_data
[2023-01-23T14:30:25.369+0000] {logging_mixin.py:137} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:249 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-01-23T14:30:25.538+0000] {logging_mixin.py:137} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-01-23T14:30:25.759+0000] {task_command.py:388} INFO - Running <TaskInstance: data_extraction_and_loading_3.extract_data scheduled__2022-01-25T00:00:00+00:00 [running]> on host 1b696c32fad4
[2023-01-23T14:30:27.203+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=abdessamad
AIRFLOW_CTX_DAG_ID=data_extraction_and_loading_3
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2022-01-25T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-25T00:00:00+00:00
[2023-01-23T14:31:15.598+0000] {python.py:177} INFO - Done. Returned value was: (<helpers.DataExtractor object at 0xffff83416890>, [{'description': "Description de l'entreprise\n\nAccélérez votre carrière au sein d’un groupe d’ingénierie mondial à forte croissance. Chez SEGULA Technologies, vous travaillerez sur des projets passionnants et contribuerez à façonner l’avenir au sein d’une entreprise pour qui l’innovation est indissociable de l’ingénierie.\nImpression 3D, réalité augmentée, véhicule autonome, usine du futur… rythment le quotidien de nos 13 000 ingénieux collaborateurs, pourquoi pas le vôtre ?\nÀ côté de chez vous ou à l’autre bout de la planète, vous trouverez chez SEGULA Technologies l’opportunité qui donnera un sens nouveau à votre carrière !\n\nDescription du poste\n\nDans le cadre de nos activités aéronautiques sur Marignane (13), nous recherchons un Data Analyst Junior H/F.\nLe/la Data Analyst Junior sera rattaché au service Service Maintenance Repair & Overhaull (MRO) des ensembles mécaniques d'H/C.\n\nVos missions:\nEffectuer la maintenance d'un outil excel connecté à un système access déjà existant avec plus de 150 utilisateurs par jour.\nEffectuer les dépannages logiciels sur les dysfonctionnements remontés par les opérationnels\nAnalyser les données pour extraire des pilotages d'activité\nL’analyse des données recueillies et leur tri en fonction de leur pertinence pour la problématique de l’entreprise\nl’amélioration constante du système de récupération des données client afin d’optimiser et d’agrandir le stock de données possédé par l’entreprise\n\nQualifications\n\nVous disposez d'au moins 1/2 ans d'expérience en alternance ou vous sortez récemment de formation.\nVous avez des connaissance en gestion de production industrielle.\nLe langage des données SQL + VBA n'a pas de secret pour vous\nLa maitrise des outils comme : suite office, excel est indispensable.\nLa connaissance des outils SAP et Access est un plus.\nAlors n'hésitez plus ! Faites nous parvenir votre CV !\n\nInformations supplémentaires\n\nContrat: CDI\nLieu: Marignane (13)\nOuverture du poste: Dés que possible\nHoraire: 35h journée\nRémunération: selon profil + avantages"}, {'description': "Description de l'entreprise\n\nAccélérez votre carrière au sein d’un groupe d’ingénierie mondial à forte croissance. Chez SEGULA Technologies, vous travaillerez sur des projets passionnants et contribuerez à façonner l’avenir au sein d’une entreprise pour qui l’innovation est indissociable de l’ingénierie.\nImpression 3D, réalité augmentée, véhicule autonome, usine du futur… rythment le quotidien de nos 13 000 ingénieux collaborateurs, pourquoi pas le vôtre ?\nÀ côté de chez vous ou à l’autre bout de la planète, vous trouverez chez SEGULA Technologies l’opportunité qui donnera un sens nouveau à votre carrière !\n\nDescription du poste\n\nDans le cadre de nos activités aéronautiques sur Marignane (13), nous recherchons un Data Analyst Junior H/F.\nLe/la Data Analyst Junior sera rattaché au service Service Maintenance Repair & Overhaull (MRO) des ensembles mécaniques d'H/C.\n\nVos missions:\nEffectuer la maintenance d'un outil excel connecté à un système access déjà existant avec plus de 150 utilisateurs par jour.\nEffectuer les dépannages logiciels sur les dysfonctionnements remontés par les opérationnels\nAnalyser les données pour extraire des pilotages d'activité\nL’analyse des données recueillies et leur tri en fonction de leur pertinence pour la problématique de l’entreprise\nl’amélioration constante du système de récupération des données client afin d’optimiser et d’agrandir le stock de données possédé par l’entreprise\n\nQualifications\n\nVous disposez d'au moins 1/2 ans d'expérience en alternance ou vous sortez récemment de formation.\nVous avez des connaissance en gestion de production industrielle.\nLe langage des données SQL + VBA n'a pas de secret pour vous\nLa maitrise des outils comme : suite office, excel est indispensable.\nLa connaissance des outils SAP et Access est un plus.\nAlors n'hésitez plus ! Faites nous parvenir votre CV !\n\nInformations supplémentaires\n\nContrat: CDI\nLieu: Marignane (13)\nOuverture du poste: Dés que possible\nHoraire: 35h journée\nRémunération: selon profil + avantages"}, {'description': "Référence de l’offre\n23000086\nType de contrat\nCDI\nNiveau d'expérience\nExpérimentés\nSociété du groupeAXA Investment Managers\nFamille métier\nIT, Data & Transformation\nLocalisation\nPUTEAUX, Hauts-de-Seine\n\nVotre rôle et vos missions\nLe titulaire intègre l’équipe Portfolios & Third Party Data, située au sein du département Data & Analytics Management, le centre d’expertise interne relativement à l’administration, à la qualité et à la gouvernance des données et des analytics.\nL’équipe Portfolios & Third Party Data administre plusieurs référentiels de données centraux d’AXA IM, notamment ceux relatifs aux définitions des portefeuilles et aux entités tiers. Par ailleurs, l’équipe supervise la gestion par des partenaires externes de certains référentiels de données externalisés, en particulier ceux ayant trait aux NAV des produits ainsi qu’aux transactions et détentions côté clients.\nAu-delà de sa contribution aux activités de l’équipe d’administration et de modélisation des données, le titulaire sera amené à participer à la transformation en cours de nos référentiels de données, et aidera à ce titre l’équipe à utiliser au mieux les nouvelles capacités data dont s’est dotée AXA IM, notamment en matière d’ingestion, de transformation, et de distribution des données (Data Platform), et en matière d’analyse et d’exploration de données (Data Science Studio).\nKey Accountabilities\nAdministration des référentiels de données\nRépondre aux demandes de support émanant des utilisateurs des données au sein d’AXA IM\nAviser quant aux éléments et modèles de données appropriés pour répondre aux besoins des initiatives métier et règlementaires\nContribuer à l’amélioration générale de la qualité des données et des analytics au sein des référentiels, en mettant en place des process d’acquisition de données adéquats et des contrôles sur ces données\nTransformation des référentiels de données\nElaborer la stratégie permettant aux équipes du périmètre Data & Analytics Management de supporter efficacement les données de référence présentes dans la Data Platform, au-delà des référentiels de données existants\nUtiliser au mieux le Data Science Studio et ses capacités d’analyse et d’exploration massives de données, afin de construire des tableaux de bord de suivi de la qualité des données, et d’explorer de nouveaux jeux de données actuellement non couverts dans les référentiels\nVotre profil\nConnaissances générales en finance, et plus spécifiquement relatives aux concepts de gestion d’actifs : portefeuilles, instruments financiers, …\nAttrait marqué pour la modélisation et la gouvernance des données et des analytics\nCapacité à coder en Python pour l’automatisation et l’analyse et la visualisation de données\nFamiliarité avec les outils de gestion et d’administration de données\nTrès bonnes capacités de communication et d’interaction\nCapacité à interagir avec des profils divers, tels que : gestionnaires des données, fournisseurs de données, développeurs, responsables middle office, analystes de performance, gérants de portefeuilles, …\nCapacité à organiser les priorités et à gérer de multiples sujets de front\nAttention portée aux détails\nFrançais et Anglais courants (lu, écrit et parlé) indispensable\nVotre environnement de travail\nAimeriez-vous vous lever chaque jour motivé(e) par une mission inspirante et travailler en équipe pour permettre de protéger les personnes et leurs proches? Chez AXA nous avons l’ambition de mener la transformation de notre métier. Nous cherchons des personnes talentueuses ayant une expérience diversifiée, qui pensent différemment, et qui veulent faire partie de cette transformation passionnante en challengeant le statu quo et faire d’AXA – marque globale leader et une des sociétés les plus innovantes dans notre secteur – une entreprise encore plus performante et responsable. Dans un monde en perpétuelle évolution et avec une présence dans 64 pays, nos 166 000 salariés et distributeurs privilégiés anticipent le changement pour offrir des services et solutions adaptés aux besoins actuels et futurs de nos 103 millions de clients.\n\nAXA Investment Managers (AXA IM) est un gestionnaire d’actifs responsable qui investit activement sur le long terme pour la prospérité de ses clients, de ses collaborateurs et de la planète. Avec environ 866 milliards d’euros d’actifs sous gestion à fin juin 2021, notre gestion de conviction nous permet d’identifier les opportunités d’investissement que nous considérons comme les meilleures du marché à l’échelle mondiale dans les différentes classes d’actifs alternatives et traditionnelles. AXA IM est un leader sur le marché de l’investissement vert, social et durable, avec 568 milliards d’euros d’actifs intégrant des critères ESG, durables ou à impact, à fin juin 2021. Nous nous sommes engagés à atteindre l’objectif de zéro émission nette de gaz à effet de serre d’ici 2050 pour l’ensemble de nos actifs, et à intégrer les considérations ESG dans nos activités, de la sélection des titres à notre culture d’entreprise en passant par la façon dont nous gérons nos opérations au quotidien. Nous souhaitons apporter de la valeur à nos clients grâce à des solutions d’investissement responsables, tout en suscitant des changements significatifs pour la société et l’environnement. A fin juin 2021, AXA IM emploie plus de 2 488 collaborateurs dans le monde, répartis dans 26 bureaux et 20 pays. AXA IM fait partie du Groupe AXA, un leader mondial de l’assurance et de la gestion d’actifs.\nPourquoi nous rejoindre ?\nNous sommes fiers de promouvoir une culture de la performance ce qui veut dire que nous cherchons à recruter des personnes qui sont non seulement compétentes techniquement mais également ouvertes à l'international, innovants et capables de mettre à contribution leurs perspectives et expériences uniques afin d'accompagner nos succès en tant qu'entreprise. Employer les meilleurs professionnels parmi le plus large vivier de talents possible est au cœur de notre stratégie qui consiste à délivrer une excellente qualité de service à notre clientèle diversifiée. AXA IM s’engage à développer une culture inclusive, mettant en valeur la diversité et soutenant la progression de carrière de l’ensemble de ses collaborateurs et collaboratrices."}, {'description': "Entreprise : Airbus Helicopters SAS\nLocalisation : Marseille - France - Provence-Alpes-Côte d’Azur\nFonction : Data Scientist F/M\nType de contrat : Contrat à durée indéterminée (CDI)\nDate de publication : 20-01-2023\nDescription du poste\nDescription de l'emploi :\nAirbus Helicopters is looking for a Data Scientist (f/m) to join our Marketing department based in Marignane, France.\nYou will be part of a team of 6 people developing market & real flight analysis. As part of the Marketing Data Science team, you will be involved in developing new models & methodologies to understand, anticipate and drive the helicopter market.\nYour working environment:\nMajor economic hub with Marseille-Provence Airport, Marignane is located near the cities of Aix-en-Provence and Marseille, which host a rich cultural and tourist offer. Close to the beaches of the Côte Bleue, it offers many options for water sports activities and sunny weather all year long.\nHow we care for you:\nFinancial rewards: Attractive salary, agreements on success and profit sharing schemes, employee savings plan abounded by Airbus and employee stock purchase plan on a voluntary basis.\nWork / Life Balance: Extra days-off for special occasions, holiday transfer option, a Staff council offering many social, cultural and sport activities and other services.\nWellbeing / Health: Complementary health insurance coverage (disability, invalidity, death). Depending on the site: health services center, concierge services, gym, carpooling application.\nIndividual development: Great upskilling opportunities and development prospects with unlimited access to +10.000 e-learning courses to develop your employability, certifications, expert career path, accelerated development programmes, national and international mobility.\nAt Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.\n\nYour challenges:\nYour main mission will be to develop new models and methodologies for helicopter market forecasts and analysis. This includes the development of new econometric or optimization models and apply statistical methodologies to support the strategic decision making process of Airbus Helicopters.\nYou will have the possibility to work on geospatial data, linked to real flights of our aircraft.\nYou will work on large datasets. You must have a proven ability to drive business insights with data-based insights.\nYou must be comfortable working with a wide range of stakeholders and functional teams.\nIn this position, you will also contribute to marketing digital transformation on data projects that are transversal to the whole company.\nYou will work on internal and external data sets (Helicopter fleet datasets, helicopter operations (flights), macroeconomic datasets, environment datasets?).\nYou will be working closely with the following departments:\nMarket analysts;\nInformation management and digital transformation;\nStrategy;\nSales?\nYour profile:\n1-2 years on a similar position\nMaster's degree in data science, Statistics, Econometrics, applied Mathematics\nStatistical methods\nMathematical optimization\nEconometrics (Panel data models, regression, time series ?)\nProgramming (Python, R, PySpark?)\nAble to communicate and explain complex processes in a simple way\nTeam spirit\nInnovator\nEnglish: Negotiation\nFrench: Negotiation\nWhat would be seen has an advantage:\nKnowledge about the aerospace domain\nData visualization\nThis position requires a security clearance or will require being eligible for clearance by the recognized authorities.\nNot a 100% match? No worries! Airbus supports your personal growth with customized development solutions.\nTake your career to a new level and apply online now!\nCet emploi exige une connaissance des risques de conformité potentiels et un engagement à agir avec intégrité, comme base de la réussite, de la réputation et de la croissance durable de la société.\nProfil recherché\nDate de début : nc.\nDurée : nc.\nExpérience requise : Débutant / Jeune diplomé\nSalaire : nc.\nRéférence : JR10154608\nSecteur d'activité : Industrialisation, Production"}, {'description': "Entreprise : Airbus Protect SAS\nLocalisation : Toulouse - France - Occitanie\nFonction : Data Scientist / Engineer Skywise\nType de contrat : Contrat à durée indéterminée (CDI)\nDate de publication : 20-01-2023\nDescription du poste\nDescription de l'emploi :\nAirbus PROTECT rassemble des experts dans les métiers de la safety, de la cybersecurity et de la sustainability. Nous mettons notre expertise au service de notre propre groupe, Airbus, auprès de qui nous agissons en tant que partenaire privilégié, mais également au service de clients externes.\nAvec plus de 1.200 collaborateurs expérimentés basés notamment en France, en Angleterre et en Allemagne, nous gérons des contrats de grande envergure avec des entreprises telles que des infrastructures critiques (OIVs), d'autres groupes industriels ou encore des institutions publiques. Notre positionnement et notre stratégie nous permettent de répondre aux normes les plus élevées du marché et de relever les défis de demain en équipe? avec vous !\nVotre futur job, si vous l'acceptez?\nDéploiement et automatisation de pipelines de données\nIndustrialisation d'algorithmes de Machine Learning\nDéveloppement de produits Skywise / Palantir / AWS (Front/Back)\nDévelopper de nouveaux systèmes de bases de données (logique NoSQL)\nConception et développement de nouveaux uses cases\nParticipation aux cérémonies Agile\nGestion de base de données NoSQL orienté Graph (Neo4J, Neptune, ArangoDB)\nIndustrialisation des algorithmes de Machine Learning provenant d'équipe de Data Scientist\nSurveillance, déploiement et intervention sur les produits Skywise développés\nAccompagnement de l'équipe dans le déploiement de produits IA pour Airbus Protect et le groupe\nEtes-vous notre futur talent ?\nVous êtes Ingénieur IA, de formation grandes écoles ou universités.\nVous possédez a minima 3 ans d'expérience en data science et/ou data engineering.\nVous avez de solides connaissances sur les technologies Skywise et Palantir et en gestion de flux de données (lineage, ontology)\nUne connaissance des architectures web, basés sur les évènements et micro-services (+API) serait un plus.\nVous connaissez et savez diffuser les bonnes pratiques de développement Skywise et Agile\nVous avez de bonnes aptitudes en communication et la capacité à présenter des sujets techniques complexes aux principaux acteurs de l'entreprise de manière convaincante.\nVous êtes rigoureux avec le sens du détail et une passion pour les solutions et les technologies qui résolvent les problèmes.\nVous savez faire preuve d'autonomie avec des capacités d'écoute active et de prise d'initiatives pragmatiques\nEnglish intermediate needed\nVous recherchez un poste avec une activité variée et de réelles opportunités d'évolution?\nVenez vivre l'aventure Airbus Protect? On vous attend !\nCet emploi exige une connaissance des risques de conformité potentiels et un engagement à agir avec intégrité, comme base de la réussite, de la réputation et de la croissance durable de la société.\nProfil recherché\nDate de début : nc.\nDurée : nc.\nExpérience requise : Plus de 10 ans d'expérience\nSalaire : nc.\nRéférence : JR10150294\nSecteur d'activité : Industrialisation, Production"}, {'description': 'Job Title\nData Analyst\nThe objective of the role ?\nTo develop and implement analytics applications and dashboards in Qlik and PowerBI on the cytric Data Platform.\nCommon accountabilities:\n\nWorks autonomously within defined processes and procedures or methodologies, takes standard decisions and may support the development of solutions to complex problems of a recurring nature.\n\nReceives instruction, guidance and direction from more senior level roles or manager, with regular monitoring on the status of the assignments.\n\nMay have specialized formal education or the equivalent work experience and has the required technical and functional skills and basic knowledge of the business.\n\nSpecific accountabilities:\n\nImplement data analysis algorithms on a large scale working closely with software engineering members\nCreate business solutions through a combination of science and software considering hypothesis by concrete business effect.\nDevelop products / service cooperating with project manager, developer and business staff.\nBuild & Maintain the “Big Data” infrastructure\nTrack business effect through products and leading next action.\nOperate and manage product to keep product availability cooperating with operation staff\nDiversity & Inclusion\nWe are an Equal Opportunity Employer and seek to hire the best candidate regardless of age, beliefs, disability, ethnicity, gender or sexual orientation.'}, {'description': "Stage\nTemps plein\n6 mois\nBac+5\nDémarrage souhaité : 6 mars 2023\n27-31, avenue du Général Leclerc\n94 700 Maisons Alfort\nFRANCE\n\nVous cherchez à vivre une expérience professionnelle enrichissante et trouver du sens dans vos missions au quotidien ? Rejoignez l’aventure Bpifrance et faites partie de la nouvelle promotion de stagiaires et d’alternants prêts à Servir l’Avenir !\n\nBpifrance, une banque pas comme les autres\n\nLe rôle de Bpifrance, Banque Publique d’Investissement, est de dynamiser et rendre plus compétitive l’économie française.\nBpifrance soutient les entreprises françaises pour accélérer leur développement en France comme à l’international et renforcer leurs capacités d’innovation. Banque génératrice de croissance et de confiance, elle offre une palette de solutions de financement et d’accompagnement adaptées à chaque étape de la vie des entreprises, et fait de la transition écologique et énergétique une priorité stratégique. En tant qu’interlocuteur privilégié, les équipes sont au cœur des régions sur l'ensemble du territoire, à travers 50 implantations régionales.\n\nNotre ambition ? Devenir une Fintech. Et nous avons besoin des meilleurs !\n\nNous souhaitons transmuter pour devenir une FINTECH et offrir les meilleurs services digitaux à l’ensemble de nos clients, grâce à des plateformes digitales.\n\nLe goût du challenge\nNous avons développé notre propre techno : Hypercube qui porte l’ensemble de nos services banque en ligne. Nous agissons par les events, les API, les socles. Nous sommes Cloud first, Data centriques; nous rénovons toute notre tech avec les meilleures stacks et nous le faisons en agile à l’échelle. Ce projet, c’est bien. C’est même plus que bien, c’est révolutionnaire. Mais on veut aller encore plus loin.\n\n\nNous avons le goût du challenge et nos clients ont besoin de nous plus que jamais !\nEn Mars 2020, au cœur de la pandémie de Covid-19 qui frappait le monde, les entreprises françaises en pleine crise, nous avons réussi l’impossible : monter en seulement 3 semaines l’intégralité de la plateforme qui allait permettre de soutenir des centaines de milliers d’entreprises.\nVos missions au service de l’économie française\nLa validation et la revue régulière des modèles quantitatifs de Bpifrance\nLa supervision de backtests annuels sur les modèles quantitatifs\nLe développement de mesures de risque de modèle purement statistiques ou à dires d’expert\nLe Pôle de Validation des Modèles est le point d’entrée des contrôles externes sur les modèles (DGAU, Commissaires aux comptes, BCE, actionnaires...).\n\nObjectifs et problématiques du stage :\nAnalyser le comportement des modèles existants en exploitant des bases de données volumineuses\nChallenger les approches de modélisation employées en développant/exploitant des modèles miroirs\nProposer et développer des mesures de risque sur les modèles\nContribuer au développement d’outils permettant le contrôle permanent du risque de modèle\n\nPrêts à rejoindre notre équipe ?\n\nVous êtes de formation BAC+5 écoles d’ingénieur ou d’actuariat, 3ème cycle universitaire statistique ou économétrie\n\nUne première expérience dans le domaine bancaire serait un plus (stage court, césure, alternance...)\n\nPrincipales qualités requises :\n\nMaitrise du logiciel Python, et éventuellement SAS et/ou R\n\nCuriosité, pro-activité\nBonnes capacités rédactionnelles\n\nAptitude à proposer des solutions innovantes\n\nOutils statistiques ou méthodes utilisés :\n\nModèles statistiques\nMesures de risques\nAnalyse de données descriptive\nVous serez amené à exploiter des bases de données en utilisant Python.\n\nLes bonnes raisons de rejoindre l’aventure Bpifrance !\n\nUn travail avec du sens : Vous contribuerez à une mission unique d’utilité publique au service de l’économie française et au sein d’une banque engagée sur des sujets de société (climat, jeunesse, égalité des chances…).\nUn environnement dans lequel il fait bon vivre : Labellisé parmi les Meilleurs Employeurs France 2022 par Glassdoor et certifié Happy Trainees pour la 7e année consécutive, rejoindre Bpifrance c’est intégrer une banque engagée auprès des jeunes et évoluer au sein d'équipes dynamiques et bienveillantes.\nDes conditions avantageuses : Vous bénéficierez des nombreux avantages qu’offre le groupe pour ses stagiaires : rémunération attractive, jours de congé, remboursement transport supérieur au minimum légal, ateliers Qualité de Vie au Travail…\nUn tremplin pour votre carrière : Vous profiterez des meilleures conditions mises en place chez Bpifrance pour vous former, grandir, et donner une impulsion à votre carrière !\nTravailler chez Bpifrance, c’est intégrer une banque pas comme les autres, un projet d’entreprise ambitieux et tourné vers l’avenir. C’est plus qu’un métier : c’est une mission, une équipe, un réseau et un écosystème.\n\nPour découvrir nos autres opportunités et tout savoir de la vie au sein du groupe, rendez-vous sur notre site carrière : https://talents.bpifrance.fr !\n\nBpifrance est une banque citoyenne dotée d’un code de déontologie et d’une politique anti-corruption.\nAvant de postuler, nous vous invitons à consulter notre politique relative à la gestion des données à caractère personnel disponible sur notre site https://talents.bpifrance.fr/build/bpiTheme/files/politique-de-protection-des-donnees.pdf"}, {'description': 'Rejoignez une société en pleine croissance qui investit lourdement dans ses collaborateurs !\nNous recherchons un Data scientist pour un acteur majeur du secteur industriel en région Centre. Notre client est en pleine croissance depuis quelques années et investit lourdement dans l’IT avec la mise en place d’outils de reporting liés à la gestion de données produit et projet.\n\nLe poste est à pourvoir ASAP en CDI à Tours dans le cadre d’un renfort d’équipe.\n\nIntégré au sein du service system & Data, composé d’une petite quinzaine de personnes, vous avez en charge les systèmes, les outils de reporting et devenez un véritable expert des outils de données et du reporting de la division produits. Vous travaillez en étroite collaboration avec un homologue sur la partie métier pour assurer une complémentarité. Vous recevez le besoin client que vous analysez en termes d’impact, de complexité et de gain pour l’organisation. De plus, vous développez et maintenez des reports identifiés précédemment, avez à cœur de développer des outils pertinents et robustes, en utilisant une méthode agile, basé sur le besoin client. Vous livrez et formez les utilisateurs tout en gardant un œil attentif aux derniers outils du marché.\n\nIssu d’une formation en Bac +5 en Data Science, vous êtes capable de vous former aux différentes évolutions techniques pour pouvoir proposer des solutions robustes et innovantes.\n\nMaitrise de l’environnement Microsoft 365 incluant Power BI\nConnaissance en langage de développement (Java/Python etc…)\nCompétences en gestion de bases de données (SQL, ETL etc.)\n\nSi vous êtes curieux, à l’écoute, force de proposition et que vous souhaitez contribuer au bien être de vos futurs collaborateurs, ce poste est pour vous. Postulez ! #1332693'}, {'description': "La Poste Groupe change, nos métiers évoluent.\nEtre toujours au plus près des Français, développer la confiance dans le numérique et être acteur de la transformation écologique, c'est aussi le sens de notre métier.\nChaque jour, sur l'ensemble du territoire, nos 250 000 collaborateurs imaginent les services de demain.\nRejoindre La Poste Groupe, c'est rejoindre une entreprise responsable !\nVous aussi, engagez-vous à nos côtés pour donner du sens à votre métier.\n\nVous voulez faire de la finance différemment ? La Banque Postale œuvre pour l'intérêt général, chaque jour, au plus proche de ses clients en envisageant la finance autrement : plus juste, plus responsable, plus citoyenne.\nÉgalement attentive à ses collaborateurs, elle s'engage en faveur de la diversité et de l'égalité des chances pour donner accès à tous ses métiers sans discrimination.\nVenez contribuer à bâtir l'acteur bancaire de référence de demain.\n\nØ Définir, en cohérence avec le coût du risque cible défini par l’entreprise, les objectifs annuels : - du recouvrement amiable (taux de mise à jour des dossiers en recouvrement, taux de passage du recouvrement amiable vers le recouvrement judiciaire, matrice de transition des impayés…)- du recouvrement contentieux (niveau d’encaissement cible annuel, frais et honoraires des huissiers, passage en perte….)Ø Créer, suivre, automatiser les indicateurs, les reporting, les outils de supervision afin de mieux contrôler l’activité opérationnelle LBPCFØ Contribuer à la construction des Comités Risques et RecouvrementØ Mener des analyses complémentaires sur des cibles identifiéesØ Proposer les actions visant à améliorer les résultats, le contrôle, les pratiques du recouvrement amiable et judiciaireØ Assurer la surveillance de l’efficacité du process de recouvrement sur l’ensemble de la chaine de valeur, le cas échéant alerterØ Participer ou contribuer aux projets opérationnels menés avec la Direction des Risques et la Direction des OpérationsØ Réaliser les reporting nécessaires à sa hiérarchie ; proposer des évolutions dans le contenu et le format et le mode de production des reporting\n\nØ Maîtrise des outils de gestion de Donnéeso Bon niveau souhaité (SAS, SQL, Excel)o Connaissance en option (Python, Excel programmation VBA)Ø Connaissance de l’activité du crédit à la consommation : produits, services, réglementationØ Expérience (ou formation) requise dans le pilotage / analyse du risque de crédit et de ses composantes opérationnelles : au recouvrement amiable et judiciaire, risque à l’acceptationØ Préparation de la documentation des comités\n\nVous êtes diplômé d’une formation de niveau Bac+5Vous avez une expérience d'au moins 2 ans à un poste similaire"}, {'description': "YouStock a pour ambition de révolutionner la gestion de nos espaces de vie en offrant une réelle extension de chez soi accessible en ligne. Les problématiques de manque d'espace arrivent régulièrement tout au long de nos vies, aussi bien pour les particuliers que les entreprises. C'est pourtant toujours une galère, beaucoup de contraintes et de stress et souvent cher par rapport à nos besoins.\nYouStock a donc créé un SaaS, un Storage as a Service, en utilisant des technos modernes afin de proposer une solution simple, rapide et économique pour libérer son espace en quelques clics. La tech est la colonne vertébrale de YouStock et c’est grâce à celle-ci qu'elle peut rendre son modèle ultra scalable.\nLes caves humides, cambriolées, externalisées, bordéliques ou encore surfacturées, c’est du passé. Sur simple demande en ligne, YouStock collecte les objets à stocker et réalise un inventaire photo accessible sur son compte client. La livraison est rapide et s’effectue en quelques clics. Les tarifs sont justes car calculés au m3 près, ainsi le client ne paie que pour ce qu’il stocke réellement.\nCréée en 2015, YouStock devient un acteur majeur de la SmartCity en France et commence son expansion son Europe. En quelques chiffres, YouStock c’est déjà :\nPlus de 14 000 m3 en stockage\nParis, Lyon, Bordeaux, Nice, Monaco et Bruxelles! Le reste de l'Europe ensuite.\n10 millions d’€ levés par des fonds reconnus de la Proptech\n\nNB : ce poste n'est malheuresement ni pr un stage, ni une alternance. On ressent la grande motiviation chez tous mais nous cherchons un profil avec expérience. Merci :)\nTes missions, si tu les acceptes\nYouStock a pris partie d'investir sur le long terme sur la tech afin d'accroître son avantage concurrentiel. Nous recherchons un Data Analyst expérimenté et capable d’exploiter les données et de les utiliser comme outils pertinents d’aide à la décision. Tu auras l’opportunité de poser la première pierre de l’équipe Data. Tu vas collaborer avec les équipes pour leur fournir plus de visibilité sur leurs actions. Tu seras également accompagné par l'équipe technique pour la mise en place d'outils et d'automatisations, que tu sauras accompagnée aussi de part ton expérience dans une data team.\nComprendre les problématiques de chaque pôle ainsi que ceux de YouStock dans son ensemble\nAnalyser et traiter les bases de données de sorte à les transformer en informations exploitables pour les équipes\nModéliser et structurer les données à l’aide d’un outil de visualisation à implémenter\nMettre en place des dashboards automatisés et faire un suivi régulier des KPIs pour les différents pôles\nConstruire des modèles en SQL et établir des prévisions\nIdentifier les usage patterns auprès du pôle webmarketing pour anticiper les comportements des utilisateurs\nÉmettre des recommandations stratégiques et régulières aux différentes équipes\nAgir en tant que référent(e) pour toutes les questions liées aux données chez YouStock\n\nTon premier mois\nPasser avec toutes les teams pour comprendre leur besoin par rapport aux données déjà mises à disposition\nPrendre en main toutes les bases de données et les dashboards sur Metabase\nFaire la liste des sujets et prioriser en fonction de la stratégie globale\n\nTu es fait(e) pour nous rejoindre si\nTu es issu(e) d’un Bac +4 ou 5 en ingénierie / commerce / statistiques\nTu as minimum 3 ans d'expériences en Data Analysis, Statistiques\nTu maîtrises les langages SQL pour base données MySQL et PostgreSQL, Python et/ou R\nSuper esprit analytique, tu as une profonde connaissance des outils de Data Visualisation (Metabase, Tableau)\nYou understand what is written and you can have a conversation in english\nTu es positif et tu souhaites te dépasser dans des projets ambitieux\nTu es curieux, tu aimes apprendre, te former et résoudre des problèmes\nL’autonomie ne te fait pas peur. Tu es une machine d'exécution et tu sais être rigoureux\nTu as le startup team spirit : tu aimes échanger, apprendre et partager tes idées.\nLes avantages d'être avec Nous :) :\nBenefits: tickets restaus, télétravail jusqu'à 3j/sem., 1 mois de remote possible, Mutuelle Alan, Crédits de 1500€ pour un déménagement et 50€/mois de stockage, achat de Livres sur Amazon offert et d’autres encore.\nMeaning : tu participes pleinement à des projets innovants, ambitieux et stimulants\nAutonomy : tu es responsable, tu cherches et prends des décisions qui ont du sens\nTraining : tu reçois des feedbacks réguliers et tu prends part à notre partage de connaissances\nLearning : tu bénéficies de Blinkist Premium, tu montes en compétences et t’enrichis personnellement\n️ Fun (on bosse dur mais on sait s’amuser) : tu profites des team buildings et des afterworks\n️ Cadre de vie : tu travailles dans un environnement inspirant et ensoleillé\nDiversity : tu fais partie d'une équipe bienveillante qui accorde une grande importance à l’égalité\nDéroulement du recrutement :\nPour postuler, décris toi en 2 phrases, explique nous ce qui a retenu ton attention dans cette annonce, ce qui t’attire et ce que tu as envie de nous apporter. Si t’es chaud, envoie une vidéo pour répondre; nous on adore!\nPar la suite, on s’emploie à ce que tu rencontres plusieurs personnes de la Team :\nEntretien visio de 30 min\nEntretien physique avec Responsable + test technique\nCafé ou verre avec 2 personnes avec qui tu travaillerais\nEntretien avec un fondateur et/ou COO"}, {'description': "ALM Treasury Analyste Quantitatif / Data Scientist F/H\n#ALMT #DSQF\n\nCONCRÈTEMENT VOTRE QUOTIDIEN ?\nL’ALM Treasury (Asset & Liabilities Management Treasury), activité transversale présente dans l’ensemble du Groupe BNP Paribas, est en charge de gérer des risques de marché engendrés par l’activité commerciale de la banque, spécifiquement les risques de liquidité, de taux et de change.\nL’ALM Treasury comprend une équipe importante au siège à Paris ainsi que des équipes locales présentes dans les succursales et filiales du Groupe en France et à l’étranger.\nVotre mission principale sera de développer des modèles statistiques pour prédire le comportement clientèle (exercice de l’option de remboursements anticipés, écoulement des dépôts, tirage du hors-bilan, …). Ces modèles sont nécessaires pour permettre à l’ALM Treasury d’avoir une juste représentation des risques sous sa responsabilité et sont la base des décisions de couverture (opérations de marchés) mises en place.\nLe développement des modèles pour répondre à de nouveaux besoins ou la mise à jour des modèles existants feront partie de votre quotidien. Vous utiliserez dans ce cadre diverses méthodes de Data Science, d’économétrie ou de finance quantitative. Bien sûr, vous suivrez et tiendrez compte de l’évolution de l’environnement économique et financier.\nVous pourrez contribuer à l’amélioration des outils de simulation de scénarios économiques (trajectoires de taux d’intérêt, inflation, …) développés dans l’équipe, ainsi qu’à la calibration des modèles sous-jacents, reposant sur des algorithmes d’optimisation sophistiqués.\nVous jouerez un rôle actif dans la veille technologique de l’équipe, notamment pour les projets sur les environnements Big Data du groupe BNP Paribas, les tests d'algorithmes de Machine Learning / Intelligence Artificielle. Vous serez également actif dans la veille académique, en particulier via l’étude d’articles académiques.\nLa collaboration et les interactions avec d’autres équipes de l’ALM Treasury seront importantes. Vous serez amené à travailler avec ces équipes pour connaitre le contexte du modèle (spécificités des clients, cadre économique et concurrentiel, …) et échanger sur vos travaux. Vous serez également amené à interagir avec les équipes RISK (en charge de la validation des modèles) et IT (en particulier dans le cadre de la collecte de données historiques).\nEnfin, vous participerez à l’animation du réseau des modélisateurs ALM Treasury du Groupe BNP Paribas ; via des meetings réguliers avec les équipes locales, des présentations des nouvelles méthodologies standard du Groupe. Vous veillerez à l’harmonisation des méthodes de modélisation dans le Groupe et interviendrez en support aux équipes locales dans le développement de modèles.\nL'ENVIRONNEMENT DE TRAVAIL, C'EST IMPORTANT !\nVous rejoindrez l’équipe Data Science & Quantitative Finance (DS&QF) au sein de l’ALM Treasury, composée de 10 Data Scientists installés au sein du Head Office de l’ALM Treasury, dans le quartier Paris Opéra (2e arrondissement).\nET APRÈS?\nCette mission vous permettra de développer vos compétences techniques ainsi que vos connaissances de l'activité de l'ALM Treasury. Les interactions constantes avec les différentes équipes de l'ALM Treasury vous permettront de découvrir la richesse des missions de cette activité transverse, tant au sein de Head Office que dans les métiers / filiales. Vous pourrez ensuite évoluer vers d’autres services au sein de l'ALMT tant en France au siège, dans les filiales du Groupe, qu'à l'étranger.\nAprès une première expérience, vous aurez la possibilité d’évoluer au sein de l’ALM Treasury, tant en France qu’à l’étranger, dans des activités aussi variées que les activités de marchés, de refinancement, d’analyses et de production d’indicateurs ou de pilotage de risques.\nET LA RÉMUNÉRATION ?\nC'est un sujet important, qui sera bien sûr abordé. Nous saurons valoriser votre expérience et votre parcours.\nPOURQUOI REJOINDRE BNP PARIBAS ?\nNotre monde change : notre manière de nous informer, de consommer… et de travailler aussi ! Aujourd’hui, ce qui compte dans un job, c’est de vivre de véritables expériences, d’apprendre, de partager objectifs et résultats avec ses collègues. Bref, de tracer son propre chemin, différent, responsable et durable. Chez BNP Paribas, nous recrutons nos collaborateurs avec l’idée qu’ils nous aideront à concevoir le monde et la banque de demain.\nVous voulez connaître toutes les raisons de nous rejoindre ? Rendez-vous sur : https://group.bnpparibas/emploi-carriere/bnp-paribas\n\n\nETES-VOUS NOTRE ALM TREASURY ANALYSTE QUANTITATIF - DATA SCIENTIST F/H ?\nOui si vous êtes diplômé d’un Master, ingénieur, école de commerce, université, et justifiez d’une première expérience réussie en mathématiques financières ou en statistique. Vous êtes expert dans la manipulation de données potentiellement volumineuses et le développement en Python ? La modélisation mathématique est plus qu’un hobby pour vous ? Votre connaissance des problématiques ALM Treasury serait un plus.\nBon communicant, vous êtes rigoureux avec d’excellentes capacités d’analyse ? Vous savez vous adapter rapidement à de nouveaux environnements complexes tout en restant proactif. Vous êtes à l’aise pour communiquer en anglais tant à l’oral qu’à l’écrit.\nN’hésitez plus et rejoignez-nous !\nEnfin nous attachons une importance particulière à ce que nos futurs collaborateurs agissent au quotidien avec responsabilité éthique et professionnelle.\nDans un monde qui change, la diversité, l’équité et l’inclusion sont des valeurs clés pour le bien-être et la performance des équipes. Chez BNP Paribas, nous souhaitons accueillir et retenir tous les talents sans distinction : c’est ainsi que nous construirons, ensemble, la finance de demain, innovante, responsable et durable.\nA tout moment pendant le processus de recrutement, les informations figurant sur votre CV et vos données d’identification pourront être vérifiées par un prestataire extérieur mandaté par BNP Paribas.\n\nLIEU PRINCIPAL\nFR-Île-de-France-PARIS\nTYPE D'EMPLOI\nCDI\nDOMAINE D'ACTIVITÉ\nEXPERTISE FINANCIERE ET TECHNIQUE\nNIVEAU D'ÉTUDES\nMaster ou équivalent (> 4 ans)\nNIVEAU D'EXPÉRIENCE\nAu moins 1 an\nHORAIRES\nTemps plein\nRÉFÉRENCE\n!I_ALMT_0066\nAPPLY\n(REF: !I_ALMT_0066)"}, {'description': "Lieu : Paris\nDurée : 6 mois minimum ( mission longue)\nPrestation : Temps Plein\nDémarrage : ASAP\nHybride : modulable\n\nGestion des projets autour des problématiques Data / BI\nGestion des incidents pour la partie data / BI\nExpérience dans la résolution de problème lié à la data (recherche dans les bases de données, investigation dans l’intégration etc ..)\nExpérience dans la construction de rapport BI (le profile ne sera pas la force ouvrière principale, mais doit savoir ajuster / corriger des rapports de temps en temps)\n\nLe client recherche un profil :\nRigoureux et motivé\n5 à 10 ans d’expérience dans le domaine\n\nCe profil est le vôtre, vous êtes disponible ou intéressé(e) pour cette mission en freelance, alors envoyez moi votre cv à jour ainsi que votre TJ actualisé, à l'adresse mail suivante :\nnamf@emagine.org"}, {'description': 'Entreprise : Airbus Operations SAS\nLocalisation : Toulouse - France - Occitanie\nFonction : Data Scientist for Flight and Integration Test center (m/f)\nType de contrat : Contrat à durée indéterminée (CDI)\nDate de publication : 20-01-2023\nDescription du poste\nDescription de l\'emploi :\nWHO WE ARE\nWithin the Engineering Flight and Integration Tests center, we are a team of Data Scientists in charge of driving data analytics study, helping specialists extracting insight from data and building AI based solutions to automate tasks for the stakeholders in relation with development and production activities (lab and flight tests).\nWe work in a very close collaboration with our test means teams and IT colleagues.\nWe are one team passionate about AI and data science, inspired by the A/C products and related challenges, invested by new technologies and methods. Headed toward the future, we are ready to address our tomorrow thru our assets:\nOur team of dedicated individuals engaged on collective targets\nOur deep skills around AI & data analytics associated IT required competencies\nOur ability to deliver added value services around data\nWHERE WE ARE GOING\nAs a team, and key actors of the company digitalization journey, we have started a global transformation to be in line with the demanding and changing Airbus context. A vision and a strategy is currently under definition with key partners and the teams in order to bring more analytics and AI in our testing strategy.\nBeing more agile, working in a collaborative mind-set with autonomous and self-organized operational teams are our main drivers.\nFor our stakeholder\'s testing business, we are building data analytics and AI capacities that can support them in facing the coming challenges and ease their daily work.\n\nBUILDING & RE-INFORCING OUR DATA ANALYTICS CAPACITIES\nMore concretely we want to:\nBuild & structure center of competencies around AI and data analytics for the Flight and Integration Tests center\nStrengthen the operations around AI and data analytics activities\nReinforce the collaboration with our main stakeholders\nContribute to evolve our software products to includes more AI for the sake of simplicity and efficiency\nDevelop a continuous improvement mindset and approach\nAnd more to be invented...\nWE ARE LOOKING FOR?\nAn experienced data scientist to reinforce the team and help in building and structuring an activity around AI and data science\nYOU ARE READY FOR?\nNew challenges in a demanding context where you can bring\nYour strong involvement in business understanding\nYour "Doer" profile to sustain and improve our business\nYour proven records as experienced data scientist\nYour strong values and energy\nYour will to learn and influence positively in a demanding operational context\nMORE AROUND YOUR PROFILE?\nGood communication (written and oral) and interpersonal skills with good team spirit\nUser oriented mindset to understand the end-users needs and help structuring the activity\n\nDoer, vibrating for complex and "end to end" technical problems to solve\nStrong background in AI or Data Analytics\nPython / PySpark programming languages are mandatory,\nIT knowledge & programming skills might be desirable.\n\nBe aware of data governance and compliance rules in order to handle security and export control issues\nFrench & English: advanced level\nCet emploi exige une connaissance des risques de conformité potentiels et un engagement à agir avec intégrité, comme base de la réussite, de la réputation et de la croissance durable de la société.\nProfil recherché\nDate de début : nc.\nDurée : nc.\nExpérience requise : Plus de 10 ans d\'expérience\nSalaire : nc.\nRéférence : JR10162010\nSecteur d\'activité : Industrialisation, Production'}, {'description': 'Entreprise : AIRBUS SAS\nLocalisation : Toulouse - France - Occitanie\nFonction : HR Data Scientist - People Analytics\nType de contrat : Contrat à durée indéterminée (CDI)\nDate de publication : 20-01-2023\nDescription du poste\nDescription de l\'emploi :\nJoin the Airbus Human Resources (HR) community as a Data Scientist and contribute to our digital transformation!\n\nDo you want to play a proactive role within the People Analytics team to strengthen our data science capabilities?\n\nDo you have a strong background in applied statistics and data analysis in order to help us build predictive scenarios for key projects?\n\nAre you motivated to dive into the various Airbus Data and create use cases together with our HR professionals?\n\nInterested in interacting as a stakeholder within a multi-functional team to coordinate between HR business, IT counterparts and in connection with the data science community to strengthen People Analytics with the state of the art technology.\n\n==> If ?Yes? is the answer to the above questions, apply for this job and make your case!\n\nShow us your appetite for innovation, we are looking for inspiring candidates to inspire others!\nYou will take an active stake in spreading data science awareness within the HR community\nJointly with the HR experts, you will identify uses cases where Predictive, Simulations, Correlation analysis or Classification approaches will bring benefits to the function\nAs an expert, you are responsible to steer the data science analysis and to share it in a comprehensive manner to our business counterparts\nIn coordination with the IT and the other data scientists, you will support the stabilization of the processes and tools of the department. For example, by running proofs of concept or contributing to the implementation of our tools\nThis job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company\'s success, reputation and sustainable growth.\n\n-> Technical skills:\nEssential:\nPython Software Development, including modules for data engineering/machine learning such as Pandas, Scikit-Learn, Tensorflow and PyTorch\nDevOps tools including Git\nVisualization tools including Spotfire and QlikSense\nDesirable:\nExperience with HR Reporting Systems (Workday, PRISM, SAP BI)\n\n-> Soft skills:\nEssential:\nAbility to adapt in a rapidly changing environment,\nStructured, self-organized and collaborative way of working,\nStrong communication towards diverse audiences (incl. senior management) and strong networking skills,\nHands-on, pragmatic approach to building digital products (hacker / entrepreneurial mindset),\nCreativity and appetence for problem solving,\nInnovation leadership: deploy appropriate innovation methods, techniques and tools to support an innovation opportunity lifecycle phase\nCustomer orientation to provide user-centric solution\nDesirable:\nKnowledge of HR basics would be a plus\nRejoignez la communauté des ressources humaines (RH) d\'Airbus en tant que Data Scientist et contribuez à notre transformation numérique !\n\nVous souhaitez jouer un rôle proactif au sein de l\'équipe People Analytics afin de renforcer nos capacités en matière de science des données ?\n\nVous avez une solide expérience en statistiques appliquées et en analyse de données afin de nous aider à construire des scénarios prédictifs pour des projets clés ?\n\nÊtes-vous motivé pour plonger dans les différentes données d\'Airbus et créer des cas d\'utilisation avec nos professionnels des RH ?\n\nIntéressé par l\'interaction en tant que partie prenante au sein d\'une équipe multifonctionnelle pour coordonner entre les affaires RH, les homologues IT et en connexion avec la communauté de la science des données pour renforcer l\'analyse des personnes avec l\'état de l\'art de la technologie.\n\n==> Si vous avez répondu "oui" aux questions ci-dessus, postulez à cet emploi et faites valoir votre point de vue !\n\nMontrez-nous votre appétit pour l\'innovation, nous recherchons des candidats inspirants pour inspirer les autres !\nVous participerez activement à la sensibilisation à la science des données au sein de la communauté RH.\nEn collaboration avec les experts RH, vous identifierez les cas d\'utilisation où les approches prédictives, de simulation, d\'analyse de corrélation ou de classification apporteront des avantages à la fonction.\nEn tant qu\'expert, vous êtes chargé de diriger l\'analyse de la science des données et de la partager de manière exhaustive avec nos homologues commerciaux.\nEn coordination avec l\'IT et les autres data scientists, vous soutiendrez la stabilisation des processus et des outils du département. Par exemple, en réalisant des preuves de concept ou en contribuant à la mise en ?uvre de nos outils.\nCe poste requiert une conscience de tout risque potentiel de conformité et un engagement à agir avec intégrité, comme fondement du succès, de la réputation et de la croissance durable de la société.\n\n-> Compétences techniques :\nEssentielles :\nDéveloppement de logiciels Python, y compris les modules pour l\'ingénierie des données/apprentissage automatique tels que Pandas, Scikit-Learn, Tensorflow et PyTorch.\nOutils DevOps, notamment Git\nOutils de visualisation, notamment Spotfire et QlikSense.\nSouhaitable :\nExpérience des systèmes de reporting RH (Workday, PRISM, SAP BI).\n\n-> Compétences générales :\nEssentiel :\nCapacité d\'adaptation dans un environnement en évolution rapide,\nMéthode de travail structurée, auto-organisée et collaborative,\nForte communication avec des publics variés (y compris les cadres supérieurs) et fortes compétences en matière de réseautage,\nApproche pratique et pragmatique de la création de produits numériques (esprit hacker / entrepreneurial),\nCréativité et appétence pour la résolution de problèmes,\nLeadership en matière d\'innovation : déploiement de méthodes, de techniques et d\'outils d\'innovation appropriés pour soutenir une phase du cycle de vie des opportunités d\'innovation.\nOrientation client pour fournir une solution centrée sur l\'utilisateur\nSouhaitable :\nUne connaissance des bases des RH serait un plus\nCet emploi exige une connaissance des risques de conformité potentiels et un engagement à agir avec intégrité, comme base de la réussite, de la réputation et de la croissance durable de la société.\nProfil recherché\nDate de début : nc.\nDurée : nc.\nExpérience requise : Plus de 10 ans d\'expérience\nSalaire : nc.\nRéférence : JR10150393\nSecteur d\'activité : Industrialisation, Production'}, {'description': "Mherit, cabinet de recrutement engagé pour l’inclusion, le bien-être des talents expérimentés et la collaboration intergénérationnelle, recherche un.e Data Analyst F/H pour un de ses clients, acteur de la big data. Notre client est une entreprise à taille humaine (250 personnes en France), internationale qui travaille avec la majorité des acteurs de la grande consommation.\nLes missions\nEn tant qu'expert Python, au sein du pôle Analytics et de votre future équipe (une dizaine de personnes), vous aurez pour responsabilités :\n-Echanger régulièrement avec les équipes françaises et européennes pour bien comprendre les enjeux et problématiques de clients de la grande consommation ;\n-Mettre en place des automatisations de process statistiques actuels ;\n-Extraire et analyser les résultats des compagnes de marketing direct ;\n-Réaliser des projets d'études statistiques ;\nProfil recherché\nIl faut qu'on échange si vous disposez d'une formation supérieure en statistiques et que le domaine des études marketing vous intéresse.\nNiveau d'anglais courant nécessaire pour pouvoir travailler avec l'ensemble des équipes européennes.\nUne parfaite maitrise du SQL et une parfaite connaissance de Python seront nécessaires pour mener vos missions à bien.\nUne bonne connaissance des outils et d'un environnement cloud et git (Azure, Snowflake, Databricks), tout comme la connaissance de Power BI est un plus.\nL'anglais est un plus pour évoluer au sein de l'entreprise.\nQuelques mots sur l'équipe : accueillante, joyeuse, elle saura vous mettre à l'aise pour vos débuts.\nDétails pratiques\nType d'emploi : Temps plein, CDI\nLieu de travail : Boulogne-Billancourt\nTélétravail : plusieurs jours par semaine\nSalaire : 42 000,00€ par an - selon profil\nAvantages :\nParticipation au Transport\nSuper mutuelle\nTitre-restaurant\nType d'emploi : Temps plein, CDI\nStatut : Cadre\nSalaire : 40 000,00€ à 43 000,00€ par an\nAvantages :\nParticipation au Transport\nRTT\nTitre-restaurant\nTravail à domicile\nProgrammation :\nDu Lundi au Vendredi\nRepos le week-end\nTravail en journée\nTypes de primes et de gratifications :\nPrimes\nFormation:\nBac +5 (Master / MBA) (Optionnel)\nLieu du poste : Télétravail hybride (92100 Boulogne-Billancourt)"}])
[2023-01-23T14:31:15.678+0000] {xcom.py:635} ERROR - Object of type DataExtractor is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-01-23T14:31:15.682+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2297, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataExtractor is not JSON serializable
[2023-01-23T14:31:15.699+0000] {taskinstance.py:1323} INFO - Marking task as UP_FOR_RETRY. dag_id=data_extraction_and_loading_3, task_id=extract_data, execution_date=20220125T000000, start_date=20230123T143024, end_date=20230123T143115
[2023-01-23T14:31:15.718+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 70 for task extract_data (Object of type DataExtractor is not JSON serializable; 1507)
[2023-01-23T14:31:15.757+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2023-01-23T14:31:15.845+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
