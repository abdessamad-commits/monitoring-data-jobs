[2023-01-23T14:36:16.548+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: data_extraction_and_loading_3.extract_data scheduled__2022-01-25T00:00:00+00:00 [queued]>
[2023-01-23T14:36:16.560+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: data_extraction_and_loading_3.extract_data scheduled__2022-01-25T00:00:00+00:00 [queued]>
[2023-01-23T14:36:16.561+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-01-23T14:36:16.562+0000] {taskinstance.py:1280} INFO - Starting attempt 2 of 2
[2023-01-23T14:36:16.563+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-01-23T14:36:16.624+0000] {taskinstance.py:1300} INFO - Executing <Task(PythonOperator): extract_data> on 2022-01-25 00:00:00+00:00
[2023-01-23T14:36:16.630+0000] {standard_task_runner.py:55} INFO - Started process 1705 to run task
[2023-01-23T14:36:16.634+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'data_extraction_and_loading_3', 'extract_data', 'scheduled__2022-01-25T00:00:00+00:00', '--job-id', '84', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpkyvfoc_n']
[2023-01-23T14:36:16.640+0000] {standard_task_runner.py:83} INFO - Job 84: Subtask extract_data
[2023-01-23T14:36:16.655+0000] {logging_mixin.py:137} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:249 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-01-23T14:36:16.687+0000] {logging_mixin.py:137} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-01-23T14:36:16.732+0000] {task_command.py:388} INFO - Running <TaskInstance: data_extraction_and_loading_3.extract_data scheduled__2022-01-25T00:00:00+00:00 [running]> on host 1b696c32fad4
[2023-01-23T14:36:16.796+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=abdessamad
AIRFLOW_CTX_DAG_ID=data_extraction_and_loading_3
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2022-01-25T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-25T00:00:00+00:00
[2023-01-23T14:36:51.096+0000] {logging_mixin.py:137} INFO - Error
[2023-01-23T14:36:51.197+0000] {logging_mixin.py:137} INFO - Error
[2023-01-23T14:36:51.261+0000] {logging_mixin.py:137} INFO - Error
[2023-01-23T14:36:51.389+0000] {logging_mixin.py:137} INFO - Error
[2023-01-23T14:36:51.497+0000] {logging_mixin.py:137} INFO - Error
[2023-01-23T14:36:51.502+0000] {python.py:177} INFO - Done. Returned value was: (<helpers.DataExtractor object at 0xffff83400390>, [{'description': "Description de l'entreprise\n\nAccélérez votre carrière au sein d’un groupe d’ingénierie mondial à forte croissance. Chez SEGULA Technologies, vous travaillerez sur des projets passionnants et contribuerez à façonner l’avenir au sein d’une entreprise pour qui l’innovation est indissociable de l’ingénierie.\nImpression 3D, réalité augmentée, véhicule autonome, usine du futur… rythment le quotidien de nos 13 000 ingénieux collaborateurs, pourquoi pas le vôtre ?\nÀ côté de chez vous ou à l’autre bout de la planète, vous trouverez chez SEGULA Technologies l’opportunité qui donnera un sens nouveau à votre carrière !\n\nDescription du poste\n\nDans le cadre de nos activités aéronautiques sur Marignane (13), nous recherchons un Data Analyst Junior H/F.\nLe/la Data Analyst Junior sera rattaché au service Service Maintenance Repair & Overhaull (MRO) des ensembles mécaniques d'H/C.\n\nVos missions:\nEffectuer la maintenance d'un outil excel connecté à un système access déjà existant avec plus de 150 utilisateurs par jour.\nEffectuer les dépannages logiciels sur les dysfonctionnements remontés par les opérationnels\nAnalyser les données pour extraire des pilotages d'activité\nL’analyse des données recueillies et leur tri en fonction de leur pertinence pour la problématique de l’entreprise\nl’amélioration constante du système de récupération des données client afin d’optimiser et d’agrandir le stock de données possédé par l’entreprise\n\nQualifications\n\nVous disposez d'au moins 1/2 ans d'expérience en alternance ou vous sortez récemment de formation.\nVous avez des connaissance en gestion de production industrielle.\nLe langage des données SQL + VBA n'a pas de secret pour vous\nLa maitrise des outils comme : suite office, excel est indispensable.\nLa connaissance des outils SAP et Access est un plus.\nAlors n'hésitez plus ! Faites nous parvenir votre CV !\n\nInformations supplémentaires\n\nContrat: CDI\nLieu: Marignane (13)\nOuverture du poste: Dés que possible\nHoraire: 35h journée\nRémunération: selon profil + avantages"}, {'description': "Description de l'entreprise\n\nAccélérez votre carrière au sein d’un groupe d’ingénierie mondial à forte croissance. Chez SEGULA Technologies, vous travaillerez sur des projets passionnants et contribuerez à façonner l’avenir au sein d’une entreprise pour qui l’innovation est indissociable de l’ingénierie.\nImpression 3D, réalité augmentée, véhicule autonome, usine du futur… rythment le quotidien de nos 13 000 ingénieux collaborateurs, pourquoi pas le vôtre ?\nÀ côté de chez vous ou à l’autre bout de la planète, vous trouverez chez SEGULA Technologies l’opportunité qui donnera un sens nouveau à votre carrière !\n\nDescription du poste\n\nDans le cadre de nos activités aéronautiques sur Marignane (13), nous recherchons un Data Analyst Junior H/F.\nLe/la Data Analyst Junior sera rattaché au service Service Maintenance Repair & Overhaull (MRO) des ensembles mécaniques d'H/C.\n\nVos missions:\nEffectuer la maintenance d'un outil excel connecté à un système access déjà existant avec plus de 150 utilisateurs par jour.\nEffectuer les dépannages logiciels sur les dysfonctionnements remontés par les opérationnels\nAnalyser les données pour extraire des pilotages d'activité\nL’analyse des données recueillies et leur tri en fonction de leur pertinence pour la problématique de l’entreprise\nl’amélioration constante du système de récupération des données client afin d’optimiser et d’agrandir le stock de données possédé par l’entreprise\n\nQualifications\n\nVous disposez d'au moins 1/2 ans d'expérience en alternance ou vous sortez récemment de formation.\nVous avez des connaissance en gestion de production industrielle.\nLe langage des données SQL + VBA n'a pas de secret pour vous\nLa maitrise des outils comme : suite office, excel est indispensable.\nLa connaissance des outils SAP et Access est un plus.\nAlors n'hésitez plus ! Faites nous parvenir votre CV !\n\nInformations supplémentaires\n\nContrat: CDI\nLieu: Marignane (13)\nOuverture du poste: Dés que possible\nHoraire: 35h journée\nRémunération: selon profil + avantages"}, {'description': "Référence de l’offre\n23000086\nType de contrat\nCDI\nNiveau d'expérience\nExpérimentés\nSociété du groupeAXA Investment Managers\nFamille métier\nIT, Data & Transformation\nLocalisation\nPUTEAUX, Hauts-de-Seine\n\nVotre rôle et vos missions\nLe titulaire intègre l’équipe Portfolios & Third Party Data, située au sein du département Data & Analytics Management, le centre d’expertise interne relativement à l’administration, à la qualité et à la gouvernance des données et des analytics.\nL’équipe Portfolios & Third Party Data administre plusieurs référentiels de données centraux d’AXA IM, notamment ceux relatifs aux définitions des portefeuilles et aux entités tiers. Par ailleurs, l’équipe supervise la gestion par des partenaires externes de certains référentiels de données externalisés, en particulier ceux ayant trait aux NAV des produits ainsi qu’aux transactions et détentions côté clients.\nAu-delà de sa contribution aux activités de l’équipe d’administration et de modélisation des données, le titulaire sera amené à participer à la transformation en cours de nos référentiels de données, et aidera à ce titre l’équipe à utiliser au mieux les nouvelles capacités data dont s’est dotée AXA IM, notamment en matière d’ingestion, de transformation, et de distribution des données (Data Platform), et en matière d’analyse et d’exploration de données (Data Science Studio).\nKey Accountabilities\nAdministration des référentiels de données\nRépondre aux demandes de support émanant des utilisateurs des données au sein d’AXA IM\nAviser quant aux éléments et modèles de données appropriés pour répondre aux besoins des initiatives métier et règlementaires\nContribuer à l’amélioration générale de la qualité des données et des analytics au sein des référentiels, en mettant en place des process d’acquisition de données adéquats et des contrôles sur ces données\nTransformation des référentiels de données\nElaborer la stratégie permettant aux équipes du périmètre Data & Analytics Management de supporter efficacement les données de référence présentes dans la Data Platform, au-delà des référentiels de données existants\nUtiliser au mieux le Data Science Studio et ses capacités d’analyse et d’exploration massives de données, afin de construire des tableaux de bord de suivi de la qualité des données, et d’explorer de nouveaux jeux de données actuellement non couverts dans les référentiels\nVotre profil\nConnaissances générales en finance, et plus spécifiquement relatives aux concepts de gestion d’actifs : portefeuilles, instruments financiers, …\nAttrait marqué pour la modélisation et la gouvernance des données et des analytics\nCapacité à coder en Python pour l’automatisation et l’analyse et la visualisation de données\nFamiliarité avec les outils de gestion et d’administration de données\nTrès bonnes capacités de communication et d’interaction\nCapacité à interagir avec des profils divers, tels que : gestionnaires des données, fournisseurs de données, développeurs, responsables middle office, analystes de performance, gérants de portefeuilles, …\nCapacité à organiser les priorités et à gérer de multiples sujets de front\nAttention portée aux détails\nFrançais et Anglais courants (lu, écrit et parlé) indispensable\nVotre environnement de travail\nAimeriez-vous vous lever chaque jour motivé(e) par une mission inspirante et travailler en équipe pour permettre de protéger les personnes et leurs proches? Chez AXA nous avons l’ambition de mener la transformation de notre métier. Nous cherchons des personnes talentueuses ayant une expérience diversifiée, qui pensent différemment, et qui veulent faire partie de cette transformation passionnante en challengeant le statu quo et faire d’AXA – marque globale leader et une des sociétés les plus innovantes dans notre secteur – une entreprise encore plus performante et responsable. Dans un monde en perpétuelle évolution et avec une présence dans 64 pays, nos 166 000 salariés et distributeurs privilégiés anticipent le changement pour offrir des services et solutions adaptés aux besoins actuels et futurs de nos 103 millions de clients.\n\nAXA Investment Managers (AXA IM) est un gestionnaire d’actifs responsable qui investit activement sur le long terme pour la prospérité de ses clients, de ses collaborateurs et de la planète. Avec environ 866 milliards d’euros d’actifs sous gestion à fin juin 2021, notre gestion de conviction nous permet d’identifier les opportunités d’investissement que nous considérons comme les meilleures du marché à l’échelle mondiale dans les différentes classes d’actifs alternatives et traditionnelles. AXA IM est un leader sur le marché de l’investissement vert, social et durable, avec 568 milliards d’euros d’actifs intégrant des critères ESG, durables ou à impact, à fin juin 2021. Nous nous sommes engagés à atteindre l’objectif de zéro émission nette de gaz à effet de serre d’ici 2050 pour l’ensemble de nos actifs, et à intégrer les considérations ESG dans nos activités, de la sélection des titres à notre culture d’entreprise en passant par la façon dont nous gérons nos opérations au quotidien. Nous souhaitons apporter de la valeur à nos clients grâce à des solutions d’investissement responsables, tout en suscitant des changements significatifs pour la société et l’environnement. A fin juin 2021, AXA IM emploie plus de 2 488 collaborateurs dans le monde, répartis dans 26 bureaux et 20 pays. AXA IM fait partie du Groupe AXA, un leader mondial de l’assurance et de la gestion d’actifs.\nPourquoi nous rejoindre ?\nNous sommes fiers de promouvoir une culture de la performance ce qui veut dire que nous cherchons à recruter des personnes qui sont non seulement compétentes techniquement mais également ouvertes à l'international, innovants et capables de mettre à contribution leurs perspectives et expériences uniques afin d'accompagner nos succès en tant qu'entreprise. Employer les meilleurs professionnels parmi le plus large vivier de talents possible est au cœur de notre stratégie qui consiste à délivrer une excellente qualité de service à notre clientèle diversifiée. AXA IM s’engage à développer une culture inclusive, mettant en valeur la diversité et soutenant la progression de carrière de l’ensemble de ses collaborateurs et collaboratrices."}, {'description': "Entreprise : Airbus Helicopters SAS\nLocalisation : Marseille - France - Provence-Alpes-Côte d’Azur\nFonction : Data Scientist F/M\nType de contrat : Contrat à durée indéterminée (CDI)\nDate de publication : 20-01-2023\nDescription du poste\nDescription de l'emploi :\nAirbus Helicopters is looking for a Data Scientist (f/m) to join our Marketing department based in Marignane, France.\nYou will be part of a team of 6 people developing market & real flight analysis. As part of the Marketing Data Science team, you will be involved in developing new models & methodologies to understand, anticipate and drive the helicopter market.\nYour working environment:\nMajor economic hub with Marseille-Provence Airport, Marignane is located near the cities of Aix-en-Provence and Marseille, which host a rich cultural and tourist offer. Close to the beaches of the Côte Bleue, it offers many options for water sports activities and sunny weather all year long.\nHow we care for you:\nFinancial rewards: Attractive salary, agreements on success and profit sharing schemes, employee savings plan abounded by Airbus and employee stock purchase plan on a voluntary basis.\nWork / Life Balance: Extra days-off for special occasions, holiday transfer option, a Staff council offering many social, cultural and sport activities and other services.\nWellbeing / Health: Complementary health insurance coverage (disability, invalidity, death). Depending on the site: health services center, concierge services, gym, carpooling application.\nIndividual development: Great upskilling opportunities and development prospects with unlimited access to +10.000 e-learning courses to develop your employability, certifications, expert career path, accelerated development programmes, national and international mobility.\nAt Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.\n\nYour challenges:\nYour main mission will be to develop new models and methodologies for helicopter market forecasts and analysis. This includes the development of new econometric or optimization models and apply statistical methodologies to support the strategic decision making process of Airbus Helicopters.\nYou will have the possibility to work on geospatial data, linked to real flights of our aircraft.\nYou will work on large datasets. You must have a proven ability to drive business insights with data-based insights.\nYou must be comfortable working with a wide range of stakeholders and functional teams.\nIn this position, you will also contribute to marketing digital transformation on data projects that are transversal to the whole company.\nYou will work on internal and external data sets (Helicopter fleet datasets, helicopter operations (flights), macroeconomic datasets, environment datasets?).\nYou will be working closely with the following departments:\nMarket analysts;\nInformation management and digital transformation;\nStrategy;\nSales?\nYour profile:\n1-2 years on a similar position\nMaster's degree in data science, Statistics, Econometrics, applied Mathematics\nStatistical methods\nMathematical optimization\nEconometrics (Panel data models, regression, time series ?)\nProgramming (Python, R, PySpark?)\nAble to communicate and explain complex processes in a simple way\nTeam spirit\nInnovator\nEnglish: Negotiation\nFrench: Negotiation\nWhat would be seen has an advantage:\nKnowledge about the aerospace domain\nData visualization\nThis position requires a security clearance or will require being eligible for clearance by the recognized authorities.\nNot a 100% match? No worries! Airbus supports your personal growth with customized development solutions.\nTake your career to a new level and apply online now!\nCet emploi exige une connaissance des risques de conformité potentiels et un engagement à agir avec intégrité, comme base de la réussite, de la réputation et de la croissance durable de la société.\nProfil recherché\nDate de début : nc.\nDurée : nc.\nExpérience requise : Débutant / Jeune diplomé\nSalaire : nc.\nRéférence : JR10154608\nSecteur d'activité : Industrialisation, Production"}, {'description': "Entreprise : Airbus Protect SAS\nLocalisation : Toulouse - France - Occitanie\nFonction : Data Scientist / Engineer Skywise\nType de contrat : Contrat à durée indéterminée (CDI)\nDate de publication : 20-01-2023\nDescription du poste\nDescription de l'emploi :\nAirbus PROTECT rassemble des experts dans les métiers de la safety, de la cybersecurity et de la sustainability. Nous mettons notre expertise au service de notre propre groupe, Airbus, auprès de qui nous agissons en tant que partenaire privilégié, mais également au service de clients externes.\nAvec plus de 1.200 collaborateurs expérimentés basés notamment en France, en Angleterre et en Allemagne, nous gérons des contrats de grande envergure avec des entreprises telles que des infrastructures critiques (OIVs), d'autres groupes industriels ou encore des institutions publiques. Notre positionnement et notre stratégie nous permettent de répondre aux normes les plus élevées du marché et de relever les défis de demain en équipe? avec vous !\nVotre futur job, si vous l'acceptez?\nDéploiement et automatisation de pipelines de données\nIndustrialisation d'algorithmes de Machine Learning\nDéveloppement de produits Skywise / Palantir / AWS (Front/Back)\nDévelopper de nouveaux systèmes de bases de données (logique NoSQL)\nConception et développement de nouveaux uses cases\nParticipation aux cérémonies Agile\nGestion de base de données NoSQL orienté Graph (Neo4J, Neptune, ArangoDB)\nIndustrialisation des algorithmes de Machine Learning provenant d'équipe de Data Scientist\nSurveillance, déploiement et intervention sur les produits Skywise développés\nAccompagnement de l'équipe dans le déploiement de produits IA pour Airbus Protect et le groupe\nEtes-vous notre futur talent ?\nVous êtes Ingénieur IA, de formation grandes écoles ou universités.\nVous possédez a minima 3 ans d'expérience en data science et/ou data engineering.\nVous avez de solides connaissances sur les technologies Skywise et Palantir et en gestion de flux de données (lineage, ontology)\nUne connaissance des architectures web, basés sur les évènements et micro-services (+API) serait un plus.\nVous connaissez et savez diffuser les bonnes pratiques de développement Skywise et Agile\nVous avez de bonnes aptitudes en communication et la capacité à présenter des sujets techniques complexes aux principaux acteurs de l'entreprise de manière convaincante.\nVous êtes rigoureux avec le sens du détail et une passion pour les solutions et les technologies qui résolvent les problèmes.\nVous savez faire preuve d'autonomie avec des capacités d'écoute active et de prise d'initiatives pragmatiques\nEnglish intermediate needed\nVous recherchez un poste avec une activité variée et de réelles opportunités d'évolution?\nVenez vivre l'aventure Airbus Protect? On vous attend !\nCet emploi exige une connaissance des risques de conformité potentiels et un engagement à agir avec intégrité, comme base de la réussite, de la réputation et de la croissance durable de la société.\nProfil recherché\nDate de début : nc.\nDurée : nc.\nExpérience requise : Plus de 10 ans d'expérience\nSalaire : nc.\nRéférence : JR10150294\nSecteur d'activité : Industrialisation, Production"}, {'description': "Stage\nTemps plein\n6 mois\nBac+5\nDémarrage souhaité : 6 mars 2023\n27-31, avenue du Général Leclerc\n94 700 Maisons Alfort\nFRANCE\n\nVous cherchez à vivre une expérience professionnelle enrichissante et trouver du sens dans vos missions au quotidien ? Rejoignez l’aventure Bpifrance et faites partie de la nouvelle promotion de stagiaires et d’alternants prêts à Servir l’Avenir !\n\nBpifrance, une banque pas comme les autres\n\nLe rôle de Bpifrance, Banque Publique d’Investissement, est de dynamiser et rendre plus compétitive l’économie française.\nBpifrance soutient les entreprises françaises pour accélérer leur développement en France comme à l’international et renforcer leurs capacités d’innovation. Banque génératrice de croissance et de confiance, elle offre une palette de solutions de financement et d’accompagnement adaptées à chaque étape de la vie des entreprises, et fait de la transition écologique et énergétique une priorité stratégique. En tant qu’interlocuteur privilégié, les équipes sont au cœur des régions sur l'ensemble du territoire, à travers 50 implantations régionales.\n\nNotre ambition ? Devenir une Fintech. Et nous avons besoin des meilleurs !\n\nNous souhaitons transmuter pour devenir une FINTECH et offrir les meilleurs services digitaux à l’ensemble de nos clients, grâce à des plateformes digitales.\n\nLe goût du challenge\nNous avons développé notre propre techno : Hypercube qui porte l’ensemble de nos services banque en ligne. Nous agissons par les events, les API, les socles. Nous sommes Cloud first, Data centriques; nous rénovons toute notre tech avec les meilleures stacks et nous le faisons en agile à l’échelle. Ce projet, c’est bien. C’est même plus que bien, c’est révolutionnaire. Mais on veut aller encore plus loin.\n\n\nNous avons le goût du challenge et nos clients ont besoin de nous plus que jamais !\nEn Mars 2020, au cœur de la pandémie de Covid-19 qui frappait le monde, les entreprises françaises en pleine crise, nous avons réussi l’impossible : monter en seulement 3 semaines l’intégralité de la plateforme qui allait permettre de soutenir des centaines de milliers d’entreprises.\nVos missions au service de l’économie française\nLa validation et la revue régulière des modèles quantitatifs de Bpifrance\nLa supervision de backtests annuels sur les modèles quantitatifs\nLe développement de mesures de risque de modèle purement statistiques ou à dires d’expert\nLe Pôle de Validation des Modèles est le point d’entrée des contrôles externes sur les modèles (DGAU, Commissaires aux comptes, BCE, actionnaires...).\n\nObjectifs et problématiques du stage :\nAnalyser le comportement des modèles existants en exploitant des bases de données volumineuses\nChallenger les approches de modélisation employées en développant/exploitant des modèles miroirs\nProposer et développer des mesures de risque sur les modèles\nContribuer au développement d’outils permettant le contrôle permanent du risque de modèle\n\nPrêts à rejoindre notre équipe ?\n\nVous êtes de formation BAC+5 écoles d’ingénieur ou d’actuariat, 3ème cycle universitaire statistique ou économétrie\n\nUne première expérience dans le domaine bancaire serait un plus (stage court, césure, alternance...)\n\nPrincipales qualités requises :\n\nMaitrise du logiciel Python, et éventuellement SAS et/ou R\n\nCuriosité, pro-activité\nBonnes capacités rédactionnelles\n\nAptitude à proposer des solutions innovantes\n\nOutils statistiques ou méthodes utilisés :\n\nModèles statistiques\nMesures de risques\nAnalyse de données descriptive\nVous serez amené à exploiter des bases de données en utilisant Python.\n\nLes bonnes raisons de rejoindre l’aventure Bpifrance !\n\nUn travail avec du sens : Vous contribuerez à une mission unique d’utilité publique au service de l’économie française et au sein d’une banque engagée sur des sujets de société (climat, jeunesse, égalité des chances…).\nUn environnement dans lequel il fait bon vivre : Labellisé parmi les Meilleurs Employeurs France 2022 par Glassdoor et certifié Happy Trainees pour la 7e année consécutive, rejoindre Bpifrance c’est intégrer une banque engagée auprès des jeunes et évoluer au sein d'équipes dynamiques et bienveillantes.\nDes conditions avantageuses : Vous bénéficierez des nombreux avantages qu’offre le groupe pour ses stagiaires : rémunération attractive, jours de congé, remboursement transport supérieur au minimum légal, ateliers Qualité de Vie au Travail…\nUn tremplin pour votre carrière : Vous profiterez des meilleures conditions mises en place chez Bpifrance pour vous former, grandir, et donner une impulsion à votre carrière !\nTravailler chez Bpifrance, c’est intégrer une banque pas comme les autres, un projet d’entreprise ambitieux et tourné vers l’avenir. C’est plus qu’un métier : c’est une mission, une équipe, un réseau et un écosystème.\n\nPour découvrir nos autres opportunités et tout savoir de la vie au sein du groupe, rendez-vous sur notre site carrière : https://talents.bpifrance.fr !\n\nBpifrance est une banque citoyenne dotée d’un code de déontologie et d’une politique anti-corruption.\nAvant de postuler, nous vous invitons à consulter notre politique relative à la gestion des données à caractère personnel disponible sur notre site https://talents.bpifrance.fr/build/bpiTheme/files/politique-de-protection-des-donnees.pdf"}, {'description': 'Job Title\nData Analyst\nThe objective of the role ?\nTo develop and implement analytics applications and dashboards in Qlik and PowerBI on the cytric Data Platform.\nCommon accountabilities:\n\nWorks autonomously within defined processes and procedures or methodologies, takes standard decisions and may support the development of solutions to complex problems of a recurring nature.\n\nReceives instruction, guidance and direction from more senior level roles or manager, with regular monitoring on the status of the assignments.\n\nMay have specialized formal education or the equivalent work experience and has the required technical and functional skills and basic knowledge of the business.\n\nSpecific accountabilities:\n\nImplement data analysis algorithms on a large scale working closely with software engineering members\nCreate business solutions through a combination of science and software considering hypothesis by concrete business effect.\nDevelop products / service cooperating with project manager, developer and business staff.\nBuild & Maintain the “Big Data” infrastructure\nTrack business effect through products and leading next action.\nOperate and manage product to keep product availability cooperating with operation staff\nDiversity & Inclusion\nWe are an Equal Opportunity Employer and seek to hire the best candidate regardless of age, beliefs, disability, ethnicity, gender or sexual orientation.'}, {'description': 'Rejoignez une société en pleine croissance qui investit lourdement dans ses collaborateurs !\nNous recherchons un Data scientist pour un acteur majeur du secteur industriel en région Centre. Notre client est en pleine croissance depuis quelques années et investit lourdement dans l’IT avec la mise en place d’outils de reporting liés à la gestion de données produit et projet.\n\nLe poste est à pourvoir ASAP en CDI à Tours dans le cadre d’un renfort d’équipe.\n\nIntégré au sein du service system & Data, composé d’une petite quinzaine de personnes, vous avez en charge les systèmes, les outils de reporting et devenez un véritable expert des outils de données et du reporting de la division produits. Vous travaillez en étroite collaboration avec un homologue sur la partie métier pour assurer une complémentarité. Vous recevez le besoin client que vous analysez en termes d’impact, de complexité et de gain pour l’organisation. De plus, vous développez et maintenez des reports identifiés précédemment, avez à cœur de développer des outils pertinents et robustes, en utilisant une méthode agile, basé sur le besoin client. Vous livrez et formez les utilisateurs tout en gardant un œil attentif aux derniers outils du marché.\n\nIssu d’une formation en Bac +5 en Data Science, vous êtes capable de vous former aux différentes évolutions techniques pour pouvoir proposer des solutions robustes et innovantes.\n\nMaitrise de l’environnement Microsoft 365 incluant Power BI\nConnaissance en langage de développement (Java/Python etc…)\nCompétences en gestion de bases de données (SQL, ETL etc.)\n\nSi vous êtes curieux, à l’écoute, force de proposition et que vous souhaitez contribuer au bien être de vos futurs collaborateurs, ce poste est pour vous. Postulez ! #1332693'}, {'description': "YouStock a pour ambition de révolutionner la gestion de nos espaces de vie en offrant une réelle extension de chez soi accessible en ligne. Les problématiques de manque d'espace arrivent régulièrement tout au long de nos vies, aussi bien pour les particuliers que les entreprises. C'est pourtant toujours une galère, beaucoup de contraintes et de stress et souvent cher par rapport à nos besoins.\nYouStock a donc créé un SaaS, un Storage as a Service, en utilisant des technos modernes afin de proposer une solution simple, rapide et économique pour libérer son espace en quelques clics. La tech est la colonne vertébrale de YouStock et c’est grâce à celle-ci qu'elle peut rendre son modèle ultra scalable.\nLes caves humides, cambriolées, externalisées, bordéliques ou encore surfacturées, c’est du passé. Sur simple demande en ligne, YouStock collecte les objets à stocker et réalise un inventaire photo accessible sur son compte client. La livraison est rapide et s’effectue en quelques clics. Les tarifs sont justes car calculés au m3 près, ainsi le client ne paie que pour ce qu’il stocke réellement.\nCréée en 2015, YouStock devient un acteur majeur de la SmartCity en France et commence son expansion son Europe. En quelques chiffres, YouStock c’est déjà :\nPlus de 14 000 m3 en stockage\nParis, Lyon, Bordeaux, Nice, Monaco et Bruxelles! Le reste de l'Europe ensuite.\n10 millions d’€ levés par des fonds reconnus de la Proptech\n\nNB : ce poste n'est malheuresement ni pr un stage, ni une alternance. On ressent la grande motiviation chez tous mais nous cherchons un profil avec expérience. Merci :)\nTes missions, si tu les acceptes\nYouStock a pris partie d'investir sur le long terme sur la tech afin d'accroître son avantage concurrentiel. Nous recherchons un Data Analyst expérimenté et capable d’exploiter les données et de les utiliser comme outils pertinents d’aide à la décision. Tu auras l’opportunité de poser la première pierre de l’équipe Data. Tu vas collaborer avec les équipes pour leur fournir plus de visibilité sur leurs actions. Tu seras également accompagné par l'équipe technique pour la mise en place d'outils et d'automatisations, que tu sauras accompagnée aussi de part ton expérience dans une data team.\nComprendre les problématiques de chaque pôle ainsi que ceux de YouStock dans son ensemble\nAnalyser et traiter les bases de données de sorte à les transformer en informations exploitables pour les équipes\nModéliser et structurer les données à l’aide d’un outil de visualisation à implémenter\nMettre en place des dashboards automatisés et faire un suivi régulier des KPIs pour les différents pôles\nConstruire des modèles en SQL et établir des prévisions\nIdentifier les usage patterns auprès du pôle webmarketing pour anticiper les comportements des utilisateurs\nÉmettre des recommandations stratégiques et régulières aux différentes équipes\nAgir en tant que référent(e) pour toutes les questions liées aux données chez YouStock\n\nTon premier mois\nPasser avec toutes les teams pour comprendre leur besoin par rapport aux données déjà mises à disposition\nPrendre en main toutes les bases de données et les dashboards sur Metabase\nFaire la liste des sujets et prioriser en fonction de la stratégie globale\n\nTu es fait(e) pour nous rejoindre si\nTu es issu(e) d’un Bac +4 ou 5 en ingénierie / commerce / statistiques\nTu as minimum 3 ans d'expériences en Data Analysis, Statistiques\nTu maîtrises les langages SQL pour base données MySQL et PostgreSQL, Python et/ou R\nSuper esprit analytique, tu as une profonde connaissance des outils de Data Visualisation (Metabase, Tableau)\nYou understand what is written and you can have a conversation in english\nTu es positif et tu souhaites te dépasser dans des projets ambitieux\nTu es curieux, tu aimes apprendre, te former et résoudre des problèmes\nL’autonomie ne te fait pas peur. Tu es une machine d'exécution et tu sais être rigoureux\nTu as le startup team spirit : tu aimes échanger, apprendre et partager tes idées.\nLes avantages d'être avec Nous :) :\nBenefits: tickets restaus, télétravail jusqu'à 3j/sem., 1 mois de remote possible, Mutuelle Alan, Crédits de 1500€ pour un déménagement et 50€/mois de stockage, achat de Livres sur Amazon offert et d’autres encore.\nMeaning : tu participes pleinement à des projets innovants, ambitieux et stimulants\nAutonomy : tu es responsable, tu cherches et prends des décisions qui ont du sens\nTraining : tu reçois des feedbacks réguliers et tu prends part à notre partage de connaissances\nLearning : tu bénéficies de Blinkist Premium, tu montes en compétences et t’enrichis personnellement\n️ Fun (on bosse dur mais on sait s’amuser) : tu profites des team buildings et des afterworks\n️ Cadre de vie : tu travailles dans un environnement inspirant et ensoleillé\nDiversity : tu fais partie d'une équipe bienveillante qui accorde une grande importance à l’égalité\nDéroulement du recrutement :\nPour postuler, décris toi en 2 phrases, explique nous ce qui a retenu ton attention dans cette annonce, ce qui t’attire et ce que tu as envie de nous apporter. Si t’es chaud, envoie une vidéo pour répondre; nous on adore!\nPar la suite, on s’emploie à ce que tu rencontres plusieurs personnes de la Team :\nEntretien visio de 30 min\nEntretien physique avec Responsable + test technique\nCafé ou verre avec 2 personnes avec qui tu travaillerais\nEntretien avec un fondateur et/ou COO"}, {'description': "La Poste Groupe change, nos métiers évoluent.\nEtre toujours au plus près des Français, développer la confiance dans le numérique et être acteur de la transformation écologique, c'est aussi le sens de notre métier.\nChaque jour, sur l'ensemble du territoire, nos 250 000 collaborateurs imaginent les services de demain.\nRejoindre La Poste Groupe, c'est rejoindre une entreprise responsable !\nVous aussi, engagez-vous à nos côtés pour donner du sens à votre métier.\n\nVous voulez faire de la finance différemment ? La Banque Postale œuvre pour l'intérêt général, chaque jour, au plus proche de ses clients en envisageant la finance autrement : plus juste, plus responsable, plus citoyenne.\nÉgalement attentive à ses collaborateurs, elle s'engage en faveur de la diversité et de l'égalité des chances pour donner accès à tous ses métiers sans discrimination.\nVenez contribuer à bâtir l'acteur bancaire de référence de demain.\n\nØ Définir, en cohérence avec le coût du risque cible défini par l’entreprise, les objectifs annuels : - du recouvrement amiable (taux de mise à jour des dossiers en recouvrement, taux de passage du recouvrement amiable vers le recouvrement judiciaire, matrice de transition des impayés…)- du recouvrement contentieux (niveau d’encaissement cible annuel, frais et honoraires des huissiers, passage en perte….)Ø Créer, suivre, automatiser les indicateurs, les reporting, les outils de supervision afin de mieux contrôler l’activité opérationnelle LBPCFØ Contribuer à la construction des Comités Risques et RecouvrementØ Mener des analyses complémentaires sur des cibles identifiéesØ Proposer les actions visant à améliorer les résultats, le contrôle, les pratiques du recouvrement amiable et judiciaireØ Assurer la surveillance de l’efficacité du process de recouvrement sur l’ensemble de la chaine de valeur, le cas échéant alerterØ Participer ou contribuer aux projets opérationnels menés avec la Direction des Risques et la Direction des OpérationsØ Réaliser les reporting nécessaires à sa hiérarchie ; proposer des évolutions dans le contenu et le format et le mode de production des reporting\n\nØ Maîtrise des outils de gestion de Donnéeso Bon niveau souhaité (SAS, SQL, Excel)o Connaissance en option (Python, Excel programmation VBA)Ø Connaissance de l’activité du crédit à la consommation : produits, services, réglementationØ Expérience (ou formation) requise dans le pilotage / analyse du risque de crédit et de ses composantes opérationnelles : au recouvrement amiable et judiciaire, risque à l’acceptationØ Préparation de la documentation des comités\n\nVous êtes diplômé d’une formation de niveau Bac+5Vous avez une expérience d'au moins 2 ans à un poste similaire"}])
[2023-01-23T14:36:51.540+0000] {xcom.py:635} ERROR - Object of type DataExtractor is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-01-23T14:36:51.544+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2297, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataExtractor is not JSON serializable
[2023-01-23T14:36:51.559+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=data_extraction_and_loading_3, task_id=extract_data, execution_date=20220125T000000, start_date=20230123T143616, end_date=20230123T143651
[2023-01-23T14:36:51.575+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 84 for task extract_data (Object of type DataExtractor is not JSON serializable; 1705)
[2023-01-23T14:36:51.606+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2023-01-23T14:36:51.629+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
